{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(a):\n",
    "    date_formats = [\"%Y-%m-%d %H:%M:%S.%f\", \n",
    "                    \"%Y-%m-%d %H:%M:%S\", \n",
    "                    \"%m/%d/%Y %H:%M\",\n",
    "                    \"%m-%d-%Y %H:%M\", \n",
    "                    \"%m/%d/%Y\", \n",
    "                    \"%Y-%m-%d\", \n",
    "                    \"%H:%M.%f\",\n",
    "                    \"%m/%d/%Y %H:%M:%S\"] \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(str(a), fmt).strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    try:\n",
    "        return (datetime(1899, 12, 30) + timedelta(days=float(a))).strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if not re.match(\"\\d+:\\d+:\\d+(\\.\\d+)?\", str(a)):\n",
    "        return str(a)\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal_diff_case</td>\n",
       "      <td>2023-08-27 00:00:00</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appeal_dailyreport</td>\n",
       "      <td>2023-08-19 00:00:00</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regular_diff_case</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regular_false_case</td>\n",
       "      <td>2023-08-26 00:00:00</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rock_dailyreport</td>\n",
       "      <td>2023-08-19 00:00:00</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCR_diff_case</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCR_false_case</td>\n",
       "      <td>2023-08-26 00:00:00</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sideprj_shoptab</td>\n",
       "      <td>2023-08-27 00:00:00</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sideprj_ugads</td>\n",
       "      <td>2023-08-27 00:00:00</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sideprj_dailyreport</td>\n",
       "      <td>2023-08-19 00:00:00</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0           Start date   End date\n",
       "0     appeal_diff_case  2023-08-27 00:00:00 2023-08-27\n",
       "1   appeal_dailyreport  2023-08-19 00:00:00 2023-08-26\n",
       "2    regular_diff_case           2023-08-21 2023-08-27\n",
       "3   regular_false_case  2023-08-26 00:00:00 2023-08-26\n",
       "4     rock_dailyreport  2023-08-19 00:00:00 2023-08-26\n",
       "5        PCR_diff_case           2023-08-21 2023-08-27\n",
       "6       PCR_false_case  2023-08-26 00:00:00 2023-08-26\n",
       "7      sideprj_shoptab  2023-08-27 00:00:00 2023-08-27\n",
       "8        sideprj_ugads  2023-08-27 00:00:00 2023-08-27\n",
       "9  sideprj_dailyreport  2023-08-19 00:00:00 2023-08-26"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Supporting Dashboard\n",
    "\n",
    "#Variable\n",
    "Date_variable = pd.read_excel('e:/tt/qa_daily_automation/variable.xlsx')\n",
    "Date_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supporting Dashboard\n",
    "\n",
    "#Variable\n",
    "Date_variable = pd.read_excel('E:/tt/qa_daily_automation/variable.xlsx')\n",
    "from datetime import datetime\n",
    "Date_variable['Start date'] = Date_variable['Start date'].apply(convert_datetime)\n",
    "Date_variable['End date'] = Date_variable['End date'].apply(convert_datetime)\n",
    "\n",
    "Start_Date_False_Regular = datetime.strptime(str(Date_variable.loc[3, 'Start date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "End_Date_False_Regular = datetime.strptime(str(Date_variable.loc[3, 'End date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "\n",
    "Start_Date_Diff_Regular = datetime.strptime(str(Date_variable.loc[2, 'Start date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "End_Date_Diff_Regular = datetime.strptime(str(Date_variable.loc[2, 'End date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "\n",
    "#Queue\n",
    "queue_list = pd.read_excel('E:/tt/qa_daily_automation/Support_dashboard.xlsx',sheet_name='Queue List').values\n",
    "queue_list = pd.DataFrame(queue_list)\n",
    "headers = ['BUSINESS','COMPOUND','CATEGORY','MOD QUEUE ID','MOD QUEUE NAME',\n",
    "           'QA QUEUE ID','QA QUEUE NAME','QUEUE GROUP','STATUS','Priority','Latency','AHT (secs)','Policy_type','Classify']\n",
    "queue_list.columns = headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal_diff_case</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appeal_dailyreport</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regular_diff_case</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regular_false_case</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rock_dailyreport</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCR_diff_case</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCR_false_case</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sideprj_shoptab</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sideprj_ugads</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sideprj_dailyreport</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  Start date    End date\n",
       "0     appeal_diff_case  2023-08-27  2023-08-27\n",
       "1   appeal_dailyreport  2023-08-19  2023-08-26\n",
       "2    regular_diff_case  2023-08-21  2023-08-27\n",
       "3   regular_false_case  2023-08-26  2023-08-26\n",
       "4     rock_dailyreport  2023-08-19  2023-08-26\n",
       "5        PCR_diff_case  2023-08-21  2023-08-27\n",
       "6       PCR_false_case  2023-08-26  2023-08-26\n",
       "7      sideprj_shoptab  2023-08-27  2023-08-27\n",
       "8        sideprj_ugads  2023-08-27  2023-08-27\n",
       "9  sideprj_dailyreport  2023-08-19  2023-08-26"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(a):\n",
    "    my_format=\"%Y-%m-%d %H:%M:%S\"\n",
    "    try:\n",
    "        return datetime.strptime(str(a), \"%Y-%m-%d %H:%M:%S\").strftime(my_format)\n",
    "    except:\n",
    "        return datetime.strptime(str(a), \"%m/%d/%Y %H:%M\").strftime(my_format)\n",
    "def convert_date(a):\n",
    "    my_format=\"%Y-%m-%d\"\n",
    "    try:\n",
    "        return datetime.strptime(str(a), \"%Y-%m-%d %H:%M:%S\").strftime(my_format)\n",
    "    except:\n",
    "        return datetime.strptime(str(a), \"%m/%d/%Y %H:%M\").strftime(my_format)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(struct_time):\n",
    "    return datetime(*struct_time[:6])\n",
    "\n",
    "def input_data(data_dir):\n",
    "    list_files = []\n",
    "\n",
    "    for filename in pathlib.Path(data_dir).glob('**/*.*'):\n",
    "        file_suffixes = filename.suffixes\n",
    "        if file_suffixes[-1].lower() in ['.xlsx', '.csv']:\n",
    "            if file_suffixes[-1].lower() == '.xlsx':\n",
    "                export_time = os.path.getmtime(filename)\n",
    "                export_time_datetime = convert_to_datetime(time.localtime(export_time))\n",
    "\n",
    "                filename_with_export_time = filename.with_suffix('.xlsx')\n",
    "\n",
    "                dfs = pd.read_excel(filename, sheet_name=None, skiprows=0, na_values=None, dtype={'Moderation Queue ID':object,'Object ID':object,'Task id':object,'Sampling Task ID':object})\n",
    "                for sheet_name, df in dfs.items():\n",
    "                    df['sheet_name'] = sheet_name\n",
    "                    df['Export time'] = export_time_datetime\n",
    "                    list_files.append(df)\n",
    "\n",
    "            elif file_suffixes[-1].lower() == '.csv':\n",
    "                export_time = os.path.getmtime(filename)\n",
    "                export_time_datetime = convert_to_datetime(time.localtime(export_time))\n",
    "\n",
    "                df = pd.read_csv(filename, skiprows=0, na_values=None, dtype={'Moderation Queue ID':object,'Object ID':object,'Task id':object,'Sampling Task ID':object,'task_id':object})\n",
    "                df['sheet_name'] = 'CSV'\n",
    "                df['Export time'] = export_time_datetime\n",
    "                list_files.append(df)\n",
    "\n",
    "    df_list = pd.concat(list_files, axis=0, ignore_index=True)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rock_append = input_data('E:/tt/qa_daily_automation/Rock daily')\n",
    "Rock_append = Rock_append.sort_values(by=['Export time'],ascending=True)\n",
    "Rock_append = Rock_append.drop_duplicates(subset='Sampling Task ID',keep='last')\n",
    "\n",
    "Rock_append = Rock_append.dropna(subset=['Moderation Time.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = Rock_append.groupby('Sampling Queue').first().reset_index()\n",
    "columns = Rock_append.columns\n",
    "new_df = grouped_df[columns]\n",
    "new_df = new_df[['Sampling Queue','Sampling Task ID','Initial Moderation Result','Sampling respondent Result','Correct Moderated Results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_17440\\1526918364.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process_result['process result.1']=data_process_result['process result.1'].astype(str).replace('---',np.nan)\n",
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_17440\\1526918364.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process_result['process result.2']=data_process_result['process result.2'].astype(str).replace('---',np.nan)\n",
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_17440\\1526918364.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process_result['process result.3']=data_process_result['process result.3'].astype(str).replace('---',np.nan)\n",
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_17440\\1526918364.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process_result['process result.4']=data_process_result['process result.4'].astype(str).replace('---',np.nan)\n",
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_17440\\1526918364.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process_result['process result.5']=data_process_result['process result.5'].astype(str).replace('---',np.nan)\n",
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_17440\\1526918364.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process_result['Sampling Task ID'] = data_process_result['Sampling Task ID'].astype('int64').astype(str)\n",
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_17440\\1526918364.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process_result['Final process result'] = data_process_result.apply(r, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampling Task ID</th>\n",
       "      <th>Final process result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7258388699056964101</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7258722422264824326</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7258750765303448069</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7258350221615268358</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7258350224140386822</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>7269879005090693633</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>7269879122933858818</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>7269879190231515649</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>7270966570694787586</td>\n",
       "      <td>Failed appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>7270232952603181573</td>\n",
       "      <td>Arbitrator process overtime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4872 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sampling Task ID         Final process result\n",
       "0     7258388699056964101                Failed appeal\n",
       "1     7258722422264824326                Failed appeal\n",
       "2     7258750765303448069                Failed appeal\n",
       "3     7258350221615268358                Failed appeal\n",
       "4     7258350224140386822                Failed appeal\n",
       "...                   ...                          ...\n",
       "4867  7269879005090693633                Failed appeal\n",
       "4868  7269879122933858818                Failed appeal\n",
       "4869  7269879190231515649                Failed appeal\n",
       "4870  7270966570694787586                Failed appeal\n",
       "4871  7270232952603181573  Arbitrator process overtime\n",
       "\n",
       "[4872 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xử lý process_result\n",
    "data_process_result = Rock_append[['Sampling Task ID','process result','process result.1','process result.2','process result.3','process result.4','process result.5']]\n",
    "\n",
    "data_process_result['process result.1']=data_process_result['process result.1'].astype(str).replace('---',np.nan)\n",
    "data_process_result['process result.2']=data_process_result['process result.2'].astype(str).replace('---',np.nan)\n",
    "data_process_result['process result.3']=data_process_result['process result.3'].astype(str).replace('---',np.nan)\n",
    "data_process_result['process result.4']=data_process_result['process result.4'].astype(str).replace('---',np.nan)\n",
    "data_process_result['process result.5']=data_process_result['process result.5'].astype(str).replace('---',np.nan)\n",
    "\n",
    "data_process_result['Sampling Task ID'] = data_process_result['Sampling Task ID'].astype('int64').astype(str)\n",
    "data_process_result.set_index('Sampling Task ID',inplace=True)\n",
    "\n",
    "def r(row):\n",
    "    last_index = row.last_valid_index()\n",
    "    return row[last_index] if last_index else np.nan\n",
    "\n",
    "data_process_result['Final process result'] = data_process_result.apply(r, axis=1)\n",
    "data_process_result.reset_index('Sampling Task ID',inplace=True)\n",
    "data_process_result = data_process_result[['Sampling Task ID','Final process result']]\n",
    "data_process_result['Final process result']=data_process_result['Final process result'].astype(str).replace('give up appealing ',\"Failed appeal\").astype(str)\n",
    "data_process_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Selected duration', 'Claimant queue', 'Sampling Queue',\n",
       "       'Operate status', 'Moderation Queue ID', 'Object ID', 'Task id',\n",
       "       'Sampling Task ID', 'Task link', 'Moderation Round',\n",
       "       'Initial Moderation Result', 'Latest Operator', 'Last operator role',\n",
       "       'Specific operation', 'Moderation Time', 'Sampling respondent Result',\n",
       "       'Moderation Time.1', 'Arbitrator's Result', 'Final Arbitrator's Result',\n",
       "       'Corrector's result', 'Correct Moderated Results', 'Appealing Result',\n",
       "       'Error towards', 'the one who is dealing now', 'Existing tags',\n",
       "       'tagger', 'claimant', 'process result', 'process reason',\n",
       "       'beginning time', 'Terminal time', 'handling time', 'Validator',\n",
       "       'process result.1', 'process reason.1', 'beginning time.1',\n",
       "       'Terminal time.1', 'handling time.1', 'Arbitrator', 'process result.2',\n",
       "       'process reason.2', 'beginning time.2', 'Terminal time.2',\n",
       "       'handling time.2', 'Respondent', 'process result.3', 'process reason.3',\n",
       "       'beginning time.3', 'Terminal time.3', 'handling time.3',\n",
       "       'Final Arbitrator', 'process result.4', 'process reason.4',\n",
       "       'beginning time.4', 'Terminal time.4', 'handling time.4',\n",
       "       'Correct role', 'Operator', 'process reason.5', 'beginning time.5',\n",
       "       'Terminal time.5', 'handling time.5', 'Corrector', 'process result.5',\n",
       "       'process reason.6', 'beginning time.6', 'Terminal time.6',\n",
       "       'handling time.6', 'Moderation procedure index-Claimant',\n",
       "       'Moderation procedure index-Respondent', 'Sampling rounds',\n",
       "       'sheet_name', 'Export time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rock_append.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rock_append[['Moderated Results','Moderation Result','Respondent Result']] = Rock_append[['Correct Moderated Results','Initial Moderation Result','Sampling respondent Result']].replace(to_replace=r'^auditStatus: ',value= \"Audit Result:: \",regex=True).astype(str)\n",
    "pcr_result = ['remove', 'normal', 'selfvisible']\n",
    "columns = ['Moderated Results', 'Moderation Result', 'Respondent Result']\n",
    "\n",
    "def match_and_concatenate(cell):\n",
    "    cell = str(cell).lower()\n",
    "    cell = cell.replace('_x000d_', '')\n",
    "    found_words = []\n",
    "    audit_exp = re.search(r'(.*auditreason:)(.*)(\\n|$)', cell)\n",
    "    reject_exp = re.search(r'(.*rejectlabel:)(.*)(\\n|$)', cell)\n",
    "    if audit_exp:\n",
    "        cell_split = audit_exp.group(2).strip()\n",
    "    elif reject_exp:\n",
    "        cell_split = reject_exp.group(2).strip()\n",
    "    else:\n",
    "        cell_split = cell\n",
    "    cell_split = re.sub(r'[\\[\\]\"]', '', cell_split)\n",
    "    matches = re.findall('|'.join(pcr_result), cell_split, re.IGNORECASE)\n",
    "    found_words.extend(matches)\n",
    "    return \",\".join(found_words) if found_words else None\n",
    "for column in ['Moderated Results', 'Moderation Result', 'Respondent Result']:\n",
    "    Rock_append.loc[Rock_append['Sampling Queue'].isin(['QA VN LL Product Comment', 'QA VN LL Product Comment Report']), column] = Rock_append.loc[Rock_append['Sampling Queue'].isin(['QA VN LL Product Comment', 'QA VN LL Product Comment Report']), column].apply(match_and_concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rock_append[(Rock_append['Sampling Queue'].isin(['QA VN LL Product Comment', 'QA VN LL Product Comment Report']))][['Object ID', 'Moderated Results', 'Moderation Result', 'Respondent Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rock_append[(Rock_append['Sampling Queue'].isin(['QA VN LL Product Comment', 'QA VN LL Product Comment Report'])) & (Rock_append['Respondent Result'].isnull())][['Object ID', 'Moderated Results', 'Moderation Result', 'Respondent Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mod Result</th>\n",
       "      <th>QA Result</th>\n",
       "      <th>Final Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17384</th>\n",
       "      <td>Approve</td>\n",
       "      <td>Not Approve</td>\n",
       "      <td>Not Approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17383</th>\n",
       "      <td>Approve</td>\n",
       "      <td>Not Approve</td>\n",
       "      <td>Not Approve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mod Result    QA Result Final Result\n",
       "17384    Approve  Not Approve  Not Approve\n",
       "17383    Approve  Not Approve  Not Approve"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rock_append['Correct Moderated Results'] = Rock_append['Correct Moderated Results'].str.lower()\n",
    "Rock_append['Sampling respondent Result'] = Rock_append['Sampling respondent Result'].str.lower()\n",
    "Rock_append['Initial Moderation Result'] = Rock_append['Initial Moderation Result'].str.lower()\n",
    "\n",
    "def process_cell(cell, aliases):\n",
    "    results = []\n",
    "    audit_results = re.findall(r'audit result: (.+)', cell, re.IGNORECASE)\n",
    "    for audit_result in audit_results:\n",
    "        for k, v in aliases.items():\n",
    "            pat = '|'.join(v)\n",
    "            if re.search(pat, audit_result, re.IGNORECASE):\n",
    "                results.append(k)\n",
    "    return ', '.join(results)\n",
    "\n",
    "aliases = {\n",
    "    \"Not Approve\": ['\"status\":400','\":400,\"','400.0','disapproval', 'disapproved','not approval','not approve' ,'notapproval','disapprove','not approved'],\n",
    "    \"Approve\": ['approve','\"status\":200' ,'approval', 'approved','200' ,'200.0']\n",
    "}\n",
    "\n",
    "Rock_append['Final Result'] = Rock_append['Correct Moderated Results'].apply(lambda x: process_cell(str(x), aliases))\n",
    "Rock_append['QA Result'] = Rock_append['Sampling respondent Result'].apply(lambda x: process_cell(str(x), aliases))\n",
    "Rock_append['Mod Result'] = Rock_append['Initial Moderation Result'].apply(lambda x: process_cell(str(x), aliases))\n",
    "\n",
    "Rock_append.loc[Rock_append['Final Result'] == '', 'Final Result'] = Rock_append.loc[Rock_append['Final Result'] == '', 'Moderated Results']\n",
    "Rock_append.loc[Rock_append['QA Result'] == '', 'QA Result'] = Rock_append.loc[Rock_append['QA Result'] == '', 'Respondent Result']\n",
    "Rock_append.loc[Rock_append['Mod Result'] == '', 'Mod Result'] = Rock_append.loc[Rock_append['Mod Result'] == '', 'Moderation Result']\n",
    "\n",
    "def process_cell_2(cell):\n",
    "    if cell is None:\n",
    "        return '---'\n",
    "    elif 'Not' in cell:\n",
    "        return 'Not Approve'\n",
    "    elif any(substring in cell for substring in ['normal', 'remove', 'selfvisible']):\n",
    "        return cell\n",
    "    else:\n",
    "        return 'Approve'\n",
    "\n",
    "Rock_append['Final Result'] = Rock_append['Final Result'].apply(process_cell_2)\n",
    "Rock_append['QA Result'] = Rock_append['QA Result'].apply(process_cell_2)\n",
    "Rock_append['Mod Result'] = Rock_append['Mod Result'].apply(process_cell_2)\n",
    "\n",
    "Rock_append[Rock_append['Sampling Queue']=='QA VN LL Pigeon User Profile'][['Mod Result','QA Result','Final Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rock_append['Correct Moderated Results'] = Rock_append['Correct Moderated Results'].str.lower()\n",
    "Rock_append['Sampling respondent Result'] = Rock_append['Sampling respondent Result'].str.lower()\n",
    "Rock_append['Initial Moderation Result'] = Rock_append['Initial Moderation Result'].str.lower()\n",
    "\n",
    "Policy_errors_1 = [\n",
    "    'prohibited products','unsupported products','restricted products','adult nudity and sexual activities','hateful behaviors','minor safety','absolute terms',\n",
    "    'malicious comparison','title spam','abnormal price','inconsistent information','other languages','misleading functionality and effect','redirect traffic',\n",
    "    'missing brand authorization','unfair trading','obscuring product images','target to minors','underage commercial behavior','false promise','false promises','sympathy promotion',\n",
    "    'misleading size/weight/quantity','misleading patent/endorsement/metrics/awards','misleading origin','misleading return & refund service','misleading guarantees and warranties',\n",
    "    'irrelevant promotion','give away','reproduced content','soliciting mutual interactions','still frame','possible pirated contents','possible pirated content',\n",
    "    'non product promotion content','vulgar behavior','disturbing animal body','insulting and abusive content','body impurities','dirty environment','eye-catching sensitive content',\n",
    "    'bind a sell b - prohibited product','misleading logistics','misleading brand','brand circumvention','copycat products','violence',\n",
    "    'illegal behavior','hatespeech and harassment','possible ip infringement','spam','invalid company name','inaccurate company name','inaccurate company address','missing identity document',\n",
    "    'expired documentation','black-and-white copy','unclear documentation','invalid watermark or logo','incomplete documentation','inaccurate representative name','inaccurate id number',\n",
    "    'inaccurate documentation','inaccurate tax name','inaccurate tax number','inaccurate brand name','inaccurate trademark name','inaccurate trademark number','inaccurate application date',\n",
    "    'inaccurate expiry date','invalid trademark','inaccurate registrant','unqualified destination market','inaccurate class(es) of goods/service','unqualified owner','inaccurate trademark certificate',\n",
    "    'expired trademark certificate','unclear trademark certificate','inauthentic trademark certificate','unqualified 1st level distributor','inaccurate 1st level distributor letter',\n",
    "    'expired 1st level distributor letter','unclear 1st level distributor letter','inauthentic 1st level distributor letter','unqualified 2nd level distributor',\n",
    "    'inaccurate 2nd level distributor letter','expired 2nd level distributor letter','unclear 2nd level distributor letter','inauthentic 2nd level distributor letter',\n",
    "    'unqualified third level distributor','inaccurate third level distributor letter','expired third level distributor letter','unclear third level distributor letter',\n",
    "    'inauthentic third level distributor letter','missing buyer information','missing quantity of purchase item','missing purchase item information','missing purchase date',\n",
    "    'unable to locate brand item product','purchase date mismatch','seller information mismatch','missing price of purchase item','missing seller information',\n",
    "    'product quantity insufficient','exceeded validity period','altered document','lack of supportive information','unable to recognise source of purchase','underage applicant',\n",
    "    'gibberish shop name','abnormal company status','traffic redirection','inaccurate company number','oversea personal seller','ps tampering trace','inauthentic documentation',\n",
    "    'violent extremism','hate speech','unauthorized brand information','impersonation','suicide and dangerous acts','illegal activities and regulated goods',\n",
    "    'harassment and bullying','child endangerment information','counterfeit product information','inauthentic certification of incorporation','inaccurate register date','erotic nudity','hateful contexts','partner name or logo relates to ''tiktok''','inauthentic work environment','repeated image','inappropriate watermark or logo',\n",
    "    'incomplete information','inaccurate and misleading review','slightly vulgar','inaccurate package weight information','inappropriate speech','malicious behaviors','vulgar issues',\n",
    "    'imagery depicting skin defects','imagery depicting indecent body organs','imagery depicting indecent teeth&oral','imagery depicting animal meat/carcasses',\n",
    "    'imagery depicting unpleasant animal or insect','imagery depicting impurities','horror content','scene of squalor','offensive content','human excrement','mental illness content',\n",
    "    'unsuitable for recommendation','surprise-based product','vat number check','slide show','counterfeit word indication','brand never produced','bind a sell b-prohibited product',\n",
    "    'pirated content- dedup recall','pirated content','possible counterfeit product','click bait','click-bait','non shippable products','physical trademark infringement product','incorrect category high risk','low cost content',  \n",
    "    'gambling related behaviour','information trademark infringement product','physically damaged id','suspicious brand promotion','non interactive content',\n",
    "    ]\n",
    "\n",
    "Policy_errors_2 = list(map(lambda x: x.replace(\" \", \"_\") + \"0005\", Policy_errors_1))\n",
    "\n",
    "Policy_errors = Policy_errors_1 + Policy_errors_2\n",
    "\n",
    "cols_to_check = [ 'Initial Moderation Result','Sampling respondent Result','Correct Moderated Results']\n",
    "cols_to_return = ['Mod Reason', 'QA Reason', 'Correct Policy']\n",
    "\n",
    "queue_policy_type = queue_list[['QA QUEUE NAME','Policy_type']]\n",
    "   \n",
    "Rock_append = pd.merge(Rock_append,queue_policy_type, how='inner', left_on='Sampling Queue', right_on='QA QUEUE NAME')\n",
    "\n",
    "for col_idx, col in enumerate(cols_to_check):\n",
    "    Rock_append[cols_to_return[col_idx]] = ''\n",
    "    for i, row in Rock_append.iterrows():\n",
    "        cell_value = row[col]\n",
    "        policy_type = row['Policy_type']\n",
    "        if isinstance(cell_value, str):\n",
    "            if 'form_info' in cell_value:\n",
    "                form_info_index = cell_value.index('form_info')\n",
    "                cell_value = cell_value[form_info_index:]\n",
    "                match_list_1 = [match for match in Policy_errors_1 if match in cell_value]\n",
    "                match_list_2 = [match for match in Policy_errors_2 if match in cell_value]\n",
    "                if match_list_1 or match_list_2:\n",
    "                    match_list = list(OrderedDict.fromkeys(match_list_1 + match_list_2))\n",
    "                    final_reason = \", \".join(match_list).strip()\n",
    "                    Rock_append.at[i, cols_to_return[col_idx]] = final_reason\n",
    "            else:\n",
    "                if policy_type == 'Multi-choice':\n",
    "                    match_list_1 = [match for match in Policy_errors_1 if match in cell_value]\n",
    "                    match_list_2 = [match for match in Policy_errors_2 if match in cell_value]\n",
    "                    if match_list_1 or match_list_2:\n",
    "                        match_list = list(OrderedDict.fromkeys(match_list_1 + match_list_2))\n",
    "                        final_reason = \", \".join(match_list).strip()\n",
    "                        Rock_append.at[i, cols_to_return[col_idx]] = final_reason\n",
    "                elif policy_type == 'Single-choice':\n",
    "                    match_list_1 = []\n",
    "                    for match in Policy_errors_1:\n",
    "                        if match in cell_value:\n",
    "                            match_list_1.append(match)\n",
    "                            break\n",
    "                    if match_list_1:\n",
    "                        final_reason = match_list_1[0]\n",
    "                        Rock_append.at[i, cols_to_return[col_idx]] = final_reason\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "Rock_append['Final policy errors'] = Rock_append[['Mod Reason', 'QA Reason', 'Correct Policy']].apply(lambda x: x[x != ''].loc[x[x != ''].last_valid_index()] if x[x != ''].last_valid_index() else '', axis=1)\n",
    "\n",
    "Rock_append['Final policy errors'] = Rock_append['Final policy errors'].replace(\"0005\",\"\",regex=True).replace(\"_\",\" \",regex=True).replace(\"counterfeit abnorma price product\",\"abnormal price\")\n",
    "Rock_append['QA Reason'] = Rock_append['QA Reason'].replace(\"0005\",\"\",regex=True).replace(\"_\",\" \",regex=True).replace(\"counterfeit abnorma price product\",\"abnormal price\")\n",
    "Rock_append['Mod Reason'] = Rock_append['Mod Reason'].replace(\"0005\",\"\",regex=True).replace(\"_\",\" \",regex=True).replace(\"counterfeit abnorma price product\",\"abnormal price\")\n",
    "\n",
    "Rock_append['Final policy errors'] = Rock_append['Final policy errors'].apply(lambda x: \", \".join(set(x.split(\", \"))))\n",
    "Rock_append['QA Reason'] = Rock_append['QA Reason'].apply(lambda x: \", \".join(set(x.split(\", \"))))\n",
    "Rock_append['Mod Reason'] = Rock_append['Mod Reason'].apply(lambda x: \", \".join(set(x.split(\", \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mod Reason        0\n",
       "QA Reason         0\n",
       "Correct Policy    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rock_append[['Mod Reason','QA Reason','Correct Policy']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the RCA labels\n",
    "try:\n",
    "    Rock_append[['RCA lvl1','RCA lvl2','RCA lvl3']] = Rock_append['Existing tags'].str.split(' > ', expand=True, n=2)\n",
    "except:\n",
    "    Rock_append[['RCA lvl1','RCA lvl2','RCA lvl3']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add diff case\n",
    "Rock_append.loc[Rock_append['Mod Result'] != Rock_append['QA Result'],'Diff case']=\"FALSE\"\n",
    "Rock_append.loc[Rock_append['Diff case'].isnull(),'Diff case']=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert_time\n",
    "Rock_append['Moderation Time'] = Rock_append['Moderation Time'].apply(convert_datetime)\n",
    "Rock_append['Moderation Time'] = pd.to_datetime(Rock_append['Moderation Time'])\n",
    "\n",
    "Rock_append['Moderation Time.1'] = Rock_append['Moderation Time.1'].apply(convert_datetime)\n",
    "Rock_append['Moderation Time.1'] = pd.to_datetime(Rock_append['Moderation Time.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872, 89)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Rock_append = Rock_append.copy()\n",
    "Final_Rock_append['Sampling Task ID'] = Final_Rock_append['Sampling Task ID'].astype('int64').astype(str)\n",
    "Final_Rock_append.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Rock_append = pd.merge(Final_Rock_append,data_process_result,how='inner',on=['Sampling Task ID'])\n",
    "\n",
    "Final_Rock_append['Object ID'] = \"id=\" + Final_Rock_append['Object ID'].astype(str)\n",
    "Final_Rock_append['Sampling Task ID'] = \"id=\" + Final_Rock_append['Sampling Task ID'].astype('int64').astype(str)\n",
    "Final_Rock_append['Moderation Queue ID'] = \"id=\" + Final_Rock_append['Moderation Queue ID'].astype('int64').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_number(df, mod_number, qa_number):\n",
    "    priority = {\n",
    "        \"remove\": 3,\n",
    "        \"selfvisible\": 2,\n",
    "        \"normal\": 1,\n",
    "        \"Approve\": 0,\n",
    "        \"Not Approve\": 0,\n",
    "        \"---\":0\n",
    "    }\n",
    "\n",
    "    df['mod_convert_number'] = 0\n",
    "    df['qa_convert_number'] = 0\n",
    "\n",
    "    if df['Sampling Queue'].isin([\"QA VN LL Product Comment\", \"QA VN LL Product Comment Report\"]).any():\n",
    "        df['mod_convert_number'] = df[mod_number].apply(lambda x: int(''.join(str(priority[v]) for v in x.split(','))))\n",
    "        df['qa_convert_number'] = df[qa_number].apply(lambda x: int(''.join(str(priority[v]) for v in x.split(','))))\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_zeros(x, max_length):\n",
    "    x = str(x)\n",
    "    while len(x) < max_length:\n",
    "        x += '0'\n",
    "    return int(x)\n",
    "\n",
    "def add_zeros_to_shorter(df):\n",
    "    max_length = max(df['mod_convert_number'].astype(str).apply(len).max(), df['qa_convert_number'].astype(str).apply(len).max())\n",
    "    df['mod_convert_number'] = df['mod_convert_number'].apply(add_zeros, args=(max_length,))\n",
    "    df['qa_convert_number'] = df['qa_convert_number'].apply(add_zeros, args=(max_length,))\n",
    "    return df\n",
    "\n",
    "Final_Rock_append = convert_to_number(Final_Rock_append, 'Mod Result','QA Result')\n",
    "Final_Rock_append = add_zeros_to_shorter(Final_Rock_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN/FP\n",
    "Final_Rock_append.loc[(Final_Rock_append['QA Result'] == 'Approve') & (Final_Rock_append['Final process result'] == 'Failed appeal'),'Final False Error']=\"False Positive\"\n",
    "Final_Rock_append.loc[Final_Rock_append['Final False Error'].isnull(),'Final False Error']=\"False Negative\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['Mod Result'] == 'Approve') & (Final_Rock_append['Final process result'] == 'Appeal successfully'),'Final False Error']=\"False Positive\"\n",
    "Final_Rock_append.loc[Final_Rock_append['Final False Error'].isnull(),'Final False Error']=\"False Negative\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['QA Result'] == 'Approve') & (Final_Rock_append['Final process result'] == 'Edge case'),'Final False Error']=\"False Positive\"\n",
    "Final_Rock_append.loc[Final_Rock_append['Final False Error'].isnull(),'Final False Error']=\"False Negative\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['qa_convert_number'] != 0)&(Final_Rock_append['mod_convert_number'] > Final_Rock_append['qa_convert_number'])&(Final_Rock_append['Final process result'] == 'Failed appeal'),'Final False Error']=\"False Positive\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['qa_convert_number'] != 0)&(Final_Rock_append['mod_convert_number'] < Final_Rock_append['qa_convert_number'])&(Final_Rock_append['Final process result'] == 'Failed appeal'),'Final False Error']=\"False Negative\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['qa_convert_number'] != 0)&(Final_Rock_append['mod_convert_number'] > Final_Rock_append['qa_convert_number'])&(Final_Rock_append['Final process result'] == 'Edge case'),'Final False Error']=\"False Positive\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['qa_convert_number'] != 0)&(Final_Rock_append['mod_convert_number'] < Final_Rock_append['qa_convert_number'])&(Final_Rock_append['Final process result'] == 'Edge case'),'Final False Error']=\"False Negative\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['qa_convert_number'] != 0)&(Final_Rock_append['mod_convert_number'] > Final_Rock_append['qa_convert_number'])&(Final_Rock_append['Final process result'] == 'Appeal successfully'),'Final False Error']=\"False Negative\"\n",
    "Final_Rock_append.loc[(Final_Rock_append['qa_convert_number'] != 0)&(Final_Rock_append['mod_convert_number'] < Final_Rock_append['qa_convert_number'])&(Final_Rock_append['Final process result'] == 'Appeal successfully'),'Final False Error']=\"False Positive\"\n",
    "Final_Rock_append.loc[Final_Rock_append['process result'] == '---','Final False Error']=\"---\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Selected duration', 'Claimant queue', 'Sampling Queue',\n",
       "       'Operate status', 'Moderation Queue ID', 'Object ID', 'Task id',\n",
       "       'Sampling Task ID', 'Task link', 'Moderation Round',\n",
       "       'Initial Moderation Result', 'Latest Operator', 'Last operator role',\n",
       "       'Specific operation', 'Moderation Time', 'Sampling respondent Result',\n",
       "       'Moderation Time.1', 'Arbitrator's Result', 'Final Arbitrator's Result',\n",
       "       'Corrector's result', 'Correct Moderated Results', 'Appealing Result',\n",
       "       'Error towards', 'the one who is dealing now', 'Existing tags',\n",
       "       'tagger', 'claimant', 'process result', 'process reason',\n",
       "       'beginning time', 'Terminal time', 'handling time', 'Validator',\n",
       "       'process result.1', 'process reason.1', 'beginning time.1',\n",
       "       'Terminal time.1', 'handling time.1', 'Arbitrator', 'process result.2',\n",
       "       'process reason.2', 'beginning time.2', 'Terminal time.2',\n",
       "       'handling time.2', 'Respondent', 'process result.3', 'process reason.3',\n",
       "       'beginning time.3', 'Terminal time.3', 'handling time.3',\n",
       "       'Final Arbitrator', 'process result.4', 'process reason.4',\n",
       "       'beginning time.4', 'Terminal time.4', 'handling time.4',\n",
       "       'Correct role', 'Operator', 'process reason.5', 'beginning time.5',\n",
       "       'Terminal time.5', 'handling time.5', 'Corrector', 'process result.5',\n",
       "       'process reason.6', 'beginning time.6', 'Terminal time.6',\n",
       "       'handling time.6', 'Moderation procedure index-Claimant',\n",
       "       'Moderation procedure index-Respondent', 'Sampling rounds',\n",
       "       'sheet_name', 'Export time', 'Moderated Results', 'Moderation Result',\n",
       "       'Respondent Result', 'Final Result', 'QA Result', 'Mod Result',\n",
       "       'QA QUEUE NAME', 'Policy_type', 'Mod Reason', 'QA Reason',\n",
       "       'Correct Policy', 'Final policy errors', 'RCA lvl1', 'RCA lvl2',\n",
       "       'RCA lvl3', 'Diff case', 'Final process result', 'mod_convert_number',\n",
       "       'qa_convert_number', 'Final False Error'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Rock_append.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Rock_append = Final_Rock_append[['Sampling Queue','claimant','Moderation Time','Object ID','Mod Result', \n",
    "                   'Mod Reason','Respondent','Moderation Time.1','Sampling Task ID', 'QA Result', 'QA Reason','Diff case','process result',\n",
    "                   'process reason','Arbitrator','Final process result','Final False Error','Final policy errors','RCA lvl1','RCA lvl2','RCA lvl3','process reason.2',\n",
    "                   'Final Arbitrator','process result.4','process reason.4','Task id']].sort_values(ascending=True,by='Moderation Time.1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export diff case -> NEW 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_time( df,  from_date, to_date):\n",
    "\n",
    "    Final_Rock_append = df[(df['Moderation Time.1'].dt.strftime('%Y-%m-%d') >= from_date) & (df['Moderation Time.1'].dt.strftime('%Y-%m-%d') <= to_date)]\n",
    "    Final_Rock_append = Final_Rock_append[Final_Rock_append['claimant'].str.contains('@trans-cosmos.com.vn')]\n",
    "    Final_Rock_append.to_excel(f\"e:/tt/qa_daily_automation/Rock case statistic.xlsx\", index=False)\n",
    "\n",
    "    return Final_Rock_append\n",
    "# Fill in moderation time (Tue -> Today - 1)\n",
    "Regular_diff = filter_time(Final_Rock_append, Start_Date_Diff_Regular, End_Date_Diff_Regular)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
