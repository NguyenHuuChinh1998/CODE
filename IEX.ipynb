{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import shutil\n",
    "import polars as pl\n",
    "import fastexcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(struct_time):\n",
    "    return datetime(*struct_time[:6])\n",
    "\n",
    "def unify_dtypes(dfs):\n",
    "    all_columns = set()\n",
    "    for df in dfs:\n",
    "        all_columns.update(df.columns)\n",
    "\n",
    "    col_dtypes = {}\n",
    "    for col in all_columns:\n",
    "        dtypes = set()\n",
    "        for df in dfs:\n",
    "            if col in df.columns:\n",
    "                dtypes.add(df[col].dtype)\n",
    "        col_dtypes[col] = dtypes\n",
    "\n",
    "    new_dfs = []\n",
    "    for df in dfs:\n",
    "        df_new = df\n",
    "        for col, dtypes in col_dtypes.items():\n",
    "            if col in df_new.columns:\n",
    "                if len(dtypes) > 1:\n",
    "                    df_new = df_new.with_columns(pl.col(col).cast(pl.Utf8))\n",
    "                else:\n",
    "                    pass\n",
    "        new_dfs.append(df_new)\n",
    "    return new_dfs\n",
    "\n",
    "def input_data(data_dir):\n",
    "    list_files = []\n",
    "    for filename in pathlib.Path(data_dir).glob('**/*.*'):\n",
    "        file_suffixes = filename.suffixes\n",
    "        if file_suffixes[-1].lower() in ['.xlsx', '.csv']:\n",
    "            try:\n",
    "                export_time = os.path.getmtime(filename)\n",
    "                export_time_datetime = convert_to_datetime(time.localtime(export_time))\n",
    "                file_name = filename.stem\n",
    "\n",
    "                if file_suffixes[-1].lower() == '.xlsx':\n",
    "                    df = pl.read_excel(filename)\n",
    "                else:\n",
    "                    df = pl.read_csv(filename)\n",
    "\n",
    "                df = df.with_columns([\n",
    "                    pl.lit(file_name).alias('sheet_name'),\n",
    "                    pl.lit(export_time_datetime).alias('Export time')\n",
    "                ])\n",
    "\n",
    "                list_files.append(df)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {filename}: {e}\")\n",
    "\n",
    "    if list_files:\n",
    "        list_files = unify_dtypes(list_files)\n",
    "        df_list = pl.concat(list_files)\n",
    "        return df_list\n",
    "    else:\n",
    "        return pl.DataFrame()\n",
    "\n",
    "    \n",
    "def create_datetime(row, time_column, shift_column=None):\n",
    "    if row['Scheduled'] == 0:\n",
    "        return pd.NaT\n",
    "    if pd.isnull(row['Date']) or pd.isnull(row[time_column]):\n",
    "        return pd.NaT\n",
    "    time_value = row[time_column]\n",
    "    if shift_column and pd.isnull(row[shift_column]):\n",
    "        return pd.NaT\n",
    "    if shift_column and time_value < row[shift_column]:\n",
    "        return pd.Timestamp.combine(row['Date'], time_value) + pd.DateOffset(days=1)\n",
    "    return pd.Timestamp.combine(row['Date'], time_value)\n",
    "\n",
    "def convert_to_time(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = pd.to_datetime(df[column], format='%I:%M %p', errors='coerce').dt.time\n",
    "    return df\n",
    "\n",
    "def combine_date_and_time(row, time_column):\n",
    "    return pd.to_datetime(f\"{row['Date'].date()} {row[time_column]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_glob_1 = \"C:/Users/huuchinh.nguyen\"\n",
    "first_glob_2 = \"C:/Users/ADMIN\"\n",
    "\n",
    "if os.path.exists(first_glob_1):\n",
    "    first_glob = first_glob_1\n",
    "elif os.path.exists(first_glob_2):\n",
    "    first_glob = first_glob_2\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Neither {first_glob_1} nor {first_glob_2} exists.\")\n",
    "\n",
    "folder_paths = {\n",
    "    \"input_iex\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Rawdata/INPUT_AGENT_IEX_FOR_REPORT',\n",
    "    \"input_hc_master\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Headcount/HC Master Database - 2025.xlsx',\n",
    "    \"output_iex\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Rawdata/OUTPUT_AGENT_IEX_FOR_REPORT',\n",
    "    \"output_iex_intervals\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Rawdata/OUTPUT_AGENT_IEX_INTERVALS',\n",
    "    \"hc_extend_by_month\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Headcount/HC Extend by Month'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not determine dtype for column 7, falling back to string\n",
      "Could not determine dtype for column 8, falling back to string\n",
      "Could not determine dtype for column 7, falling back to string\n",
      "Could not determine dtype for column 8, falling back to string\n",
      "Could not determine dtype for column 7, falling back to string\n",
      "Could not determine dtype for column 8, falling back to string\n",
      "Could not determine dtype for column 7, falling back to string\n",
      "Could not determine dtype for column 8, falling back to string\n",
      "Could not determine dtype for column 7, falling back to string\n",
      "Could not determine dtype for column 8, falling back to string\n",
      "Could not determine dtype for column 7, falling back to string\n",
      "Could not determine dtype for column 8, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 46, falling back to string\n",
      "Could not determine dtype for column 48, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 48, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 48, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n"
     ]
    }
   ],
   "source": [
    "IEX_Input = input_data(folder_paths[\"input_iex\"])\n",
    "\n",
    "IEX_Input = IEX_Input.to_pandas()\n",
    "\n",
    "HC_MASTER_DATABASE = input_data(folder_paths[\"hc_extend_by_month\"])\n",
    "HC_MASTER_DATABASE = HC_MASTER_DATABASE.to_pandas()\n",
    "HC_MASTER_DATABASE = HC_MASTER_DATABASE.rename(columns={'IEX ID': 'IEX_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18108\\3870183097.py:19: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  IEX['Generate Date'] = IEX['Generate Date'].fillna(method='bfill')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18108\\3870183097.py:21: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  IEX_edit['Agent'] = IEX_edit['Agent'].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent</th>\n",
       "      <th>Date</th>\n",
       "      <th>Start_Shift</th>\n",
       "      <th>End_Shift</th>\n",
       "      <th>Scheduled Activity</th>\n",
       "      <th>Start_Action</th>\n",
       "      <th>End_Action</th>\n",
       "      <th>sheet_name</th>\n",
       "      <th>Export time</th>\n",
       "      <th>Generate Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agent: 3052306 BUI, BADUONG</td>\n",
       "      <td>5/12/25</td>\n",
       "      <td>7:00 AM</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>7:00 AM</td>\n",
       "      <td>9:45 AM</td>\n",
       "      <td>VNM_12_May_18_May_2025</td>\n",
       "      <td>2025-05-20 11:55:27</td>\n",
       "      <td>5/20/25 4:54 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Agent: 3052306 BUI, BADUONG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Break</td>\n",
       "      <td>9:45 AM</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>VNM_12_May_18_May_2025</td>\n",
       "      <td>2025-05-20 11:55:27</td>\n",
       "      <td>5/20/25 4:54 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Agent: 3052306 BUI, BADUONG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>12:40 PM</td>\n",
       "      <td>VNM_12_May_18_May_2025</td>\n",
       "      <td>2025-05-20 11:55:27</td>\n",
       "      <td>5/20/25 4:54 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Agent: 3052306 BUI, BADUONG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>12:40 PM</td>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>VNM_12_May_18_May_2025</td>\n",
       "      <td>2025-05-20 11:55:27</td>\n",
       "      <td>5/20/25 4:54 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Agent: 3052306 BUI, BADUONG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>2:40 PM</td>\n",
       "      <td>VNM_12_May_18_May_2025</td>\n",
       "      <td>2025-05-20 11:55:27</td>\n",
       "      <td>5/20/25 4:54 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42459</th>\n",
       "      <td>Agent: 3089155 Vuu, TienNhan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>8:45 AM</td>\n",
       "      <td>11:25 AM</td>\n",
       "      <td>VNM_9_June_15_Jun_2025</td>\n",
       "      <td>2025-06-14 11:30:46</td>\n",
       "      <td>6/14/25 4:29 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42460</th>\n",
       "      <td>Agent: 3089155 Vuu, TienNhan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>11:25 AM</td>\n",
       "      <td>12:25 PM</td>\n",
       "      <td>VNM_9_June_15_Jun_2025</td>\n",
       "      <td>2025-06-14 11:30:46</td>\n",
       "      <td>6/14/25 4:29 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42461</th>\n",
       "      <td>Agent: 3089155 Vuu, TienNhan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>12:25 PM</td>\n",
       "      <td>1:25 PM</td>\n",
       "      <td>VNM_9_June_15_Jun_2025</td>\n",
       "      <td>2025-06-14 11:30:46</td>\n",
       "      <td>6/14/25 4:29 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42462</th>\n",
       "      <td>Agent: 3089155 Vuu, TienNhan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Break</td>\n",
       "      <td>1:25 PM</td>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>VNM_9_June_15_Jun_2025</td>\n",
       "      <td>2025-06-14 11:30:46</td>\n",
       "      <td>6/14/25 4:29 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42463</th>\n",
       "      <td>Agent: 3089155 Vuu, TienNhan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>3:00 PM</td>\n",
       "      <td>VNM_9_June_15_Jun_2025</td>\n",
       "      <td>2025-06-14 11:30:46</td>\n",
       "      <td>6/14/25 4:29 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36097 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Agent     Date Start_Shift End_Shift  \\\n",
       "4       Agent: 3052306 BUI, BADUONG  5/12/25     7:00 AM   4:00 PM   \n",
       "5       Agent: 3052306 BUI, BADUONG     None        None      None   \n",
       "6       Agent: 3052306 BUI, BADUONG     None        None      None   \n",
       "7       Agent: 3052306 BUI, BADUONG     None        None      None   \n",
       "8       Agent: 3052306 BUI, BADUONG     None        None      None   \n",
       "...                             ...      ...         ...       ...   \n",
       "42459  Agent: 3089155 Vuu, TienNhan     None        None      None   \n",
       "42460  Agent: 3089155 Vuu, TienNhan     None        None      None   \n",
       "42461  Agent: 3089155 Vuu, TienNhan     None        None      None   \n",
       "42462  Agent: 3089155 Vuu, TienNhan     None        None      None   \n",
       "42463  Agent: 3089155 Vuu, TienNhan     None        None      None   \n",
       "\n",
       "      Scheduled Activity Start_Action End_Action              sheet_name  \\\n",
       "4              Open Time      7:00 AM    9:45 AM  VNM_12_May_18_May_2025   \n",
       "5                  Break      9:45 AM   10:00 AM  VNM_12_May_18_May_2025   \n",
       "6              Open Time     10:00 AM   12:40 PM  VNM_12_May_18_May_2025   \n",
       "7                  Lunch     12:40 PM    1:40 PM  VNM_12_May_18_May_2025   \n",
       "8              Open Time      1:40 PM    2:40 PM  VNM_12_May_18_May_2025   \n",
       "...                  ...          ...        ...                     ...   \n",
       "42459          Open Time      8:45 AM   11:25 AM  VNM_9_June_15_Jun_2025   \n",
       "42460              Lunch     11:25 AM   12:25 PM  VNM_9_June_15_Jun_2025   \n",
       "42461          Open Time     12:25 PM    1:25 PM  VNM_9_June_15_Jun_2025   \n",
       "42462              Break      1:25 PM    1:40 PM  VNM_9_June_15_Jun_2025   \n",
       "42463          Open Time      1:40 PM    3:00 PM  VNM_9_June_15_Jun_2025   \n",
       "\n",
       "              Export time    Generate Date  \n",
       "4     2025-05-20 11:55:27  5/20/25 4:54 AM  \n",
       "5     2025-05-20 11:55:27  5/20/25 4:54 AM  \n",
       "6     2025-05-20 11:55:27  5/20/25 4:54 AM  \n",
       "7     2025-05-20 11:55:27  5/20/25 4:54 AM  \n",
       "8     2025-05-20 11:55:27  5/20/25 4:54 AM  \n",
       "...                   ...              ...  \n",
       "42459 2025-06-14 11:30:46  6/14/25 4:29 AM  \n",
       "42460 2025-06-14 11:30:46  6/14/25 4:29 AM  \n",
       "42461 2025-06-14 11:30:46  6/14/25 4:29 AM  \n",
       "42462 2025-06-14 11:30:46  6/14/25 4:29 AM  \n",
       "42463 2025-06-14 11:30:46  6/14/25 4:29 AM  \n",
       "\n",
       "[36097 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove = [\"__UNNAMED__4\"]\n",
    "\n",
    "IEX = IEX_Input[[col for col in IEX_Input.columns if col not in columns_to_remove]]\n",
    "IEX = IEX.rename(columns={\n",
    "    \"Agent Schedules\": \"Agent\",\n",
    "    \"__UNNAMED__1\": \"Date\",\n",
    "    \"__UNNAMED__2\": \"Start_Shift\",\n",
    "    \"__UNNAMED__3\": \"End_Shift\",\n",
    "    \"__UNNAMED__5\": \"Scheduled Activity\",\n",
    "    \"__UNNAMED__6\": \"Start_Action\",\n",
    "    \"__UNNAMED__9\": \"End_Action\"\n",
    "})\n",
    "\n",
    "IEX['Generate Date'] = np.where(\n",
    "    IEX['Agent'].str.contains(\"Generation Date: \", na=False),\n",
    "    IEX['Agent'].str.extract(r'Generation Date: (.+)')[0],\n",
    "    np.nan\n",
    ")\n",
    "IEX['Generate Date'] = IEX['Generate Date'].fillna(method='bfill')\n",
    "IEX_edit = IEX.copy()\n",
    "IEX_edit['Agent'] = IEX_edit['Agent'].fillna(method='ffill')\n",
    "offTable_save = IEX_edit\n",
    "IEX_edit = IEX_edit[(IEX_edit['Start_Shift'] != \"Off\") & (IEX_edit['Date'] != \"Date\")]\n",
    "IEX_edit = IEX_edit[~(IEX_edit['Date'].isna() & IEX_edit['Scheduled Activity'].isna())]\n",
    "IEX_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18108\\1879448329.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  IEX_edit[['Date', 'Start_Shift', 'End_Shift']] = IEX_edit[['Date', 'Start_Shift', 'End_Shift']].fillna(method='ffill')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18108\\1879448329.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  offTable['Start_Shift'] = offTable['Start_Shift'].replace('Off', np.nan)\n"
     ]
    }
   ],
   "source": [
    "offTable = offTable_save[offTable_save['Start_Shift'] == \"Off\"].reset_index(drop=True)\n",
    "\n",
    "condition = (IEX_edit['Date'] != \"Date\") & (IEX_edit['Start_Shift'] != \"Off\")\n",
    "IEX_edit = IEX_edit[condition].reset_index(drop=True)\n",
    "IEX_edit[['Date', 'Start_Shift', 'End_Shift']] = IEX_edit[['Date', 'Start_Shift', 'End_Shift']].fillna(method='ffill')\n",
    "\n",
    "condition2 = (IEX_edit['Agent'].str.contains(\"Agent: \", na=False)) | (IEX_edit['Agent'].isna())\n",
    "IEX_edit = IEX_edit[condition2].reset_index(drop=True)\n",
    "\n",
    "offTable['Scheduled Activity'] = offTable['Scheduled Activity'].fillna(offTable['Start_Shift'])\n",
    "offTable['Start_Shift'] = offTable['Start_Shift'].replace('Off', np.nan)\n",
    "\n",
    "IEX_edit = IEX_edit[IEX_edit['Scheduled Activity'].notna()].reset_index(drop=True)\n",
    "combined_df = pd.concat([offTable, IEX_edit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18108\\48420382.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_df['Generate Date'] = pd.to_datetime(combined_df['Generate Date'], errors='coerce')\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18108\\48420382.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "combined_df['Export time'] = pd.to_datetime(combined_df['Export time'], errors='coerce')\n",
    "combined_df['Generate Date'] = pd.to_datetime(combined_df['Generate Date'], errors='coerce')\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
    "combined_df['Year'] = combined_df['Date'].dt.year\n",
    "combined_df['Month'] = combined_df['Date'].dt.strftime('%b-%y')\n",
    "combined_df['IEX_ID'] = combined_df['Agent'].str.extract(r'(\\d+)', expand=False).astype(int)\n",
    "\n",
    "max_generate_date_df = combined_df.groupby(['IEX_ID','Date'])['Generate Date'].max().reset_index()\n",
    "max_generate_date_df = max_generate_date_df.rename(columns={'Generate Date': 'Max Generate Date'})\n",
    "\n",
    "max_generate_date_with_details = pd.merge(combined_df, max_generate_date_df, on=['Date','IEX_ID'], how='left')\n",
    "filtered_max_generate_date = max_generate_date_with_details[max_generate_date_with_details['Generate Date'] == max_generate_date_with_details['Max Generate Date']]\n",
    "\n",
    "filtered_max_generate_date['Scheduled'] = filtered_max_generate_date.groupby(['Date', 'IEX_ID'])['Scheduled Activity'].transform(lambda x: 1 if any(x.isin(['Open Time', 'Extra Hours', 'No Call/No Show', 'PTO', 'Training Offline', 'Sick Leave', 'Paid Leave', 'Termination', 'Off Phone Misc','Billable Training'])) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_columns = ['Start_Shift', 'End_Shift', 'Start_Action', 'End_Action']\n",
    "filtered_max_generate_date = convert_to_time(filtered_max_generate_date, time_columns)\n",
    "\n",
    "# filtered_max_generate_date = filtered_max_generate_date.drop(filtered_max_generate_date[(filtered_max_generate_date['Scheduled Activity'].isin(['Lunch', 'Break','Training'])) & (filtered_max_generate_date['Scheduled'] == 0)].index)\n",
    "\n",
    "filtered_max_generate_date['Datetime_Start_Action'] = filtered_max_generate_date.apply(lambda row: create_datetime(row, 'Start_Action', 'Start_Shift'), axis=1)\n",
    "filtered_max_generate_date['Datetime_End_Action'] = filtered_max_generate_date.apply(lambda row: create_datetime(row, 'End_Action', 'Start_Shift'), axis=1)\n",
    "\n",
    "filtered_fluctuate_shifts = filtered_max_generate_date[\n",
    "    filtered_max_generate_date['Scheduled Activity'].isin([\"Open Time\", \"Extra Hours\"]) | \n",
    "    filtered_max_generate_date['Scheduled Activity'].str.contains(\"Training\", na=False)\n",
    "]\n",
    "min_max_fluctuate_shifts = filtered_fluctuate_shifts.groupby(['Date', 'IEX_ID']).agg(\n",
    "    Datetime_Fluctuate_Start_Shift=('Datetime_Start_Action', 'min'),\n",
    "    Datetime_Fluctuate_End_Shift=('Datetime_End_Action', 'max')\n",
    ").reset_index()\n",
    "min_max_fluctuate_shifts['Fluctuate Shift'] = (min_max_fluctuate_shifts['Datetime_Fluctuate_Start_Shift'].dt.strftime('%H%M') + '-' + min_max_fluctuate_shifts['Datetime_Fluctuate_End_Shift'].dt.strftime('%H%M'))\n",
    "new_table_with_fluctuate_shifts_col = pd.merge(filtered_max_generate_date, min_max_fluctuate_shifts, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "min_max_first_shifts = filtered_max_generate_date.groupby(['Date', 'IEX_ID']).agg(\n",
    "    Datetime_First_Start_Shift=('Datetime_Start_Action', 'min'),\n",
    "    Datetime_First_End_Shift=('Datetime_End_Action', 'max')\n",
    ").reset_index()\n",
    "min_max_first_shifts['First Shift'] = (min_max_first_shifts['Datetime_First_Start_Shift'].dt.strftime('%H%M') + '-' + min_max_first_shifts['Datetime_First_End_Shift'].dt.strftime('%H%M'))\n",
    "new_table_with_first_shifts_col = pd.merge(new_table_with_fluctuate_shifts_col, min_max_first_shifts, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "filtered_original_shifts = filtered_max_generate_date[\n",
    "    filtered_max_generate_date['Scheduled Activity'].isin([\"Open Time\"]) | \n",
    "    filtered_max_generate_date['Scheduled Activity'].str.contains(\"Training\", na=False)\n",
    "]\n",
    "min_max_original_shifts = filtered_original_shifts.groupby(['Date', 'IEX_ID']).agg(\n",
    "    Datetime_Original_Start_Shift=('Datetime_Start_Action', 'min'),\n",
    "    Datetime_Original_End_Shift=('Datetime_End_Action', 'max')\n",
    ").reset_index()\n",
    "min_max_original_shifts['Original Shift'] = (min_max_original_shifts['Datetime_Original_Start_Shift'].dt.strftime('%H%M') + '-' + min_max_original_shifts['Datetime_Original_End_Shift'].dt.strftime('%H%M'))\n",
    "new_table_with_original_shifts_col = pd.merge(new_table_with_first_shifts_col, min_max_original_shifts, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "new_table_with_original_shifts_col = new_table_with_original_shifts_col[\n",
    "    ~(\n",
    "        (new_table_with_original_shifts_col['Scheduled Activity'].isin([\"Lunch\", \"Break\"])) & \n",
    "        new_table_with_original_shifts_col['Fluctuate Shift'].isna()\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_generate_date = new_table_with_original_shifts_col.sort_values(by='Export time', ascending=True)\n",
    "\n",
    "sorted_generate_date['Night_Shift'] = sorted_generate_date['Datetime_First_Start_Shift'].apply(lambda x: 1 if pd.to_datetime(x).hour >= 15 else 0)\n",
    "sorted_generate_date['Week_Monday'] = sorted_generate_date['Date'] - pd.to_timedelta(sorted_generate_date['Date'].dt.weekday, unit='d')\n",
    "sorted_generate_date['Week Begin'] = sorted_generate_date['Week_Monday'].dt.strftime('WB%d%m')\n",
    "sorted_generate_date['Agent Name'] = sorted_generate_date['Agent'].str.extract(r'\\d+ (.+)', expand=False).str.upper()\n",
    "sorted_generate_date['Duration'] = (sorted_generate_date['Datetime_End_Action'] - sorted_generate_date['Datetime_Start_Action']).dt.total_seconds()\n",
    "\n",
    "def calculate_total_time(df, activity_list, time_column_name):\n",
    "    time_totals = df[df['Scheduled Activity'].isin(activity_list)]\n",
    "    time_totals = time_totals.groupby(['Date', 'IEX_ID'])['Duration'].sum().reset_index()\n",
    "    time_totals.rename(columns={'Duration': time_column_name}, inplace=True)\n",
    "    time_totals[time_column_name] = time_totals[time_column_name] / 3600\n",
    "    return time_totals\n",
    "\n",
    "sorted_generate_date = sorted_generate_date.drop_duplicates()\n",
    "\n",
    "activities = {\n",
    "    'Open Time': 'Open Time',\n",
    "    'Break': 'Break Time',\n",
    "    'Lunch': 'Lunch Time',\n",
    "    'Extra Hours': 'Extra Time',\n",
    "    'No Call/No Show': 'NCNS',\n",
    "    'Training Offline': 'Training',\n",
    "    'Training': 'Training',\n",
    "    'Training Nesting': 'Training',\n",
    "    'PTO':'AL'\n",
    "}\n",
    "training_activities = ['Training Offline', 'Training', 'Training Nesting']\n",
    "time_totals_training = calculate_total_time(sorted_generate_date, training_activities, 'Training')\n",
    "sorted_generate_date = sorted_generate_date.merge(time_totals_training, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "for activity, column_name in activities.items():\n",
    "    if activity not in training_activities:\n",
    "        time_totals = calculate_total_time(sorted_generate_date, [activity], column_name)\n",
    "        sorted_generate_date = sorted_generate_date.merge(time_totals, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "sorted_generate_date['Target'] = sorted_generate_date.apply(\n",
    "    lambda row: row['Open Time'] if pd.isnull(row['Extra Time']) else\n",
    "                 row['Extra Time'] if pd.isnull(row['Open Time']) else\n",
    "                 row['Open Time'] + row['Extra Time'],axis=1)\n",
    "\n",
    "sorted_generate_date['Time_Of_Day'] = ((sorted_generate_date['Datetime_First_End_Shift'] - sorted_generate_date['Datetime_First_Start_Shift']).dt.total_seconds())/3600\n",
    "sorted_generate_date = sorted_generate_date.sort_values(by=['Date', 'IEX_ID', 'Datetime_Start_Action'], na_position='last')\n",
    "sorted_generate_date['First_Scheduled_Activity'] = sorted_generate_date.groupby(['Date', 'IEX_ID'])['Scheduled Activity'].transform('first')\n",
    "\n",
    "conditions = [\n",
    "    ((sorted_generate_date['Open Time'] > 0) & (sorted_generate_date['NCNS'] > 3)) | (sorted_generate_date['NCNS'] <= 5),\n",
    "    ((sorted_generate_date['Open Time'] > 0) | (sorted_generate_date['Open Time'].isna())) & (sorted_generate_date['NCNS'] > 5),\n",
    "    (sorted_generate_date['Open Time'] > 0) & (sorted_generate_date['Extra Time'] > 0),\n",
    "    (sorted_generate_date['Open Time'] == 0) & (sorted_generate_date['Extra Time'] > 0),\n",
    "    (sorted_generate_date['Open Time'] > 0),\n",
    "    (sorted_generate_date['First_Scheduled_Activity'] == \"Extra Hours\") & (sorted_generate_date['Open Time'].isna()),\n",
    "    sorted_generate_date['First_Scheduled_Activity'].isin([\"Holiday\", \"Bereavement\", \"Off\", \"Off Phone Misc\", \"Termination\", \"Unscheduled\"]),\n",
    "    (sorted_generate_date['First_Scheduled_Activity'] == \"PTO\"),\n",
    "    ((sorted_generate_date['First_Scheduled_Activity'] == \"Sickness\") | (sorted_generate_date['First_Scheduled_Activity'] == \"Sick Leave\")),\n",
    "    sorted_generate_date['First_Scheduled_Activity'].isin([\"Training Offline\"]),\n",
    "    sorted_generate_date['First_Scheduled_Activity'].isin([\"Paid Leave\"]),\n",
    "    sorted_generate_date['First_Scheduled_Activity'].isin([\"Leave\"]),\n",
    "    sorted_generate_date['First_Scheduled_Activity'].isin([\"Termination\"]),\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    \"HDL\",\n",
    "    \"NCNS\",\n",
    "    \"PR - OT\",\n",
    "    \"PO\",\n",
    "    \"PR\",\n",
    "    \"PO\",\n",
    "    sorted_generate_date['First_Scheduled_Activity'],\n",
    "    \"AL\",\n",
    "    \"SL\",\n",
    "    \"Training Offline\",\n",
    "    \"CO\",\n",
    "    \"LWP\",\n",
    "    \"Termination\"\n",
    "]\n",
    "\n",
    "sorted_generate_date['Shift Tracking'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "sorted_generate_date['Fluctuate Shift'] = np.where(sorted_generate_date['Time_Of_Day'].isnull(), sorted_generate_date['Scheduled Activity'], sorted_generate_date['Fluctuate Shift'])\n",
    "sorted_generate_date['First Shift'] = np.where(sorted_generate_date['Time_Of_Day'].isnull(), sorted_generate_date['Scheduled Activity'], sorted_generate_date['First Shift'])\n",
    "\n",
    "ot_range_tracker = sorted_generate_date\n",
    "\n",
    "ot_range_tracker['OT Range'] = ot_range_tracker.apply(\n",
    "    lambda row: row['Fluctuate Shift'] if row['Shift Tracking'] == 'PO' else (\n",
    "        f\"{row['Datetime_Start_Action'].strftime('%H%M')}-{row['Datetime_End_Action'].strftime('%H%M')}\" \n",
    "        if row['Scheduled Activity'] == 'Extra Hours' else None\n",
    "    ), axis=1)\n",
    "\n",
    "def combine_ot_range(group):\n",
    "    non_null_ot_range = [val for val in group if val is not None and val != \"\"]\n",
    "    distinct_ot_range = list(set(non_null_ot_range))\n",
    "    return \",\".join(distinct_ot_range) if distinct_ot_range else None\n",
    "\n",
    "ot_range_tracker['Combined OT Range'] = (ot_range_tracker.groupby(['Date', 'IEX_ID'])['OT Range'].transform(combine_ot_range))\n",
    "ot_range_tracker = ot_range_tracker[['Date','IEX_ID','Combined OT Range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent</th>\n",
       "      <th>Date</th>\n",
       "      <th>Start_Shift</th>\n",
       "      <th>End_Shift</th>\n",
       "      <th>Scheduled Activity</th>\n",
       "      <th>Start_Action</th>\n",
       "      <th>End_Action</th>\n",
       "      <th>sheet_name</th>\n",
       "      <th>Export time</th>\n",
       "      <th>Generate Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Target</th>\n",
       "      <th>Time_Of_Day</th>\n",
       "      <th>First_Scheduled_Activity</th>\n",
       "      <th>Shift Tracking</th>\n",
       "      <th>OT Range</th>\n",
       "      <th>Combined OT Range</th>\n",
       "      <th>OT PreShift</th>\n",
       "      <th>OT PostShift</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent: 3000182 HOANG, THIPHUONGHOA</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>22:15:00</td>\n",
       "      <td>VNM_5_May_11_May_2025</td>\n",
       "      <td>2025-05-14 06:37:10</td>\n",
       "      <td>2025-05-13 23:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agent: 3000182 HOANG, THIPHUONGHOA</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Break</td>\n",
       "      <td>22:15:00</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>VNM_5_May_11_May_2025</td>\n",
       "      <td>2025-05-14 06:37:10</td>\n",
       "      <td>2025-05-13 23:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agent: 3000182 HOANG, THIPHUONGHOA</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>VNM_5_May_11_May_2025</td>\n",
       "      <td>2025-05-14 06:37:10</td>\n",
       "      <td>2025-05-13 23:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agent: 3000182 HOANG, THIPHUONGHOA</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>02:30:00</td>\n",
       "      <td>VNM_5_May_11_May_2025</td>\n",
       "      <td>2025-05-14 06:37:10</td>\n",
       "      <td>2025-05-13 23:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>2025-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agent: 3000182 HOANG, THIPHUONGHOA</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>02:30:00</td>\n",
       "      <td>03:45:00</td>\n",
       "      <td>VNM_5_May_11_May_2025</td>\n",
       "      <td>2025-05-14 06:37:10</td>\n",
       "      <td>2025-05-13 23:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>2025-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31852</th>\n",
       "      <td>Agent: 3097238 Nguyen, LamNgocLong</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>VNM_2_June_8_Jun_2025</td>\n",
       "      <td>2025-06-08 12:01:59</td>\n",
       "      <td>2025-06-08 05:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>2025-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31853</th>\n",
       "      <td>Agent: 3097238 Nguyen, LamNgocLong</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>03:25:00</td>\n",
       "      <td>VNM_2_June_8_Jun_2025</td>\n",
       "      <td>2025-06-08 12:01:59</td>\n",
       "      <td>2025-06-08 05:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>2025-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31854</th>\n",
       "      <td>Agent: 3097238 Nguyen, LamNgocLong</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>Break</td>\n",
       "      <td>03:25:00</td>\n",
       "      <td>03:40:00</td>\n",
       "      <td>VNM_2_June_8_Jun_2025</td>\n",
       "      <td>2025-06-08 12:01:59</td>\n",
       "      <td>2025-06-08 05:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>2025-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31855</th>\n",
       "      <td>Agent: 3097238 Nguyen, LamNgocLong</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>03:40:00</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>VNM_2_June_8_Jun_2025</td>\n",
       "      <td>2025-06-08 12:01:59</td>\n",
       "      <td>2025-06-08 05:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>PR</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>2025-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31856</th>\n",
       "      <td>Agent: 3097284 Nguyen, MinhNhat</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Off</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>VNM_2_June_8_Jun_2025</td>\n",
       "      <td>2025-06-08 12:01:59</td>\n",
       "      <td>2025-06-08 05:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off</td>\n",
       "      <td>Off</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31857 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Agent       Date Start_Shift End_Shift  \\\n",
       "0      Agent: 3000182 HOANG, THIPHUONGHOA 2025-05-05    21:00:00  06:00:00   \n",
       "1      Agent: 3000182 HOANG, THIPHUONGHOA 2025-05-05    21:00:00  06:00:00   \n",
       "2      Agent: 3000182 HOANG, THIPHUONGHOA 2025-05-05    21:00:00  06:00:00   \n",
       "3      Agent: 3000182 HOANG, THIPHUONGHOA 2025-05-05    21:00:00  06:00:00   \n",
       "4      Agent: 3000182 HOANG, THIPHUONGHOA 2025-05-05    21:00:00  06:00:00   \n",
       "...                                   ...        ...         ...       ...   \n",
       "31852  Agent: 3097238 Nguyen, LamNgocLong 2025-06-08    20:00:00  05:00:00   \n",
       "31853  Agent: 3097238 Nguyen, LamNgocLong 2025-06-08    20:00:00  05:00:00   \n",
       "31854  Agent: 3097238 Nguyen, LamNgocLong 2025-06-08    20:00:00  05:00:00   \n",
       "31855  Agent: 3097238 Nguyen, LamNgocLong 2025-06-08    20:00:00  05:00:00   \n",
       "31856     Agent: 3097284 Nguyen, MinhNhat 2025-06-08         NaT       NaT   \n",
       "\n",
       "      Scheduled Activity Start_Action End_Action             sheet_name  \\\n",
       "0              Open Time     21:00:00   22:15:00  VNM_5_May_11_May_2025   \n",
       "1                  Break     22:15:00   22:30:00  VNM_5_May_11_May_2025   \n",
       "2              Open Time     22:30:00   01:30:00  VNM_5_May_11_May_2025   \n",
       "3                  Lunch     01:30:00   02:30:00  VNM_5_May_11_May_2025   \n",
       "4              Open Time     02:30:00   03:45:00  VNM_5_May_11_May_2025   \n",
       "...                  ...          ...        ...                    ...   \n",
       "31852              Lunch     00:00:00   01:00:00  VNM_2_June_8_Jun_2025   \n",
       "31853          Open Time     01:00:00   03:25:00  VNM_2_June_8_Jun_2025   \n",
       "31854              Break     03:25:00   03:40:00  VNM_2_June_8_Jun_2025   \n",
       "31855          Open Time     03:40:00   05:00:00  VNM_2_June_8_Jun_2025   \n",
       "31856                Off          NaT        NaT  VNM_2_June_8_Jun_2025   \n",
       "\n",
       "              Export time       Generate Date  ...  Target Time_Of_Day  \\\n",
       "0     2025-05-14 06:37:10 2025-05-13 23:35:00  ...     7.5         9.0   \n",
       "1     2025-05-14 06:37:10 2025-05-13 23:35:00  ...     7.5         9.0   \n",
       "2     2025-05-14 06:37:10 2025-05-13 23:35:00  ...     7.5         9.0   \n",
       "3     2025-05-14 06:37:10 2025-05-13 23:35:00  ...     7.5         9.0   \n",
       "4     2025-05-14 06:37:10 2025-05-13 23:35:00  ...     7.5         9.0   \n",
       "...                   ...                 ...  ...     ...         ...   \n",
       "31852 2025-06-08 12:01:59 2025-06-08 05:01:00  ...     7.5         9.0   \n",
       "31853 2025-06-08 12:01:59 2025-06-08 05:01:00  ...     7.5         9.0   \n",
       "31854 2025-06-08 12:01:59 2025-06-08 05:01:00  ...     7.5         9.0   \n",
       "31855 2025-06-08 12:01:59 2025-06-08 05:01:00  ...     7.5         9.0   \n",
       "31856 2025-06-08 12:01:59 2025-06-08 05:01:00  ...     NaN         NaN   \n",
       "\n",
       "       First_Scheduled_Activity Shift Tracking  OT Range Combined OT Range  \\\n",
       "0                     Open Time             PR      None               NaN   \n",
       "1                     Open Time             PR      None               NaN   \n",
       "2                     Open Time             PR      None               NaN   \n",
       "3                     Open Time             PR      None               NaN   \n",
       "4                     Open Time             PR      None               NaN   \n",
       "...                         ...            ...       ...               ...   \n",
       "31852                 Open Time             PR      None               NaN   \n",
       "31853                 Open Time             PR      None               NaN   \n",
       "31854                 Open Time             PR      None               NaN   \n",
       "31855                 Open Time             PR      None               NaN   \n",
       "31856                       Off            Off      None               NaN   \n",
       "\n",
       "      OT PreShift OT PostShift Start Date   End Date  \n",
       "0             0.0          0.0 2025-05-05 2025-05-05  \n",
       "1             0.0          0.0 2025-05-05 2025-05-05  \n",
       "2             0.0          0.0 2025-05-05 2025-05-06  \n",
       "3             0.0          0.0 2025-05-06 2025-05-06  \n",
       "4             0.0          0.0 2025-05-06 2025-05-06  \n",
       "...           ...          ...        ...        ...  \n",
       "31852         0.0          0.0 2025-06-09 2025-06-09  \n",
       "31853         0.0          0.0 2025-06-09 2025-06-09  \n",
       "31854         0.0          0.0 2025-06-09 2025-06-09  \n",
       "31855         0.0          0.0 2025-06-09 2025-06-09  \n",
       "31856         0.0          0.0        NaT        NaT  \n",
       "\n",
       "[31857 rows x 48 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_ot_pre_post_shift(df):\n",
    "    extra_hours_df = df[df['Scheduled Activity'] == 'Extra Hours']\n",
    "    \n",
    "    ot_df = df[['Date', 'IEX_ID']].drop_duplicates()\n",
    "    \n",
    "    def calculate_duration_for_group(group_df, date, iex_id, shift_start, shift_end):\n",
    "        pre_shift_duration = extra_hours_df[\n",
    "            (extra_hours_df['Date'] == date) & \n",
    "            (extra_hours_df['IEX_ID'] == iex_id) & \n",
    "            (extra_hours_df['Datetime_Start_Action'] < shift_start)\n",
    "        ]['Duration'].sum()\n",
    "        \n",
    "        post_shift_duration = extra_hours_df[\n",
    "            (extra_hours_df['Date'] == date) & \n",
    "            (extra_hours_df['IEX_ID'] == iex_id) & \n",
    "            (extra_hours_df['Datetime_End_Action'] > shift_end)\n",
    "        ]['Duration'].sum()\n",
    "        \n",
    "        return pre_shift_duration, post_shift_duration\n",
    "    \n",
    "    ot_df[['OT PreShift Seconds', 'OT PostShift Seconds']] = ot_df.apply(\n",
    "        lambda row: pd.Series(\n",
    "            calculate_duration_for_group(\n",
    "                extra_hours_df, \n",
    "                row['Date'], \n",
    "                row['IEX_ID'], \n",
    "                df[(df['Date'] == row['Date']) & (df['IEX_ID'] == row['IEX_ID'])]['Datetime_Original_Start_Shift'].min(),\n",
    "                df[(df['Date'] == row['Date']) & (df['IEX_ID'] == row['IEX_ID'])]['Datetime_Original_End_Shift'].max()\n",
    "            )\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "    ot_df['OT PreShift'] = ot_df['OT PreShift Seconds'] / 3600\n",
    "    ot_df['OT PostShift'] = ot_df['OT PostShift Seconds'] / 3600\n",
    "\n",
    "    ot_df = ot_df.drop(columns=['OT PreShift Seconds', 'OT PostShift Seconds'])\n",
    "    df = df.merge(ot_df, on=['Date', 'IEX_ID'], how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "OT_Pre_Post_Table = calculate_ot_pre_post_shift(sorted_generate_date)\n",
    "OT_Pre_Post_Table = OT_Pre_Post_Table.groupby(['Date', 'IEX_ID'])[['OT PreShift', 'OT PostShift']].max().reset_index()\n",
    "combine_OT_Pre_Post_Table = pd.merge(sorted_generate_date, OT_Pre_Post_Table, on=['Date','IEX_ID'], how='left')\n",
    "combine_OT_Pre_Post_Table['Start Date'] = pd.to_datetime(combine_OT_Pre_Post_Table['Datetime_Start_Action']).dt.normalize()\n",
    "combine_OT_Pre_Post_Table['End Date'] = pd.to_datetime(combine_OT_Pre_Post_Table['Datetime_End_Action']).dt.normalize()\n",
    "\n",
    "combine_OT_Pre_Post_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2603243299.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = sorted_df.groupby(['Date', 'IEX_ID']).apply(label_breaks)\n"
     ]
    }
   ],
   "source": [
    "iex_ids_with_max_export_time = combine_OT_Pre_Post_Table[['sheet_name', 'Generate Date','Year','Month','Week Begin','Week_Monday','Date','Start Date','End Date','Agent Name', 'IEX_ID','Datetime_Fluctuate_Start_Shift',\n",
    "       'Datetime_Fluctuate_End_Shift', 'Fluctuate Shift',\n",
    "       'Datetime_First_Start_Shift', 'Datetime_First_End_Shift',\n",
    "       'First Shift','Scheduled Activity','Datetime_Start_Action','Datetime_End_Action','Time_Of_Day','Duration','Open Time','Extra Time','Target','Break Time','Lunch Time','Training','NCNS','AL','Night_Shift', 'Scheduled','Shift Tracking','OT PreShift', 'OT PostShift','Combined OT Range']]\n",
    "iex_merged_with_HC = pd.merge(\n",
    "    iex_ids_with_max_export_time,\n",
    "    HC_MASTER_DATABASE[['Date','OracleID','People ID', 'IEX_ID','Employee Name','Email Id','Alias','LOB','LOB_2','LOB_3','Supervisor Name','Wave','Detail Status','Status']],\n",
    "    on=['Date','IEX_ID'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "sorted_df = iex_merged_with_HC.sort_values(by=[ 'Date','IEX_ID','Datetime_Start_Action'],ascending=[ True, True,True]).reset_index(drop=True)\n",
    "\n",
    "sorted_df = sorted_df.drop_duplicates()\n",
    "\n",
    "def label_breaks(group):\n",
    "    group.loc[group['Scheduled Activity'] == 'Break', 'Scheduled Activity'] = (\n",
    "        group['Scheduled Activity'] + '_' + (group['Scheduled Activity'].eq('Break').cumsum()).astype(str))\n",
    "    return group\n",
    "\n",
    "sorted_df = sorted_df.groupby(['Date', 'IEX_ID']).apply(label_breaks)\n",
    "sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "fill_zero = ['Time_Of_Day', 'Open Time', 'Extra Time', 'Target', 'Break Time', 'Lunch Time', 'Training', 'NCNS', 'AL', 'Night_Shift', 'OT PreShift', 'OT PostShift']\n",
    "sorted_df[fill_zero] = sorted_df[fill_zero].fillna(0)\n",
    "\n",
    "sorted_df['Roster Scheduled'] = sorted_df.apply(lambda x: 0.5 if (0 <= x['Time_Of_Day'] < 6) and (x['Scheduled'] == 1) else x['Scheduled'], axis=1)\n",
    "sorted_df['Roster Presented'] = sorted_df.apply(lambda x: 0.5 if 0 < (x['Open Time'] + x['Extra Time'] + x['Training']) < 6 else (0 if (x['Open Time'] + x['Extra Time'] + x['Training']) == 0 else 1),axis=1)\n",
    "\n",
    "sorted_df['Unplanned'] = None\n",
    "sorted_df['Unplanned'] = sorted_df.apply(lambda x: 0.5 if 0 < x['NCNS'] < 6 else (1 if x['NCNS'] >= 6 else None), axis=1)\n",
    "\n",
    "sorted_df['Planned'] = None\n",
    "sorted_df['Planned'] = sorted_df.apply(lambda x: 0.5 if 0 < x['AL'] < 6 else (1 if x['AL'] >= 6 else None), axis=1)\n",
    "\n",
    "fill_zero2 = ['Unplanned', 'Planned', 'Roster Presented', 'Roster Scheduled']\n",
    "sorted_df[fill_zero2] = sorted_df[fill_zero2].fillna(0)\n",
    "\n",
    "def determine_ot_type(row):\n",
    "    if row[\"Shift Tracking\"] == \"PO\": return \"OT - PO\"\n",
    "    elif row[\"Shift Tracking\"] == \"PR - OT\":\n",
    "        if (row[\"OT PreShift\"] > 0) and (row[\"OT PostShift\"] > 0): return \"OT - Pre/Post Shift\"\n",
    "        elif (row[\"OT PreShift\"] > 0): return \"OT - Pre Shift\"\n",
    "        elif (row[\"OT PostShift\"] > 0): return \"OT - Post Shift\"\n",
    "        else: return None\n",
    "    else: return \"No OT\"\n",
    "\n",
    "sorted_df[\"OT Type\"] = sorted_df.apply(determine_ot_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'Datetime_{col}_Action'].dt.hour + \\\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'{col}_Time_Hours'].round(2)\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'Datetime_{col}_Action'].dt.hour + \\\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'{col}_Time_Hours'].round(2)\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table['End_Time_Hours'] = split_table.apply(\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Half_Rounding'] = split_table[f'{col}_Time_Hours'].apply(\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Half_Rounding'] = split_table[f'{col}_Time_Hours'].apply(\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_19024\\2715543524.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table['Number_Split'] = split_table.apply(\n",
      "c:\\Users\\huuchinh.nguyen\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 nan 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n"
     ]
    }
   ],
   "source": [
    "split_table = sorted_df[['Year','Month','Week_Monday','Date','OracleID','People ID', 'IEX_ID', 'Employee Name','Email Id','Alias','LOB','LOB_3', 'Supervisor Name','Wave','Detail Status','Status','Start Date', 'End Date', 'Scheduled Activity', 'Datetime_Start_Action', 'Datetime_End_Action']]\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time_Hours'] = split_table[f'Datetime_{col}_Action'].dt.hour + \\\n",
    "                                       split_table[f'Datetime_{col}_Action'].dt.minute / 60 + \\\n",
    "                                        split_table[f'Datetime_{col}_Action'].dt.second / 3600\n",
    "    split_table[f'{col}_Time_Hours'] = split_table[f'{col}_Time_Hours'].round(2)\n",
    "\n",
    "split_table['End_Time_Hours'] = split_table.apply(\n",
    "    lambda row: row['End_Time_Hours'] + 24 if row['End_Time_Hours'] < row['Start_Time_Hours'] else row['End_Time_Hours'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time_Half_Rounding'] = split_table[f'{col}_Time_Hours'].apply(\n",
    "        lambda x: np.round(x * 2) / 2 if np.round(x * 2) / 2 == x else np.floor(x * 2) / 2\n",
    "    )\n",
    "\n",
    "split_table['Number_Split'] = split_table.apply(\n",
    "    lambda row: (row['End_Time_Half_Rounding'] - row['Start_Time_Half_Rounding']) * 2 \n",
    "    if pd.notna(row['End_Time_Half_Rounding']) and pd.notna(row['Start_Time_Half_Rounding']) \n",
    "    else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "split_table = split_table.rename(columns={'Start_Time_Half_Rounding': 'Time_1'})\n",
    "split_table['Time_2'] = split_table['Time_1'] + 0.5\n",
    "split_table['Custom'] = split_table['Number_Split'].apply(lambda n: list(range(int(n) + 1)) if pd.notna(n) else [])\n",
    "split_table = split_table.explode('Custom')\n",
    "\n",
    "print(split_table['Custom'].unique())\n",
    "\n",
    "split_table['Time_1_New'] = split_table['Time_1'] + (split_table['Custom'] * 0.5)\n",
    "split_table['Time_2_New'] = split_table['Time_2'] + (split_table['Custom'] * 0.5)\n",
    "split_table['Rounded_End_Time_Hours'] = np.ceil(split_table['End_Time_Hours'] * 2) / 2\n",
    "\n",
    "filtered_df = split_table[split_table['Rounded_End_Time_Hours'] > split_table['Time_1_New']]\n",
    "\n",
    "split_table['Start_Time_Number'] = np.where(\n",
    "    split_table['Time_1_New'] > split_table['Start_Time_Hours'],\n",
    "    split_table['Time_1_New'],\n",
    "    split_table['Start_Time_Hours']\n",
    ")\n",
    "\n",
    "split_table['End_Time_Number'] = np.where(\n",
    "    split_table['Time_2_New'] < split_table['End_Time_Hours'],\n",
    "    split_table['Time_2_New'],\n",
    "    split_table['End_Time_Hours']\n",
    ")\n",
    "\n",
    "def calculate_new_day_time(row, time_col, date_col):\n",
    "    calculated_value = row[time_col]\n",
    "    if row['Start Date'] == row['End Date']:\n",
    "        return row[date_col]\n",
    "    else:\n",
    "        if time_col == 'Start_Time_Number' and calculated_value >= 24:\n",
    "            return row['Start Date'] + pd.Timedelta(days=1)\n",
    "        elif time_col == 'End_Time_Number' and calculated_value < 24:\n",
    "            return row['End Date'] - pd.Timedelta(days=1)\n",
    "        else:\n",
    "            return row[date_col]\n",
    "\n",
    "split_table['New_Day_Start_Time'] = split_table.apply(lambda row: calculate_new_day_time(row, 'Start_Time_Number', 'Start Date'), axis=1)\n",
    "split_table['New_Day_End_Time'] = split_table.apply(lambda row: calculate_new_day_time(row, 'End_Time_Number', 'End Date'), axis=1)\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time_Number'] = (split_table[f'{col}_Time_Number'] - 24 * (split_table[f'{col}_Time_Number'] >= 24)) % 24\n",
    "              \n",
    "def number_to_time(number):\n",
    "    if pd.isna(number):\n",
    "        return pd.NaT\n",
    "    hours = int(np.floor(number))\n",
    "    minutes = int(np.floor((number - hours) * 60))\n",
    "    seconds = int(np.floor((number - hours - minutes / 60) * 3600))\n",
    "    return pd.Timestamp(f\"1970-01-01 {hours:02}:{minutes:02}:{seconds:02}\")\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time'] = split_table[f'{col}_Time_Number'].apply(number_to_time).dt.time\n",
    "split_table['Time_1'] = split_table['Time_1'].apply(number_to_time).dt.time\n",
    "\n",
    "def combine_date_time(row, time_col, date_col):\n",
    "    if pd.isna(row[time_col]):\n",
    "        return pd.NaT\n",
    "    return datetime.combine(row[date_col].date(), row[time_col])\n",
    "\n",
    "split_table['Datetime_Start_Time'] = split_table.apply(lambda row: combine_date_time(row, 'Start_Time', 'New_Day_Start_Time'), axis=1)\n",
    "split_table['Datetime_End_Time'] = split_table.apply(lambda row: combine_date_time(row, 'End_Time', 'New_Day_End_Time'), axis=1)\n",
    "split_table['Duration'] = (split_table['Datetime_End_Time'] - split_table['Datetime_Start_Time']).dt.total_seconds()\n",
    "split_table['Work Category'] = np.where(split_table['Scheduled Activity'].isin(['Open Time', 'Extra Hours']),'Productive','Unproductive')\n",
    "\n",
    "def adjust_time_to_interval(row, start_time_col):\n",
    "    dt = row[start_time_col]\n",
    "    hour = dt.hour\n",
    "    minute = dt.minute\n",
    "    if minute < 30:\n",
    "        adjusted_time = dt.replace(minute=0, second=0, microsecond=0)\n",
    "    else:\n",
    "        adjusted_time = dt.replace(minute=30, second=0, microsecond=0)\n",
    "        \n",
    "    return adjusted_time\n",
    "\n",
    "split_table['Intervals'] = split_table.apply(lambda row: adjust_time_to_interval(row, 'Datetime_Start_Time'), axis=1)\n",
    "\n",
    "split_table = split_table[split_table['Datetime_Start_Time'] < split_table['Datetime_End_Time']]\n",
    "INTERVALS_EXTEND = split_table[['Year','Month','Week_Monday','Date','OracleID','People ID', 'IEX_ID', 'Employee Name','Email Id', 'Alias','LOB','LOB_3', 'Supervisor Name','Wave','Detail Status','Status','Start Date', 'End Date', 'Scheduled Activity','Intervals', 'Datetime_Start_Time', 'Datetime_End_Time','Duration','Work Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEDULE = sorted_df.pivot_table(index=['OracleID','People ID', 'IEX_ID', 'Employee Name','Email Id','Alias','LOB','LOB_2','LOB_3', 'Supervisor Name','Wave','Detail Status','Status'],columns=[ 'Date'],values='First Shift',aggfunc='first').reset_index()\n",
    "SCHEDULE = pd.DataFrame(SCHEDULE)\n",
    "\n",
    "IEX_EXTEND = sorted_df[['Year', 'Month', 'Week Begin','Week_Monday', 'Date', 'Agent Name', 'IEX_ID','Datetime_Fluctuate_Start_Shift', 'Datetime_Fluctuate_End_Shift','Fluctuate Shift', 'Datetime_First_Start_Shift',\n",
    "       'Datetime_First_End_Shift', 'First Shift', 'Time_Of_Day', 'Open Time', 'Extra Time', 'Target', 'Break Time','Lunch Time', 'Training', 'NCNS','AL','Unplanned','Planned', 'Night_Shift','Roster Presented', 'Roster Scheduled',\n",
    "       'Shift Tracking', 'OT PreShift', 'OT PostShift', 'OracleID','People ID', 'Employee Name', 'Email Id', 'Alias', 'LOB','LOB_2','LOB_3','Supervisor Name', 'Wave', 'Detail Status', 'Status','OT Type','Combined OT Range']]\n",
    "\n",
    "IEX_EXTEND = IEX_EXTEND.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for week_monday, group in IEX_EXTEND.groupby('Week_Monday'):\n",
    "    week_monday_str = week_monday.strftime('%Y_%m_%d')\n",
    "    file_name = f'{week_monday_str}.xlsx'\n",
    "    file_path = os.path.join(folder_paths[\"output_iex\"], file_name)\n",
    "    group.to_excel(file_path, index=False)\n",
    "\n",
    "for week_monday, group in INTERVALS_EXTEND.groupby('Week_Monday'):\n",
    "    week_monday_str = week_monday.strftime('%Y-%m-%d')\n",
    "    file_name = f'{week_monday_str}.xlsx'\n",
    "    file_path = os.path.join(folder_paths[\"output_iex_intervals\"], file_name)\n",
    "    group.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "# from datetime import datetime\n",
    "\n",
    "# all_sheets = {\n",
    "#     '1. INTERVALS_EXTEND': INTERVALS_EXTEND,\n",
    "#     '2. IEX_EXTEND': IEX_EXTEND,\n",
    "#     '3. Schedule': SCHEDULE\n",
    "# }\n",
    "\n",
    "# today_temp = datetime.today().date()\n",
    "# today = today_temp.strftime('%b_%d_%Y')\n",
    "\n",
    "# writer = pd.ExcelWriter(f'{today}_IEX_DAILY_OUTPUT.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# for sheet_name in all_sheets.keys():\n",
    "#     all_sheets[sheet_name].to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
