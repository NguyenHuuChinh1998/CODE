{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(a):\n",
    "    date_formats = [\"%Y-%m-%d %H:%M:%S.%f\", \n",
    "                    \"%Y-%m-%d %H:%M:%S\", \n",
    "                    \"%m/%d/%Y %H:%M\",\n",
    "                    \"%m-%d-%Y %H:%M\", \n",
    "                    \"%m/%d/%Y\", \n",
    "                    \"%Y-%m-%d\", \n",
    "                    \"%H:%M.%f\",\n",
    "                    \"%m/%d/%Y %H:%M:%S\"] \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(str(a), fmt).strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    try:\n",
    "        return (datetime(1899, 12, 30) + timedelta(days=float(a))).strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if not re.match(\"\\d+:\\d+:\\d+(\\.\\d+)?\", str(a)):\n",
    "        return str(a)\n",
    "    return  \n",
    "def convert_date(a):\n",
    "    my_format=\"%Y-%m-%d\"\n",
    "    try:\n",
    "        return datetime.strptime(str(a), \"%Y-%m-%d %H:%M:%S\").strftime(my_format)\n",
    "    except:\n",
    "        return datetime.strptime(str(a), \"%m/%d/%Y %H:%M\").strftime(my_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def rename_files(data_dir):\n",
    "    dates_set = set()\n",
    "\n",
    "    for filename in pathlib.Path(data_dir).glob('*.csv'):\n",
    "        if \"Product Comment Report\" in filename.name:\n",
    "            continue\n",
    "        with open(filename, 'r') as csv_file:\n",
    "            rows = csv.reader(csv_file, delimiter=',')\n",
    "            headers = next(rows)\n",
    "            sheet = {col: [] for col in headers}\n",
    "            for row in rows:\n",
    "                for i, col in enumerate(headers):\n",
    "                    sheet[col].append(row[i])\n",
    "        if not sheet['1_resolve_time']:\n",
    "            continue\n",
    "        date_str = sheet['1_resolve_time'][1].split()[0]\n",
    "        dates_set.add(date_str)\n",
    "\n",
    "        title = sheet['title'][0].strip()\n",
    "\n",
    "    for date in dates_set:\n",
    "        start_date, end_date = date, date\n",
    "\n",
    "        for filename in pathlib.Path(data_dir).glob('*.csv'):\n",
    "            if \"Product Comment Report\" in filename.name:\n",
    "                continue\n",
    "            with open(filename, 'r') as csv_file:\n",
    "                rows = csv.reader(csv_file, delimiter=',')\n",
    "                headers = next(rows)\n",
    "                sheet = {col: [] for col in headers}\n",
    "                for row in rows:\n",
    "                    for i, col in enumerate(headers):\n",
    "                        sheet[col].append(row[i])\n",
    "            if not sheet['1_resolve_time'] or len(sheet['1_resolve_time']) < 2:\n",
    "                continue\n",
    "            date_list = []\n",
    "            for date_str in sheet['1_resolve_time']:\n",
    "                date = datetime.datetime.strptime(date_str.split()[0], '%Y-%m-%d').date()\n",
    "                date_list.append(date)\n",
    "\n",
    "            date_list.sort(reverse=True)\n",
    "            start_date = date_list[-1].strftime('%Y-%m-%d')\n",
    "            end_date = date_list[0].strftime('%Y-%m-%d')\n",
    "\n",
    "            new_file_name = f\"{title}_{start_date}_{end_date}.csv\"\n",
    "            new_filepath = os.path.join(data_dir, new_file_name)\n",
    "            \n",
    "            if os.path.exists(new_filepath):\n",
    "                os.remove(new_filepath)\n",
    "            \n",
    "            os.rename(filename, new_filepath)\n",
    "\n",
    "\n",
    "rename_files('E:/tt/qa_daily_automation/Product comment report/R1')\n",
    "rename_files('E:/tt/qa_daily_automation/Product comment report/R2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal_diff_case</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appeal_dailyreport</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regular_diff_case</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regular_false_case</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rock_dailyreport</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCR_diff_case</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCR_false_case</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sideprj_shoptab</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sideprj_ugads</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>2023-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sideprj_dailyreport</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>2023-08-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  Start date    End date\n",
       "0     appeal_diff_case  2023-08-27  2023-08-27\n",
       "1   appeal_dailyreport  2023-08-26  2023-08-26\n",
       "2    regular_diff_case  2023-08-21  2023-08-27\n",
       "3   regular_false_case  2023-08-26  2023-08-26\n",
       "4     rock_dailyreport  2023-08-26  2023-08-26\n",
       "5        PCR_diff_case  2023-08-21  2023-08-27\n",
       "6       PCR_false_case  2023-08-26  2023-08-26\n",
       "7      sideprj_shoptab  2023-08-27  2023-08-27\n",
       "8        sideprj_ugads  2023-08-27  2023-08-27\n",
       "9  sideprj_dailyreport  2023-08-26  2023-08-26"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Supporting Dashboard\n",
    "#Queue\n",
    "queue_list = pd.read_excel('E:/tt/qa_daily_automation/Support_dashboard.xlsx',sheet_name='Queue List').values\n",
    "queue_list = pd.DataFrame(queue_list)\n",
    "headers = ['BUSINESS','COMPOUND','CATEGORY','MOD QUEUE ID','MOD QUEUE NAME',\n",
    "           'QA QUEUE ID','QA QUEUE NAME','QUEUE GROUP','STATUS','Priority','Latency','AHT (secs)','Policy_type','Classify']\n",
    "queue_list.columns = headers\n",
    "\n",
    "#Variable\n",
    "Date_variable = pd.read_excel('E:/tt/qa_daily_automation/variable.xlsx')\n",
    "from datetime import datetime\n",
    "Date_variable['Start date'] = Date_variable['Start date'].apply(convert_datetime)\n",
    "Date_variable['End date'] = Date_variable['End date'].apply(convert_datetime)\n",
    "\n",
    "Start_Date_False_PCR = datetime.strptime(str(Date_variable.loc[6, 'Start date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "End_Date_False_PCR = datetime.strptime(str(Date_variable.loc[6, 'End date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "\n",
    "Start_Date_Diff_PCR = datetime.strptime(str(Date_variable.loc[5, 'Start date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "End_Date_Diff_PRC = datetime.strptime(str(Date_variable.loc[5, 'End date']), '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "\n",
    "Date_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # Đặt kiểu dữ liệu của cột có chuỗi dài 19 số thành 'object'\n",
    "            df = pd.read_csv(file_path, dtype={'task_id': object,'project_id':object,'object_id':object})\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "  \n",
    "    # Ghép tất cả các dataframe trong danh sách dfs\n",
    "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_rawdata = merge_csv_files('E:/tt/qa_daily_automation/Product comment report/R2')\n",
    "mod_rawdata = merge_csv_files('E:/tt/qa_daily_automation/Product comment report/R1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VN Product Comment Report'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_rawdata['title'] = mod_rawdata['title'].replace('VN LL Product Comment Report', 'VN Product Comment Report')\n",
    "mod_rawdata['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "QA VN LL Product Comment Report    24879\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_rawdata['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_rawdata = pd.merge(qa_rawdata,queue_list,how='left',left_on='title',right_on='QA QUEUE NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(qa_rawdata, mod_rawdata, how='left', \n",
    "                     left_on=['MOD QUEUE NAME','object_id'], \n",
    "                     right_on=['title','object_id'],\n",
    "                     suffixes=('_qa', '_mod'))\n",
    "merged_df.dropna(subset='1_rejectLabel_mod',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['task_id_qa', 'project_id_qa', 'title_qa', 'object_id', 'status_qa',\n",
       "       'create_time_qa', 'closed_time_qa', '1_verifier_qa', '1_assign_time_qa',\n",
       "       '1_resolve_time_qa', '1_duration_qa', '1_verify_data_qa',\n",
       "       '1_auditResult_qa', '1_auditStatus_qa', '1_rejectLabel_qa',\n",
       "       'tcs_link_qa', 'is_simulation_qa', 'Unnamed: 17_qa', 'Unnamed: 18_qa',\n",
       "       'Unnamed: 19_qa', 'BUSINESS', 'COMPOUND', 'CATEGORY', 'MOD QUEUE ID',\n",
       "       'MOD QUEUE NAME', 'QA QUEUE ID', 'QA QUEUE NAME', 'QUEUE GROUP',\n",
       "       'STATUS', 'Priority', 'Latency', 'AHT (secs)', 'Policy_type',\n",
       "       'Classify', 'task_id_mod', 'project_id_mod', 'title_mod', 'status_mod',\n",
       "       'create_time_mod', 'closed_time_mod', '1_verifier_mod',\n",
       "       '1_assign_time_mod', '1_resolve_time_mod', '1_duration_mod',\n",
       "       '1_verify_data_mod', '1_auditResult_mod', '1_auditStatus_mod',\n",
       "       '1_rejectLabel_mod', 'tcs_link_mod', 'is_simulation_mod',\n",
       "       'Unnamed: 17_mod', 'Unnamed: 18_mod', 'Unnamed: 19_mod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[['Moderation Result','Respondent Result']] = merged_df[['1_verify_data_mod','1_verifier_qa']].replace(to_replace=r'^auditStatus: ',value= \"Audit Result:: \",regex=True).astype(str)\n",
    "pcr_result = ['remove', 'normal', 'selfvisible']\n",
    "columns = ['Moderation Result', 'Respondent Result']\n",
    "\n",
    "def match_and_concatenate(cell):\n",
    "    cell = str(cell).lower()\n",
    "    cell = cell.replace('_x000d_', '')\n",
    "    found_words = []\n",
    "    audit_exp = re.search(r'(.*auditreason:)(.*)(\\n|$)', cell)\n",
    "    reject_exp = re.search(r'(.*rejectlabel:)(.*)(\\n|$)', cell)\n",
    "    if audit_exp:\n",
    "        cell_split = audit_exp.group(2).strip()\n",
    "    elif reject_exp:\n",
    "        cell_split = reject_exp.group(2).strip()\n",
    "    else:\n",
    "        cell_split = cell\n",
    "    cell_split = re.sub(r'[\\[\\]\"]', '', cell_split)\n",
    "    matches = re.findall('|'.join(pcr_result), cell_split, re.IGNORECASE)\n",
    "    found_words.extend(matches)\n",
    "    return \",\".join(found_words) if found_words else None\n",
    "for column in ['Moderation Result', 'Respondent Result']:\n",
    "    merged_df.loc[merged_df['title_qa'].isin(['QA VN LL Product Comment', 'QA VN LL Product Comment Report']), column] = merged_df.loc[merged_df['title_qa'].isin(['QA VN LL Product Comment', 'QA VN LL Product Comment Report']), column].apply(match_and_concatenate)\n",
    "    \n",
    "merged_df['Mod Result'] = merged_df['1_rejectLabel_mod'].apply(match_and_concatenate)\n",
    "merged_df['BPO QA Result'] = merged_df['1_rejectLabel_qa'].apply(match_and_concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['title_qa','project_id_qa','1_verifier_mod','1_resolve_time_mod',\n",
    "                       'object_id','Mod Result','1_auditResult_mod','1_duration_mod',\n",
    "                       '1_verifier_qa','1_resolve_time_qa','task_id_qa','tcs_link_qa',\n",
    "                       'BPO QA Result','1_auditResult_qa']].rename(columns={'title_qa':'Sampling Queue','project_id_qa':'Queue ID','1_verifier_mod':'Moderator name','1_resolve_time_mod':'Moderation time','object_id':'Object ID','1_auditResult_mod':'Mod Reason',\n",
    "                                                                           '1_duration_mod':'Mod AHT','1_verifier_qa':'BPO QA','1_resolve_time_qa':'BPO QA Date','task_id_qa':'BPO QA Task ID','tcs_link_qa':'BPO QA Link','1_auditResult_qa':'BPO QA Reason'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Object ID'] = \"id=\" + merged_df['Object ID'].astype(str)\n",
    "merged_df['Queue ID'] = \"id=\" + merged_df['Queue ID'].astype(str)\n",
    "merged_df['BPO QA Task ID'] = \"id=\" + merged_df['BPO QA Task ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95906, 15)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy_errors_1 = [\n",
    "    'prohibited products','unsupported products','restricted products','adult nudity and sexual activities','hateful behaviors','minor safety','absolute terms',\n",
    "    'malicious comparison','title spam','abnormal price','inconsistent information','other languages','misleading functionality and effect','redirect traffic',\n",
    "    'missing brand authorization','unfair trading','obscuring product images','target to minors','underage commercial behavior','false promise','false promises','sympathy promotion',\n",
    "    'misleading size/weight/quantity','misleading patent/endorsement/metrics/awards','misleading origin','misleading return & refund service','misleading guarantees and warranties',\n",
    "    'irrelevant promotion','give away','reproduced content','soliciting mutual interactions','still frame','possible pirated contents','possible pirated content',\n",
    "    'non product promotion content','vulgar behavior','disturbing animal body','insulting and abusive content','body impurities','dirty environment','eye-catching sensitive content',\n",
    "    'bind a sell b - prohibited product','misleading logistics','misleading brand','brand circumvention','copycat products','violence',\n",
    "    'illegal behavior','hatespeech and harassment','possible ip infringement','spam','invalid company name','inaccurate company name','inaccurate company address','missing identity document',\n",
    "    'expired documentation','black-and-white copy','unclear documentation','invalid watermark or logo','incomplete documentation','inaccurate representative name','inaccurate id number',\n",
    "    'inaccurate documentation','inaccurate tax name','inaccurate tax number','inaccurate brand name','inaccurate trademark name','inaccurate trademark number','inaccurate application date',\n",
    "    'inaccurate expiry date','invalid trademark','inaccurate registrant','unqualified destination market','inaccurate class(es) of goods/service','unqualified owner','inaccurate trademark certificate',\n",
    "    'expired trademark certificate','unclear trademark certificate','inauthentic trademark certificate','unqualified 1st level distributor','inaccurate 1st level distributor letter',\n",
    "    'expired 1st level distributor letter','unclear 1st level distributor letter','inauthentic 1st level distributor letter','unqualified 2nd level distributor',\n",
    "    'inaccurate 2nd level distributor letter','expired 2nd level distributor letter','unclear 2nd level distributor letter','inauthentic 2nd level distributor letter',\n",
    "    'unqualified third level distributor','inaccurate third level distributor letter','expired third level distributor letter','unclear third level distributor letter',\n",
    "    'inauthentic third level distributor letter','missing buyer information','missing quantity of purchase item','missing purchase item information','missing purchase date',\n",
    "    'unable to locate brand item product','purchase date mismatch','seller information mismatch','missing price of purchase item','missing seller information',\n",
    "    'product quantity insufficient','exceeded validity period','altered document','lack of supportive information','unable to recognise source of purchase','underage applicant',\n",
    "    'gibberish shop name','abnormal company status','traffic redirection','inaccurate company number','oversea personal seller','ps tampering trace','inauthentic documentation',\n",
    "    'violent extremism','hate speech','unauthorized brand information','impersonation','suicide and dangerous acts','illegal activities and regulated goods',\n",
    "    'harassment and bullying','child endangerment information','counterfeit product information','inauthentic certification of incorporation','inaccurate register date','erotic nudity','hateful contexts','partner name or logo relates to ''tiktok''','inauthentic work environment','repeated image','inappropriate watermark or logo',\n",
    "    'incomplete information','inaccurate and misleading review','slightly vulgar','inaccurate package weight information','inappropriate speech','malicious behaviors','vulgar issues',\n",
    "    'imagery depicting skin defects','imagery depicting indecent body organs','imagery depicting indecent teeth&oral','imagery depicting animal meat/carcasses',\n",
    "    'imagery depicting unpleasant animal or insect','imagery depicting impurities','horror content','scene of squalor','offensive content','human excrement','mental illness content',\n",
    "    'unsuitable for recommendation','surprise-based product','vat number check','slide show','counterfeit word indication','brand never produced','bind a sell b-prohibited product',\n",
    "    'pirated content- dedup recall','pirated content','possible counterfeit product','click bait','click-bait','non shippable products','physical trademark infringement product','incorrect category high risk','low cost content',  \n",
    "    'gambling related behaviour','information trademark infringement product','physically damaged id','suspicious brand promotion'\n",
    "    ]\n",
    "Policy_errors_2 = list(map(lambda x: x.replace(\" \", \"_\") + \"0005\",Policy_errors_1))\n",
    "\n",
    "Policy_errors = Policy_errors_1 + Policy_errors_2\n",
    "\n",
    "merged_df['Mod Reason'] = merged_df['Mod Reason'].str.lower()\n",
    "merged_df['BPO QA Reason'] = merged_df['BPO QA Reason'].str.lower()\n",
    "\n",
    "Policy_errors_pattern = \"|\".join(Policy_errors )\n",
    "\n",
    "def pattern_searcher(search_str:str, search_list:str):\n",
    "\n",
    "    search_obj = re.search(search_list, search_str)\n",
    "    if search_obj :\n",
    "        return_str = search_str[search_obj.start(): search_obj.end()]\n",
    "    else:\n",
    "        return_str = np.nan\n",
    "    return return_str\n",
    "\n",
    "merged_df['Mod Reason'] = merged_df['Mod Reason'].astype(str).apply(lambda y: pattern_searcher(search_str=y, search_list=Policy_errors_pattern))\n",
    "merged_df['BPO QA Reason'] = merged_df['BPO QA Reason'].astype(str).apply(lambda z: pattern_searcher(search_str=z, search_list=Policy_errors_pattern))\n",
    "\n",
    "def d(row):\n",
    "    last_index = row.last_valid_index()\n",
    "    return row[last_index] if last_index else np.nan\n",
    "\n",
    "#Final Policy Errors\n",
    "merged_df['Final policy errors'] = merged_df[['Mod Reason','BPO QA Reason']].apply(d, axis=1)\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add diff case\n",
    "\n",
    "merged_df.loc[merged_df['Mod Result'] != merged_df['BPO QA Result'],'Diff case']=\"FALSE\"\n",
    "merged_df.loc[merged_df['Diff case'].isnull(),'Diff case']=\"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['BPO QA Date'] = pd.to_datetime(merged_df['BPO QA Date'])\n",
    "merged_df['Moderation time'] = pd.to_datetime(merged_df['Moderation time'])\n",
    "\n",
    "merged_df['QA Week'] = merged_df['BPO QA Date'].dt.isocalendar().week - (merged_df['BPO QA Date'].dt.weekday == 0).astype(int)\n",
    "merged_df['Mod Week'] = merged_df['Moderation time'].dt.isocalendar().week - (merged_df['Moderation time'].dt.weekday == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_false_case = merged_df[(merged_df['BPO QA Date'] >= merged_df['Moderation time']) &\n",
    "                        (merged_df['QA Week'] >= merged_df['Mod Week'])]\n",
    "\n",
    "Final_false_case = Final_false_case.drop(columns=['QA Week', 'Mod Week'])\n",
    "Final_false_case = Final_false_case.sort_values(by='BPO QA Date', ascending=True).drop_duplicates(subset='BPO QA Task ID', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampling Queue</th>\n",
       "      <th>Queue ID</th>\n",
       "      <th>Moderator name</th>\n",
       "      <th>Moderation time</th>\n",
       "      <th>Object ID</th>\n",
       "      <th>Mod Result</th>\n",
       "      <th>Mod Reason</th>\n",
       "      <th>Mod AHT</th>\n",
       "      <th>BPO QA</th>\n",
       "      <th>BPO QA Date</th>\n",
       "      <th>BPO QA Task ID</th>\n",
       "      <th>BPO QA Link</th>\n",
       "      <th>BPO QA Result</th>\n",
       "      <th>BPO QA Reason</th>\n",
       "      <th>Final policy errors</th>\n",
       "      <th>Diff case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98328</th>\n",
       "      <td>QA VN LL Product Comment Report</td>\n",
       "      <td>id=7181739508772110849</td>\n",
       "      <td>tran.tl@trans-cosmos.com.vn</td>\n",
       "      <td>2023-08-24 16:56:03</td>\n",
       "      <td>id=7270790179282059525</td>\n",
       "      <td>normal,normal,normal,normal,normal,remove</td>\n",
       "      <td>harassment and bullying</td>\n",
       "      <td>47.0</td>\n",
       "      <td>my.ntk@trans-cosmos.com.vn</td>\n",
       "      <td>2023-08-25 09:55:27</td>\n",
       "      <td>id=7270998066709266946</td>\n",
       "      <td>https://tcs-sg.bytelemon.com/worktable/7181739...</td>\n",
       "      <td>normal,normal,normal,normal,remove,remove</td>\n",
       "      <td>harassment and bullying</td>\n",
       "      <td>harassment and bullying</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98754</th>\n",
       "      <td>QA VN LL Product Comment Report</td>\n",
       "      <td>id=7181739508772110849</td>\n",
       "      <td>sang.vtn@trans-cosmos.com.vn</td>\n",
       "      <td>2023-08-25 21:10:13</td>\n",
       "      <td>id=7271261314017313029</td>\n",
       "      <td>normal,normal,selfvisible</td>\n",
       "      <td>redirect traffic</td>\n",
       "      <td>32.0</td>\n",
       "      <td>my.ntk@trans-cosmos.com.vn</td>\n",
       "      <td>2023-08-26 11:12:15</td>\n",
       "      <td>id=7271340683640799746</td>\n",
       "      <td>https://tcs-sg.bytelemon.com/worktable/7181739...</td>\n",
       "      <td>normal,normal,normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>redirect traffic</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99121</th>\n",
       "      <td>QA VN LL Product Comment Report</td>\n",
       "      <td>id=7181739508772110849</td>\n",
       "      <td>vy.dtt3@trans-cosmos.com.vn</td>\n",
       "      <td>2023-08-26 15:41:14</td>\n",
       "      <td>id=7271543913712763142</td>\n",
       "      <td>remove</td>\n",
       "      <td>harassment and bullying</td>\n",
       "      <td>8.0</td>\n",
       "      <td>tram.nn@trans-cosmos.com.vn</td>\n",
       "      <td>2023-08-27 20:31:20</td>\n",
       "      <td>id=7271754387612172801</td>\n",
       "      <td>https://tcs-sg.bytelemon.com/worktable/7181739...</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>harassment and bullying</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Sampling Queue                Queue ID  \\\n",
       "98328  QA VN LL Product Comment Report  id=7181739508772110849   \n",
       "98754  QA VN LL Product Comment Report  id=7181739508772110849   \n",
       "99121  QA VN LL Product Comment Report  id=7181739508772110849   \n",
       "\n",
       "                     Moderator name     Moderation time  \\\n",
       "98328   tran.tl@trans-cosmos.com.vn 2023-08-24 16:56:03   \n",
       "98754  sang.vtn@trans-cosmos.com.vn 2023-08-25 21:10:13   \n",
       "99121   vy.dtt3@trans-cosmos.com.vn 2023-08-26 15:41:14   \n",
       "\n",
       "                    Object ID                                 Mod Result  \\\n",
       "98328  id=7270790179282059525  normal,normal,normal,normal,normal,remove   \n",
       "98754  id=7271261314017313029                  normal,normal,selfvisible   \n",
       "99121  id=7271543913712763142                                     remove   \n",
       "\n",
       "                    Mod Reason  Mod AHT                       BPO QA  \\\n",
       "98328  harassment and bullying     47.0   my.ntk@trans-cosmos.com.vn   \n",
       "98754         redirect traffic     32.0   my.ntk@trans-cosmos.com.vn   \n",
       "99121  harassment and bullying      8.0  tram.nn@trans-cosmos.com.vn   \n",
       "\n",
       "              BPO QA Date          BPO QA Task ID  \\\n",
       "98328 2023-08-25 09:55:27  id=7270998066709266946   \n",
       "98754 2023-08-26 11:12:15  id=7271340683640799746   \n",
       "99121 2023-08-27 20:31:20  id=7271754387612172801   \n",
       "\n",
       "                                             BPO QA Link  \\\n",
       "98328  https://tcs-sg.bytelemon.com/worktable/7181739...   \n",
       "98754  https://tcs-sg.bytelemon.com/worktable/7181739...   \n",
       "99121  https://tcs-sg.bytelemon.com/worktable/7181739...   \n",
       "\n",
       "                                   BPO QA Result            BPO QA Reason  \\\n",
       "98328  normal,normal,normal,normal,remove,remove  harassment and bullying   \n",
       "98754                       normal,normal,normal                      NaN   \n",
       "99121                                     normal                      NaN   \n",
       "\n",
       "           Final policy errors Diff case  \n",
       "98328  harassment and bullying     FALSE  \n",
       "98754         redirect traffic     FALSE  \n",
       "99121  harassment and bullying     FALSE  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_time( df,  from_date, to_date):\n",
    "\n",
    "    Final_false_case = df[(df['BPO QA Date'].dt.strftime('%Y-%m-%d') >= from_date) & (df['BPO QA Date'].dt.strftime('%Y-%m-%d') <= to_date)]\n",
    "\n",
    "    #Final_false_case.to_excel(f\"C:/Users/v6210227/Desktop/Product comment {from_date}{to_date}.xlsx\", index=False)\n",
    "\n",
    "    return Final_false_case\n",
    "# Fill in moderation time (Tue -> Today - 1)\n",
    "Regular_diff_pcr = filter_time(Final_false_case, Start_Date_Diff_PCR, End_Date_Diff_PRC)\n",
    "\n",
    "Regular_diff_case_pcr = Regular_diff_pcr[Regular_diff_pcr['Diff case']==\"FALSE\"]\n",
    "Regular_diff_case_pcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81177   2023-08-21 08:06:48\n",
       "91771   2023-08-21 11:05:29\n",
       "81936   2023-08-21 11:05:32\n",
       "81945   2023-08-21 11:06:34\n",
       "81203   2023-08-21 11:06:39\n",
       "                ...        \n",
       "99233   2023-08-27 20:38:32\n",
       "99235   2023-08-27 20:38:36\n",
       "99237   2023-08-27 20:38:39\n",
       "99239   2023-08-27 20:38:46\n",
       "99241   2023-08-27 20:38:51\n",
       "Name: BPO QA Date, Length: 798, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Regular_diff_pcr['BPO QA Date']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diff case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anh.td\\AppData\\Local\\Temp\\ipykernel_26720\\4193611911.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Diff_case_PCR['Moderation time'] = pd.to_datetime(Diff_case_PCR['Moderation time'].apply(convert_date))\n"
     ]
    }
   ],
   "source": [
    "def filter_time( df,  from_date, to_date):\n",
    "\n",
    "    Diff_case_PCR = df[(df['Moderation time'].dt.strftime('%Y-%m-%d') >= from_date) & (df['Moderation time'].dt.strftime('%Y-%m-%d') <= to_date)]\n",
    "    Diff_case_PCR['Moderation time'] = pd.to_datetime(Diff_case_PCR['Moderation time'].apply(convert_date))\n",
    "    Diff_case_PCR = Diff_case_PCR[Diff_case_PCR['Diff case'] == 'FALSE']\n",
    "    Diff_case_PCR = Diff_case_PCR.groupby(by=['Moderation time','Sampling Queue','Moderator name'], as_index=False).agg({'BPO QA Task ID':'count'})\n",
    "    Diff_case_PCR = Diff_case_PCR[['Moderation time','Sampling Queue','Moderator name','BPO QA Task ID']]\n",
    "    Diff_case_PCR.rename(columns={'BPO QA Task ID':'No. Diff cases'}, inplace=True)\n",
    "   \n",
    "    return Diff_case_PCR, from_date, to_date\n",
    "# Fill in moderation time (Tue -> Today - 1)\n",
    "Final_False_Case_PCR, Start_date_PCR, End_date_PCR = filter_time(Regular_diff_pcr, Start_Date_False_PCR, End_Date_False_PCR)\n",
    "\n",
    "Final_False_Case_PCR.to_excel('E:/tt/qa_daily_automation/Product comment report.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
