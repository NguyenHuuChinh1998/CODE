{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import shutil\n",
    "import polars as pl\n",
    "import fastexcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_11796\\3603552263.py:20: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  if not re.match(\"\\d+:\\d+:\\d+(\\.\\d+)?\", str(a)):\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_11796\\3603552263.py:41: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  if not re.match(\"\\d+:\\d+:\\d+(\\.\\d+)?\", str(a)):\n"
     ]
    }
   ],
   "source": [
    "def convert_datetime(a):\n",
    "    my_format=\"%Y-%m-%d %H:%M:%S\"\n",
    "    date_formats = [\"%Y-%m-%d %H:%M:%S.%f\", \n",
    "                    \"%Y-%m-%d %H:%M:%S\", \n",
    "                    \"%m/%d/%Y %H:%M\",\n",
    "                    \"%m-%d-%Y %H:%M\", \n",
    "                    \"%m/%d/%Y\", \n",
    "                    \"%Y-%m-%d\", \n",
    "                    \"%H:%M.%f\",\n",
    "                    \"%m/%d/%Y %H:%M:%S\"] \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(str(a), fmt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    try:\n",
    "        return (datetime(1899, 12, 30) + timedelta(days=float(a))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if not re.match(\"\\d+:\\d+:\\d+(\\.\\d+)?\", str(a)):\n",
    "        return str(a)\n",
    "    return  \n",
    "def convert_date(a):\n",
    "    date_formats = [\"%Y-%m-%d %H:%M:%S.%f\", \n",
    "                    \"%Y-%m-%d %H:%M:%S\", \n",
    "                    \"%m/%d/%Y %H:%M\",\n",
    "                    \"%m-%d-%Y %H:%M\", \n",
    "                    \"%m/%d/%Y\", \n",
    "                    \"%Y-%m-%d\", \n",
    "                    \"%H:%M.%f\",\n",
    "                    \"%m/%d/%Y %H:%M:%S\"] \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(str(a), fmt).strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    try:\n",
    "        return (datetime(1899, 12, 30) + timedelta(days=float(a))).strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if not re.match(\"\\d+:\\d+:\\d+(\\.\\d+)?\", str(a)):\n",
    "        return str(a)\n",
    "    return  \n",
    "def convert_to_datetime(struct_time):\n",
    "    return datetime(*struct_time[:6])\n",
    "def input_data(data_dir):\n",
    "    list_files = []\n",
    "    for filename in pathlib.Path(data_dir).glob('**/*.*'):\n",
    "        file_suffixes = filename.suffixes\n",
    "        if file_suffixes[-1].lower() in ['.xlsx', '.csv']:\n",
    "            export_time = os.path.getmtime(filename)\n",
    "            export_time_datetime = convert_to_datetime(time.localtime(export_time))\n",
    "            \n",
    "            if file_suffixes[-1].lower() == '.xlsx':\n",
    "                file_name = filename.stem\n",
    "                dfs = pd.read_excel(filename, sheet_name=None, skiprows=0, na_values=None)\n",
    "                for sheet_name, df in dfs.items():\n",
    "                    df['sheet_name'] = file_name \n",
    "                    df['Export time'] = export_time_datetime\n",
    "                    list_files.append(df)\n",
    "                    \n",
    "            elif file_suffixes[-1].lower() == '.csv':\n",
    "                file_name = filename.stem\n",
    "                df = pd.read_csv(filename, skiprows=0, na_values=None)\n",
    "                df['sheet_name'] = file_name\n",
    "                df['Export time'] = export_time_datetime\n",
    "                list_files.append(df)\n",
    "                \n",
    "    df_list = pd.concat(list_files, axis=0, ignore_index=True)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agent Schedules',\n",
       " '__UNNAMED__1',\n",
       " '__UNNAMED__2',\n",
       " '__UNNAMED__3',\n",
       " '__UNNAMED__4',\n",
       " '__UNNAMED__5',\n",
       " '__UNNAMED__6',\n",
       " '__UNNAMED__9',\n",
       " 'sheet_name',\n",
       " 'Export time']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IEX_Input = input_data(r'1. DAILY RAWDATA/3. IEX/1. VIETNAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "'rename' on column: '__UNNAMED__7' is invalid\n\nSchema at this point: Schema:\nname: Agent Schedules, field: String\nname: __UNNAMED__1, field: String\nname: __UNNAMED__2, field: String\nname: __UNNAMED__3, field: String\nname: __UNNAMED__4, field: String\nname: __UNNAMED__5, field: String\nname: __UNNAMED__6, field: String\nname: __UNNAMED__9, field: String\nname: sheet_name, field: String\nname: Export time, field: Datetime(Microseconds, None)\n\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING THIS_NODE <---\nDF [\"Agent Schedules\", \"__UNNAMED__1\", \"__UNNAMED__2\", \"__UNNAMED__3\"]; PROJECT */10 COLUMNS; SELECTION: None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m columns_to_remove \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 9\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 11\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 12\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m IEX \u001b[38;5;241m=\u001b[39m IEX_Input[[col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m IEX_Input\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns_to_remove]]\n\u001b[1;32m----> 4\u001b[0m IEX \u001b[38;5;241m=\u001b[39m IEX\u001b[38;5;241m.\u001b[39mrename({\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__UNNAMED__1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__UNNAMED__2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__UNNAMED__3\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart_Shift\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__UNNAMED__4\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd_Shift\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__UNNAMED__6\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScheduled Activity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__UNNAMED__7\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart_Action\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__UNNAMED__10\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd_Action\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m })\n\u001b[0;32m     14\u001b[0m IEX[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerate Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m     15\u001b[0m     IEX[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration Date: \u001b[39m\u001b[38;5;124m\"\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     16\u001b[0m     IEX[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeneration Date: (.+)\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     17\u001b[0m     np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m IEX[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerate Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m IEX[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerate Date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfill\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\huuchinh.nguyen\\AppData\\Local\\anaconda3\\Lib\\site-packages\\polars\\dataframe\\frame.py:4526\u001b[0m, in \u001b[0;36mDataFrame.rename\u001b[1;34m(self, mapping, strict)\u001b[0m\n\u001b[0;32m   4482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrename\u001b[39m(\n\u001b[0;32m   4483\u001b[0m     \u001b[38;5;28mself\u001b[39m, mapping: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m, strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   4484\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   4485\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4486\u001b[0m \u001b[38;5;124;03m    Rename column names.\u001b[39;00m\n\u001b[0;32m   4487\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4524\u001b[0m \u001b[38;5;124;03m    └─────┴─────┴─────┘\u001b[39;00m\n\u001b[0;32m   4525\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy()\u001b[38;5;241m.\u001b[39mrename(mapping, strict\u001b[38;5;241m=\u001b[39mstrict)\u001b[38;5;241m.\u001b[39mcollect(_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\huuchinh.nguyen\\AppData\\Local\\anaconda3\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2050\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[0;32m   2048\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[0;32m   2049\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[1;32m-> 2050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(ldf\u001b[38;5;241m.\u001b[39mcollect(callback))\n",
      "\u001b[1;31mColumnNotFoundError\u001b[0m: 'rename' on column: '__UNNAMED__7' is invalid\n\nSchema at this point: Schema:\nname: Agent Schedules, field: String\nname: __UNNAMED__1, field: String\nname: __UNNAMED__2, field: String\nname: __UNNAMED__3, field: String\nname: __UNNAMED__4, field: String\nname: __UNNAMED__5, field: String\nname: __UNNAMED__6, field: String\nname: __UNNAMED__9, field: String\nname: sheet_name, field: String\nname: Export time, field: Datetime(Microseconds, None)\n\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING THIS_NODE <---\nDF [\"Agent Schedules\", \"__UNNAMED__1\", \"__UNNAMED__2\", \"__UNNAMED__3\"]; PROJECT */10 COLUMNS; SELECTION: None"
     ]
    }
   ],
   "source": [
    "columns_to_remove = [\"Unnamed: 0\", \"Unnamed: 8\", \"Unnamed: 9\", \"Unnamed: 5\", \"Unnamed: 11\", \"Unnamed: 12\"]\n",
    "\n",
    "IEX = IEX_Input[[col for col in IEX_Input.columns if col not in columns_to_remove]]\n",
    "IEX = IEX.rename(columns={\n",
    "    \"Unnamed: 1\": \"Agent\",\n",
    "    \"Unnamed: 2\": \"Date\",\n",
    "    \"Unnamed: 3\": \"Start_Shift\",\n",
    "    \"Unnamed: 4\": \"End_Shift\",\n",
    "    \"Unnamed: 6\": \"Scheduled Activity\",\n",
    "    \"Unnamed: 7\": \"Start_Action\",\n",
    "    \"Unnamed: 10\": \"End_Action\"\n",
    "})\n",
    "\n",
    "IEX['Generate Date'] = np.where(\n",
    "    IEX['Agent'].str.contains(\"Generation Date: \", na=False),\n",
    "    IEX['Agent'].str.extract(r'Generation Date: (.+)')[0],\n",
    "    np.nan\n",
    ")\n",
    "IEX['Generate Date'] = IEX['Generate Date'].fillna(method='bfill')\n",
    "IEX_edit = IEX.copy()\n",
    "IEX_edit['Agent'] = IEX_edit['Agent'].fillna(method='ffill')\n",
    "offTable_save = IEX_edit\n",
    "IEX_edit = IEX_edit[(IEX_edit['Start_Shift'] != \"Off\") & (IEX_edit['Date'] != \"Date\")]\n",
    "IEX_edit = IEX_edit[~(IEX_edit['Date'].isna() & IEX_edit['Scheduled Activity'].isna())]\n",
    "IEX_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1879448329.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  IEX_edit[['Date', 'Start_Shift', 'End_Shift']] = IEX_edit[['Date', 'Start_Shift', 'End_Shift']].fillna(method='ffill')\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1879448329.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  offTable['Start_Shift'] = offTable['Start_Shift'].replace('Off', np.nan)\n"
     ]
    }
   ],
   "source": [
    "offTable = offTable_save[offTable_save['Start_Shift'] == \"Off\"].reset_index(drop=True)\n",
    "\n",
    "condition = (IEX_edit['Date'] != \"Date\") & (IEX_edit['Start_Shift'] != \"Off\")\n",
    "IEX_edit = IEX_edit[condition].reset_index(drop=True)\n",
    "IEX_edit[['Date', 'Start_Shift', 'End_Shift']] = IEX_edit[['Date', 'Start_Shift', 'End_Shift']].fillna(method='ffill')\n",
    "\n",
    "condition2 = (IEX_edit['Agent'].str.contains(\"Agent: \", na=False)) | (IEX_edit['Agent'].isna())\n",
    "IEX_edit = IEX_edit[condition2].reset_index(drop=True)\n",
    "\n",
    "offTable['Scheduled Activity'] = offTable['Scheduled Activity'].fillna(offTable['Start_Shift'])\n",
    "offTable['Start_Shift'] = offTable['Start_Shift'].replace('Off', np.nan)\n",
    "\n",
    "IEX_edit = IEX_edit[IEX_edit['Scheduled Activity'].notna()].reset_index(drop=True)\n",
    "combined_df = pd.concat([offTable, IEX_edit], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\2330591367.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_df['Generate Date'] = pd.to_datetime(combined_df['Generate Date'], errors='coerce')\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\2330591367.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "combined_df['Export time'] = pd.to_datetime(combined_df['Export time'], errors='coerce')\n",
    "combined_df['Generate Date'] = pd.to_datetime(combined_df['Generate Date'], errors='coerce')\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
    "combined_df['Year'] = combined_df['Date'].dt.year\n",
    "combined_df['Month'] = combined_df['Date'].dt.strftime('%b-%y')\n",
    "combined_df['IEX_ID'] = combined_df['Agent'].str.extract(r'(\\d+)', expand=False).astype(int)\n",
    "\n",
    "max_generate_date_df = combined_df.groupby(['IEX_ID','Date'])['Generate Date'].max().reset_index()\n",
    "max_generate_date_df = max_generate_date_df.rename(columns={'Generate Date': 'Max Generate Date'})\n",
    "\n",
    "max_generate_date_with_details = pd.merge(combined_df, max_generate_date_df, on=['Date','IEX_ID'], how='left')\n",
    "filtered_max_generate_date = max_generate_date_with_details[max_generate_date_with_details['Generate Date'] == max_generate_date_with_details['Max Generate Date']]\n",
    "\n",
    "filtered_max_generate_date['Scheduled'] = filtered_max_generate_date.groupby(['Date', 'IEX_ID'])['Scheduled Activity'].transform(lambda x: 1 if any(x.isin(['Open Time', 'Extra Hours', 'No Call/No Show', 'PTO'])) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent</th>\n",
       "      <th>Date</th>\n",
       "      <th>Start_Shift</th>\n",
       "      <th>End_Shift</th>\n",
       "      <th>Scheduled Activity</th>\n",
       "      <th>Start_Action</th>\n",
       "      <th>End_Action</th>\n",
       "      <th>sheet_name</th>\n",
       "      <th>Export time</th>\n",
       "      <th>Generate Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Datetime_End_Action</th>\n",
       "      <th>Datetime_Fluctuate_Start_Shift</th>\n",
       "      <th>Datetime_Fluctuate_End_Shift</th>\n",
       "      <th>Fluctuate Shift</th>\n",
       "      <th>Datetime_First_Start_Shift</th>\n",
       "      <th>Datetime_First_End_Shift</th>\n",
       "      <th>First Shift</th>\n",
       "      <th>Datetime_Original_Start_Shift</th>\n",
       "      <th>Datetime_Original_End_Shift</th>\n",
       "      <th>Original Shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent: 3001610 BUI, LYNHATDUY</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Off</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>VNM_07_Oct_13_Oct_2024</td>\n",
       "      <td>2024-10-17 00:49:06</td>\n",
       "      <td>2024-10-16 17:44:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agent: 3001610 BUI, LYNHATDUY</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Off</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>VNM_07_Oct_13_Oct_2024</td>\n",
       "      <td>2024-10-17 00:49:06</td>\n",
       "      <td>2024-10-16 17:44:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agent: 3003466 BUI, MINHTRIET</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Off</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>VNM_07_Oct_13_Oct_2024</td>\n",
       "      <td>2024-10-17 00:49:06</td>\n",
       "      <td>2024-10-16 17:44:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agent: 3003466 BUI, MINHTRIET</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Off</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>VNM_07_Oct_13_Oct_2024</td>\n",
       "      <td>2024-10-17 00:49:06</td>\n",
       "      <td>2024-10-16 17:44:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agent: 3083538 CAO, CHAUTOAN</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Off</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>VNM_07_Oct_13_Oct_2024</td>\n",
       "      <td>2024-10-17 00:49:06</td>\n",
       "      <td>2024-10-16 17:44:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44263</th>\n",
       "      <td>Agent: 3001034 tran, thihaiyen</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>VNM_9_Sep_15_Sep_2024</td>\n",
       "      <td>2024-10-17 00:51:22</td>\n",
       "      <td>2024-10-16 17:46:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-09-14 09:30:00</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44264</th>\n",
       "      <td>Agent: 3001034 tran, thihaiyen</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>VNM_9_Sep_15_Sep_2024</td>\n",
       "      <td>2024-10-17 00:51:22</td>\n",
       "      <td>2024-10-16 17:46:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-09-14 10:30:00</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44265</th>\n",
       "      <td>Agent: 3001034 tran, thihaiyen</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>11:45:00</td>\n",
       "      <td>VNM_9_Sep_15_Sep_2024</td>\n",
       "      <td>2024-10-17 00:51:22</td>\n",
       "      <td>2024-10-16 17:46:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-09-14 11:45:00</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44266</th>\n",
       "      <td>Agent: 3001034 tran, thihaiyen</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Break</td>\n",
       "      <td>11:45:00</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>VNM_9_Sep_15_Sep_2024</td>\n",
       "      <td>2024-10-17 00:51:22</td>\n",
       "      <td>2024-10-16 17:46:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-09-14 12:00:00</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44267</th>\n",
       "      <td>Agent: 3001034 tran, thihaiyen</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Open Time</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>VNM_9_Sep_15_Sep_2024</td>\n",
       "      <td>2024-10-17 00:51:22</td>\n",
       "      <td>2024-10-16 17:46:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "      <td>2024-09-14 04:00:00</td>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>0400-1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44243 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Agent       Date Start_Shift End_Shift  \\\n",
       "0       Agent: 3001610 BUI, LYNHATDUY 2024-10-07         NaT       NaT   \n",
       "1       Agent: 3001610 BUI, LYNHATDUY 2024-10-08         NaT       NaT   \n",
       "2       Agent: 3003466 BUI, MINHTRIET 2024-10-08         NaT       NaT   \n",
       "3       Agent: 3003466 BUI, MINHTRIET 2024-10-09         NaT       NaT   \n",
       "4        Agent: 3083538 CAO, CHAUTOAN 2024-10-09         NaT       NaT   \n",
       "...                               ...        ...         ...       ...   \n",
       "44263  Agent: 3001034 tran, thihaiyen 2024-09-14    04:00:00  13:00:00   \n",
       "44264  Agent: 3001034 tran, thihaiyen 2024-09-14    04:00:00  13:00:00   \n",
       "44265  Agent: 3001034 tran, thihaiyen 2024-09-14    04:00:00  13:00:00   \n",
       "44266  Agent: 3001034 tran, thihaiyen 2024-09-14    04:00:00  13:00:00   \n",
       "44267  Agent: 3001034 tran, thihaiyen 2024-09-14    04:00:00  13:00:00   \n",
       "\n",
       "      Scheduled Activity Start_Action End_Action              sheet_name  \\\n",
       "0                    Off          NaT        NaT  VNM_07_Oct_13_Oct_2024   \n",
       "1                    Off          NaT        NaT  VNM_07_Oct_13_Oct_2024   \n",
       "2                    Off          NaT        NaT  VNM_07_Oct_13_Oct_2024   \n",
       "3                    Off          NaT        NaT  VNM_07_Oct_13_Oct_2024   \n",
       "4                    Off          NaT        NaT  VNM_07_Oct_13_Oct_2024   \n",
       "...                  ...          ...        ...                     ...   \n",
       "44263          Open Time     06:30:00   09:30:00   VNM_9_Sep_15_Sep_2024   \n",
       "44264              Lunch     09:30:00   10:30:00   VNM_9_Sep_15_Sep_2024   \n",
       "44265          Open Time     10:30:00   11:45:00   VNM_9_Sep_15_Sep_2024   \n",
       "44266              Break     11:45:00   12:00:00   VNM_9_Sep_15_Sep_2024   \n",
       "44267          Open Time     12:00:00   13:00:00   VNM_9_Sep_15_Sep_2024   \n",
       "\n",
       "              Export time       Generate Date  ...  Datetime_End_Action  \\\n",
       "0     2024-10-17 00:49:06 2024-10-16 17:44:00  ...                  NaT   \n",
       "1     2024-10-17 00:49:06 2024-10-16 17:44:00  ...                  NaT   \n",
       "2     2024-10-17 00:49:06 2024-10-16 17:44:00  ...                  NaT   \n",
       "3     2024-10-17 00:49:06 2024-10-16 17:44:00  ...                  NaT   \n",
       "4     2024-10-17 00:49:06 2024-10-16 17:44:00  ...                  NaT   \n",
       "...                   ...                 ...  ...                  ...   \n",
       "44263 2024-10-17 00:51:22 2024-10-16 17:46:00  ...  2024-09-14 09:30:00   \n",
       "44264 2024-10-17 00:51:22 2024-10-16 17:46:00  ...  2024-09-14 10:30:00   \n",
       "44265 2024-10-17 00:51:22 2024-10-16 17:46:00  ...  2024-09-14 11:45:00   \n",
       "44266 2024-10-17 00:51:22 2024-10-16 17:46:00  ...  2024-09-14 12:00:00   \n",
       "44267 2024-10-17 00:51:22 2024-10-16 17:46:00  ...  2024-09-14 13:00:00   \n",
       "\n",
       "      Datetime_Fluctuate_Start_Shift  Datetime_Fluctuate_End_Shift  \\\n",
       "0                                NaT                           NaT   \n",
       "1                                NaT                           NaT   \n",
       "2                                NaT                           NaT   \n",
       "3                                NaT                           NaT   \n",
       "4                                NaT                           NaT   \n",
       "...                              ...                           ...   \n",
       "44263            2024-09-14 04:00:00           2024-09-14 13:00:00   \n",
       "44264            2024-09-14 04:00:00           2024-09-14 13:00:00   \n",
       "44265            2024-09-14 04:00:00           2024-09-14 13:00:00   \n",
       "44266            2024-09-14 04:00:00           2024-09-14 13:00:00   \n",
       "44267            2024-09-14 04:00:00           2024-09-14 13:00:00   \n",
       "\n",
       "      Fluctuate Shift  Datetime_First_Start_Shift Datetime_First_End_Shift  \\\n",
       "0                 NaN                         NaT                      NaT   \n",
       "1                 NaN                         NaT                      NaT   \n",
       "2                 NaN                         NaT                      NaT   \n",
       "3                 NaN                         NaT                      NaT   \n",
       "4                 NaN                         NaT                      NaT   \n",
       "...               ...                         ...                      ...   \n",
       "44263       0400-1300         2024-09-14 04:00:00      2024-09-14 13:00:00   \n",
       "44264       0400-1300         2024-09-14 04:00:00      2024-09-14 13:00:00   \n",
       "44265       0400-1300         2024-09-14 04:00:00      2024-09-14 13:00:00   \n",
       "44266       0400-1300         2024-09-14 04:00:00      2024-09-14 13:00:00   \n",
       "44267       0400-1300         2024-09-14 04:00:00      2024-09-14 13:00:00   \n",
       "\n",
       "      First Shift Datetime_Original_Start_Shift Datetime_Original_End_Shift  \\\n",
       "0             NaN                           NaT                         NaT   \n",
       "1             NaN                           NaT                         NaT   \n",
       "2             NaN                           NaT                         NaT   \n",
       "3             NaN                           NaT                         NaT   \n",
       "4             NaN                           NaT                         NaT   \n",
       "...           ...                           ...                         ...   \n",
       "44263   0400-1300           2024-09-14 04:00:00         2024-09-14 13:00:00   \n",
       "44264   0400-1300           2024-09-14 04:00:00         2024-09-14 13:00:00   \n",
       "44265   0400-1300           2024-09-14 04:00:00         2024-09-14 13:00:00   \n",
       "44266   0400-1300           2024-09-14 04:00:00         2024-09-14 13:00:00   \n",
       "44267   0400-1300           2024-09-14 04:00:00         2024-09-14 13:00:00   \n",
       "\n",
       "      Original Shift  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "...              ...  \n",
       "44263      0400-1300  \n",
       "44264      0400-1300  \n",
       "44265      0400-1300  \n",
       "44266      0400-1300  \n",
       "44267      0400-1300  \n",
       "\n",
       "[44243 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_max_generate_date['Start_Shift'] = pd.to_datetime(filtered_max_generate_date['Start_Shift'], format='%I:%M %p', errors='coerce').dt.time\n",
    "filtered_max_generate_date['End_Shift'] = pd.to_datetime(filtered_max_generate_date['End_Shift'], format='%I:%M %p', errors='coerce').dt.time\n",
    "filtered_max_generate_date['Start_Action'] = pd.to_datetime(filtered_max_generate_date['Start_Action'], format='%I:%M %p', errors='coerce').dt.time\n",
    "filtered_max_generate_date['End_Action'] = pd.to_datetime(filtered_max_generate_date['End_Action'], format='%I:%M %p', errors='coerce').dt.time\n",
    "\n",
    "def create_datetime(row, time_column, shift_column=None):\n",
    "    if row['Scheduled'] == 0:\n",
    "        return pd.NaT\n",
    "    if pd.isnull(row['Date']) or pd.isnull(row[time_column]):\n",
    "        return pd.NaT\n",
    "    time_value = row[time_column]\n",
    "    if shift_column and pd.isnull(row[shift_column]):\n",
    "        return pd.NaT\n",
    "    if shift_column and time_value < row[shift_column]:\n",
    "        return pd.Timestamp.combine(row['Date'], time_value) + pd.DateOffset(days=1)\n",
    "    return pd.Timestamp.combine(row['Date'], time_value)\n",
    "\n",
    "filtered_max_generate_date = filtered_max_generate_date.drop(filtered_max_generate_date[(filtered_max_generate_date['Scheduled Activity'].isin(['Lunch', 'Break','Training'])) & (filtered_max_generate_date['Scheduled'] == 0)].index)\n",
    "\n",
    "filtered_max_generate_date['Datetime_Start_Action'] = filtered_max_generate_date.apply(lambda row: create_datetime(row, 'Start_Action', 'Start_Shift'), axis=1)\n",
    "filtered_max_generate_date['Datetime_End_Action'] = filtered_max_generate_date.apply(lambda row: create_datetime(row, 'End_Action', 'Start_Shift'), axis=1)\n",
    "\n",
    "filtered_fluctuate_shifts = filtered_max_generate_date[\n",
    "    filtered_max_generate_date['Scheduled Activity'].isin([\"Open Time\", \"Extra Hours\"]) | \n",
    "    filtered_max_generate_date['Scheduled Activity'].str.contains(\"Training\", na=False)\n",
    "]\n",
    "min_max_fluctuate_shifts = filtered_fluctuate_shifts.groupby(['Date', 'IEX_ID']).agg(\n",
    "    Datetime_Fluctuate_Start_Shift=('Datetime_Start_Action', 'min'),\n",
    "    Datetime_Fluctuate_End_Shift=('Datetime_End_Action', 'max')\n",
    ").reset_index()\n",
    "min_max_fluctuate_shifts['Fluctuate Shift'] = (min_max_fluctuate_shifts['Datetime_Fluctuate_Start_Shift'].dt.strftime('%H%M') + '-' + min_max_fluctuate_shifts['Datetime_Fluctuate_End_Shift'].dt.strftime('%H%M'))\n",
    "new_table_with_fluctuate_shifts_col = pd.merge(filtered_max_generate_date, min_max_fluctuate_shifts, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "\n",
    "min_max_first_shifts = filtered_max_generate_date.groupby(['Date', 'IEX_ID']).agg(\n",
    "    Datetime_First_Start_Shift=('Datetime_Start_Action', 'min'),\n",
    "    Datetime_First_End_Shift=('Datetime_End_Action', 'max')\n",
    ").reset_index()\n",
    "min_max_first_shifts['First Shift'] = (min_max_first_shifts['Datetime_First_Start_Shift'].dt.strftime('%H%M') + '-' + min_max_first_shifts['Datetime_First_End_Shift'].dt.strftime('%H%M'))\n",
    "new_table_with_first_shifts_col = pd.merge(new_table_with_fluctuate_shifts_col, min_max_first_shifts, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "filtered_original_shifts = filtered_max_generate_date[\n",
    "    filtered_max_generate_date['Scheduled Activity'].isin([\"Open Time\"]) | \n",
    "    filtered_max_generate_date['Scheduled Activity'].str.contains(\"Training\", na=False)\n",
    "]\n",
    "min_max_original_shifts = filtered_original_shifts.groupby(['Date', 'IEX_ID']).agg(\n",
    "    Datetime_Original_Start_Shift=('Datetime_Start_Action', 'min'),\n",
    "    Datetime_Original_End_Shift=('Datetime_End_Action', 'max')\n",
    ").reset_index()\n",
    "min_max_original_shifts['Original Shift'] = (min_max_original_shifts['Datetime_Original_Start_Shift'].dt.strftime('%H%M') + '-' + min_max_original_shifts['Datetime_Original_End_Shift'].dt.strftime('%H%M'))\n",
    "new_table_with_original_shifts_col = pd.merge(new_table_with_first_shifts_col, min_max_original_shifts, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "new_table_with_original_shifts_col = new_table_with_original_shifts_col[\n",
    "    ~(\n",
    "        (new_table_with_original_shifts_col['Scheduled Activity'].isin([\"Lunch\", \"Break\"])) & \n",
    "        new_table_with_original_shifts_col['Fluctuate Shift'].isna()\n",
    "    )\n",
    "]\n",
    "\n",
    "new_table_with_original_shifts_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_generate_date = new_table_with_original_shifts_col.sort_values(by='Export time', ascending=True)\n",
    "\n",
    "sorted_generate_date['Night_Shift'] = sorted_generate_date['Datetime_First_Start_Shift'].apply(lambda x: 1 if pd.to_datetime(x).hour >= 18 else 0)\n",
    "sorted_generate_date['Week_Monday'] = sorted_generate_date['Date'] - pd.to_timedelta(sorted_generate_date['Date'].dt.weekday, unit='d')\n",
    "sorted_generate_date['Week Begin'] = sorted_generate_date['Week_Monday'].dt.strftime('WB%d%m')\n",
    "sorted_generate_date['Agent Name'] = sorted_generate_date['Agent'].str.extract(r'\\d+ (.+)', expand=False).str.upper()\n",
    "sorted_generate_date['Duration'] = (sorted_generate_date['Datetime_End_Action'] - sorted_generate_date['Datetime_Start_Action']).dt.total_seconds()\n",
    "\n",
    "def calculate_total_time(df, activity_list, time_column_name):\n",
    "    time_totals = df[df['Scheduled Activity'].isin(activity_list)]\n",
    "    time_totals = time_totals.groupby(['Date', 'IEX_ID'])['Duration'].sum().reset_index()\n",
    "    time_totals.rename(columns={'Duration': time_column_name}, inplace=True)\n",
    "    time_totals[time_column_name] = time_totals[time_column_name] / 3600\n",
    "    return time_totals\n",
    "\n",
    "open_time_totals = calculate_total_time(sorted_generate_date, ['Open Time'], 'Open Time')\n",
    "sorted_generate_date = sorted_generate_date.merge(open_time_totals, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "rest_time_totals = calculate_total_time(sorted_generate_date, ['Break', 'Lunch'], 'Rest Time')\n",
    "sorted_generate_date = sorted_generate_date.merge(rest_time_totals, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "extra_time_totals = calculate_total_time(sorted_generate_date, ['Extra Hours'], 'Extra Time')\n",
    "sorted_generate_date = sorted_generate_date.merge(extra_time_totals, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "ncns_time_totals = calculate_total_time(sorted_generate_date, ['No Call/No Show'], 'NCNS')\n",
    "sorted_generate_date = sorted_generate_date.merge(ncns_time_totals, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "training_time_totals = calculate_total_time(sorted_generate_date, ['Training Offline','Training','Training Nesting'], 'Training')\n",
    "sorted_generate_date = sorted_generate_date.merge(training_time_totals, on=['Date', 'IEX_ID'], how='left')\n",
    "\n",
    "sorted_generate_date = sorted_generate_date.sort_values(by=['Date', 'IEX_ID', 'Datetime_Start_Action'])\n",
    "sorted_generate_date['First_Scheduled_Activity'] = sorted_generate_date.groupby(['Date', 'IEX_ID'])['Scheduled Activity'].transform('first')\n",
    "\n",
    "sorted_generate_date['Shift Tracking'] = np.where(\n",
    "    (sorted_generate_date['Open Time'] > 0) & (sorted_generate_date['NCNS'] > 3),\n",
    "    \"HDL\",\n",
    "    np.where(\n",
    "        ((sorted_generate_date['Open Time'] > 0) | (sorted_generate_date['Open Time'].isna())) & (sorted_generate_date['NCNS'] > 3),\n",
    "        \"UPL\",\n",
    "        np.where(\n",
    "            (sorted_generate_date['Open Time'] > 0) & (sorted_generate_date['Extra Time'] > 0),\n",
    "            \"PR - OT\",\n",
    "            np.where(\n",
    "                (sorted_generate_date['Open Time'] == 0) & (sorted_generate_date['Extra Time'] > 0),\n",
    "                \"PO\",\n",
    "                np.where(\n",
    "                    (sorted_generate_date['Open Time'] > 0),\n",
    "                    \"PR\",\n",
    "                    np.where(\n",
    "                        sorted_generate_date['First_Scheduled_Activity'] == \"Extra Hours\",\n",
    "                        np.where(\n",
    "                            sorted_generate_date['Open Time'].isna(),\n",
    "                            \"PO\",\n",
    "                            np.nan\n",
    "                        ),\n",
    "                        np.where(\n",
    "                            sorted_generate_date['First_Scheduled_Activity'].isin([\"Holiday\", \"Bereavement\", \"Off\", \"Off Phone Misc\", \"Termination\", \"Unscheduled\"]),\n",
    "                            sorted_generate_date['First_Scheduled_Activity'],\n",
    "                            np.where(\n",
    "                                sorted_generate_date['First_Scheduled_Activity'] == \"PTO\",\n",
    "                                \"AL\",\n",
    "                                np.where(\n",
    "                                    sorted_generate_date['First_Scheduled_Activity'] == \"Sickness\",\n",
    "                                    \"SL\",\n",
    "                                    np.nan\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ot_pre_post_shift(df):\n",
    "    extra_hours_df = df[df['Scheduled Activity'] == 'Extra Hours']\n",
    "    \n",
    "    ot_df = df[['Date', 'IEX_ID']].drop_duplicates()\n",
    "    \n",
    "    def calculate_duration_for_group(group_df, date, iex_id, shift_start, shift_end):\n",
    "        pre_shift_duration = extra_hours_df[\n",
    "            (extra_hours_df['Date'] == date) & \n",
    "            (extra_hours_df['IEX_ID'] == iex_id) & \n",
    "            (extra_hours_df['Datetime_Start_Action'] < shift_start)\n",
    "        ]['Duration'].sum()\n",
    "        \n",
    "        post_shift_duration = extra_hours_df[\n",
    "            (extra_hours_df['Date'] == date) & \n",
    "            (extra_hours_df['IEX_ID'] == iex_id) & \n",
    "            (extra_hours_df['Datetime_End_Action'] > shift_end)\n",
    "        ]['Duration'].sum()\n",
    "        \n",
    "        return pre_shift_duration, post_shift_duration\n",
    "    \n",
    "    ot_df[['OT PreShift Seconds', 'OT PostShift Seconds']] = ot_df.apply(\n",
    "        lambda row: pd.Series(\n",
    "            calculate_duration_for_group(\n",
    "                extra_hours_df, \n",
    "                row['Date'], \n",
    "                row['IEX_ID'], \n",
    "                df[(df['Date'] == row['Date']) & (df['IEX_ID'] == row['IEX_ID'])]['Datetime_Original_Start_Shift'].min(),\n",
    "                df[(df['Date'] == row['Date']) & (df['IEX_ID'] == row['IEX_ID'])]['Datetime_Original_End_Shift'].max()\n",
    "            )\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "    ot_df['OT PreShift'] = ot_df['OT PreShift Seconds'] / 3600\n",
    "    ot_df['OT PostShift'] = ot_df['OT PostShift Seconds'] / 3600\n",
    "    \n",
    "    ot_df = ot_df.drop(columns=['OT PreShift Seconds', 'OT PostShift Seconds'])\n",
    "    df = df.merge(ot_df, on=['Date', 'IEX_ID'], how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "OT_Pre_Post_Table = calculate_ot_pre_post_shift(sorted_generate_date)\n",
    "OT_Pre_Post_Table = OT_Pre_Post_Table.groupby(['Date', 'IEX_ID'])[['OT PreShift', 'OT PostShift']].max().reset_index()\n",
    "\n",
    "combine_OT_Pre_Post_Table = pd.merge(sorted_generate_date, OT_Pre_Post_Table, on=['Date','IEX_ID'], how='left')\n",
    "combine_OT_Pre_Post_Table['Start Date'] = pd.to_datetime(combine_OT_Pre_Post_Table['Datetime_Start_Action']).dt.normalize()\n",
    "combine_OT_Pre_Post_Table['End Date'] = pd.to_datetime(combine_OT_Pre_Post_Table['Datetime_End_Action']).dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1085749366.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = sorted_df.groupby(['Date', 'IEX_ID']).apply(label_breaks)\n"
     ]
    }
   ],
   "source": [
    "# Select the desired columns\n",
    "iex_ids_with_max_export_time = combine_OT_Pre_Post_Table[['sheet_name', 'Generate Date','Year','Month','Week Begin','Date','Start Date','End Date','Agent Name', 'IEX_ID','Datetime_Fluctuate_Start_Shift',\n",
    "       'Datetime_Fluctuate_End_Shift', 'Fluctuate Shift',\n",
    "       'Datetime_First_Start_Shift', 'Datetime_First_End_Shift',\n",
    "       'First Shift','Scheduled Activity','Datetime_Start_Action','Datetime_End_Action','Duration','Open Time','Extra Time','Rest Time','Training','NCNS','Night_Shift', 'Scheduled','Shift Tracking','OT PreShift', 'OT PostShift']]\n",
    "\n",
    "sorted_df = iex_ids_with_max_export_time.sort_values(\n",
    "    by=[ 'Date','IEX_ID','Datetime_Start_Action'],\n",
    "    ascending=[ True, True,True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "sorted_df = sorted_df.drop_duplicates()\n",
    "\n",
    "def label_breaks(group):\n",
    "    group.loc[group['Scheduled Activity'] == 'Break', 'Scheduled Activity'] = (\n",
    "        group['Scheduled Activity'] + '_' + (group['Scheduled Activity'].eq('Break').cumsum()).astype(str)\n",
    "    )\n",
    "    return group\n",
    "\n",
    "sorted_df = sorted_df.groupby(['Date', 'IEX_ID']).apply(label_breaks)\n",
    "sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "sorted_df['Date'] = sorted_df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'Datetime_{col}_Action'].dt.hour + \\\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'{col}_Time_Hours'].round(2)\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'Datetime_{col}_Action'].dt.hour + \\\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Hours'] = split_table[f'{col}_Time_Hours'].round(2)\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table['End_Time_Hours'] = split_table.apply(\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Half_Rounding'] = split_table[f'{col}_Time_Hours'].apply(\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table[f'{col}_Time_Half_Rounding'] = split_table[f'{col}_Time_Hours'].apply(\n",
      "C:\\Users\\huuchinh.nguyen\\AppData\\Local\\Temp\\ipykernel_25864\\1231678368.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_table['Number_Split'] = split_table.apply(\n",
      "c:\\Users\\huuchinh.nguyen\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    }
   ],
   "source": [
    "split_table = sorted_df[['Date', 'Start Date', 'End Date', 'IEX_ID', 'Agent Name', 'Scheduled Activity', 'Datetime_Start_Action', 'Datetime_End_Action']]\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time_Hours'] = split_table[f'Datetime_{col}_Action'].dt.hour + \\\n",
    "                                       split_table[f'Datetime_{col}_Action'].dt.minute / 60 + \\\n",
    "                                        split_table[f'Datetime_{col}_Action'].dt.second / 3600\n",
    "    split_table[f'{col}_Time_Hours'] = split_table[f'{col}_Time_Hours'].round(2)\n",
    "\n",
    "split_table['End_Time_Hours'] = split_table.apply(\n",
    "    lambda row: row['End_Time_Hours'] + 24 if row['End_Time_Hours'] < row['Start_Time_Hours'] else row['End_Time_Hours'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time_Half_Rounding'] = split_table[f'{col}_Time_Hours'].apply(\n",
    "        lambda x: np.round(x * 2) / 2 if np.round(x * 2) / 2 == x else np.floor(x * 2) / 2\n",
    "    )\n",
    "\n",
    "split_table['Number_Split'] = split_table.apply(\n",
    "    lambda row: (row['End_Time_Half_Rounding'] - row['Start_Time_Half_Rounding']) * 2 \n",
    "    if pd.notna(row['End_Time_Half_Rounding']) and pd.notna(row['Start_Time_Half_Rounding']) \n",
    "    else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "split_table = split_table.rename(columns={'Start_Time_Half_Rounding': 'Time_1'})\n",
    "split_table['Time_2'] = split_table['Time_1'] + 0.5\n",
    "split_table['Custom'] = split_table['Number_Split'].apply(lambda n: list(range(int(n) + 1)) if pd.notna(n) else [])\n",
    "split_table = split_table.explode('Custom')\n",
    "\n",
    "split_table['Time_1_New'] = split_table['Time_1'] + (split_table['Custom'] * 0.5)\n",
    "split_table['Time_2_New'] = split_table['Time_2'] + (split_table['Custom'] * 0.5)\n",
    "split_table['Rounded_End_Time_Hours'] = np.ceil(split_table['End_Time_Hours'] * 2) / 2\n",
    "\n",
    "filtered_df = split_table[split_table['Rounded_End_Time_Hours'] > split_table['Time_1_New']]\n",
    "\n",
    "split_table['Start_Time_Number'] = np.where(\n",
    "    split_table['Time_1_New'] > split_table['Start_Time_Hours'],\n",
    "    split_table['Time_1_New'],\n",
    "    split_table['Start_Time_Hours']\n",
    ")\n",
    "\n",
    "split_table['End_Time_Number'] = np.where(\n",
    "    split_table['Time_2_New'] < split_table['End_Time_Hours'],\n",
    "    split_table['Time_2_New'],\n",
    "    split_table['End_Time_Hours']\n",
    ")\n",
    "\n",
    "def calculate_new_day_time(row, time_col, date_col):\n",
    "    calculated_value = row[time_col]\n",
    "    if row['Start Date'] == row['End Date']:\n",
    "        return row[date_col]\n",
    "    else:\n",
    "        if time_col == 'Start_Time_Number' and calculated_value >= 24:\n",
    "            return row['Start Date'] + pd.Timedelta(days=1)\n",
    "        elif time_col == 'End_Time_Number' and calculated_value < 24:\n",
    "            return row['End Date'] - pd.Timedelta(days=1)\n",
    "        else:\n",
    "            return row[date_col]\n",
    "\n",
    "split_table['New_Day_Start_Time'] = split_table.apply(lambda row: calculate_new_day_time(row, 'Start_Time_Number', 'Start Date'), axis=1)\n",
    "split_table['New_Day_End_Time'] = split_table.apply(lambda row: calculate_new_day_time(row, 'End_Time_Number', 'End Date'), axis=1)\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time_Number'] = (split_table[f'{col}_Time_Number'] - 24 * (split_table[f'{col}_Time_Number'] >= 24)) % 24\n",
    "\n",
    "def number_to_time(number):\n",
    "    if pd.isna(number):\n",
    "        return pd.NaT\n",
    "    hours = int(np.floor(number))\n",
    "    minutes = int(np.floor((number - hours) * 60))\n",
    "    seconds = int(np.floor((number - hours - minutes / 60) * 3600))\n",
    "    return pd.Timestamp(f\"1970-01-01 {hours:02}:{minutes:02}:{seconds:02}\")\n",
    "\n",
    "for col in ['Start', 'End']:\n",
    "    split_table[f'{col}_Time'] = split_table[f'{col}_Time_Number'].apply(number_to_time).dt.time\n",
    "\n",
    "def combine_date_time(row, time_col, date_col):\n",
    "    if pd.isna(row[time_col]):\n",
    "        return pd.NaT\n",
    "    return datetime.combine(row[date_col].date(), row[time_col])\n",
    "\n",
    "split_table['Datetime_Start_Time'] = split_table.apply(lambda row: combine_date_time(row, 'Start_Time', 'New_Day_Start_Time'), axis=1)\n",
    "split_table['Datetime_End_Time'] = split_table.apply(lambda row: combine_date_time(row, 'End_Time', 'New_Day_End_Time'), axis=1)\n",
    "\n",
    "split_table = split_table[split_table['Datetime_Start_Time'] < split_table['Datetime_End_Time']]\n",
    "split_table = split_table[['Date', 'Start Date', 'End Date', 'IEX_ID', 'Agent Name', 'Scheduled Activity', 'Datetime_Start_Action', 'Datetime_End_Action', 'Datetime_Start_Time', 'Datetime_End_Time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 10, 17)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "from datetime import date\n",
    "\n",
    "all_sheets = {'1. INTERVALS_EXTEND': split_table,\n",
    "            '2. IEX_EXTEND': sorted_df}\n",
    "\n",
    "today_temp = datetime.today().date()\n",
    "today = today_temp.strftime('%b_%d_%Y')\n",
    "\n",
    "writer = pd.ExcelWriter(f'3. OUTPUT/{today}_IEX_DAILY_OUTPUT.xlsx', engine='xlsxwriter')\n",
    "for sheet_name in all_sheets.keys():\n",
    "    all_sheets[sheet_name].to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "writer.close()\n",
    "today_temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
