{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import polars as pl\n",
    "import fastexcel\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(struct_time):\n",
    "    \"\"\"Convert struct_time to datetime object.\"\"\"\n",
    "    return datetime(*struct_time[:6])\n",
    "\n",
    "def input_data(folder_path, sheet_name=None):\n",
    "    file_paths = glob.glob(f\"{folder_path}/*.xlsx\") + glob.glob(f\"{folder_path}/*.csv\")\n",
    "    df_list = []\n",
    "\n",
    "    for file in file_paths:\n",
    "        # Get last modified time and convert to datetime\n",
    "        export_time = os.path.getmtime(file)\n",
    "        export_time_datetime = convert_to_datetime(time.localtime(export_time))\n",
    "\n",
    "        # Read file\n",
    "        if file.endswith('.xlsx'):\n",
    "            df = pl.read_excel(file, sheet_name=sheet_name)\n",
    "        elif file.endswith('.csv'):\n",
    "            try:\n",
    "                df = pl.read_csv(file, encoding=\"utf-8\")\n",
    "            except:\n",
    "                df = pl.read_csv(file, encoding=\"ISO-8859-1\", ignore_errors=True)\n",
    "\n",
    "        # Cast all columns to string\n",
    "        df = df.with_columns([\n",
    "            pl.col(col).cast(pl.String)\n",
    "            for col in df.columns\n",
    "        ])\n",
    "\n",
    "        # Add file metadata columns\n",
    "        df = df.with_columns([\n",
    "            pl.lit(os.path.basename(file)).alias('File Name'),\n",
    "            pl.lit(export_time_datetime).alias('Export Time')\n",
    "        ])\n",
    "\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    if df_list:\n",
    "        merged_df = pl.concat(df_list, how='vertical')\n",
    "    else:\n",
    "        merged_df = pl.DataFrame()\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "today_temp = datetime.today().date()\n",
    "today = today_temp.strftime('%b_%d_%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_glob_1 = \"C:/Users/huuchinh.nguyen\"\n",
    "first_glob_2 = \"C:/Users/ADMIN\"\n",
    "\n",
    "if os.path.exists(first_glob_1):\n",
    "    first_glob = first_glob_1\n",
    "elif os.path.exists(first_glob_2):\n",
    "    first_glob = first_glob_2\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Neither {first_glob_1} nor {first_glob_2} exists.\")\n",
    "\n",
    "folder_paths = {\n",
    "    \"input_performance\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Rawdata/RETAIL_PERFORMANCE',\n",
    "    \"output_performance_combine\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Rawdata/OUTPUT_PERFORMANCE/OUTPUT_PERFORMANCE_COMBINE',\n",
    "    \"output_performance_compare\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Rawdata/OUTPUT_PERFORMANCE/OUTPUT_PERFORMANCE_COMPARE',\n",
    "    \"hc_extend_by_month\":f'{first_glob}/Concentrix Corporation/WFM-Expedia-HCM - Branding files/Headcount/HC Extend by Month'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 46, falling back to string\n",
      "Could not determine dtype for column 48, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 48, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 48, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n",
      "Could not determine dtype for column 63, falling back to string\n",
      "Could not determine dtype for column 64, falling back to string\n",
      "Could not determine dtype for column 65, falling back to string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Month', 'Site', 'Queue Group', 'Week Begin', 'Date Start Month', 'Date End Month', 'Week_Monday', 'Date End Week', 'Week', 'Day', 'Date', 'OracleID', 'People ID', 'IEX ID', 'Employee Name', 'Alias', 'Gender', 'Designation', 'Grade', 'LOB', 'Role', 'Multiple Chat Effective Date', 'Primary role', 'Secondary role', 'TL ID', 'Supervisor Name', 'Manager/OM Name', 'Email Id', 'Wave', 'CCT Training', 'Lodging Training', 'Lodging Nesting', 'Lodging Extended Nesting', 'CSG Joining Date', 'Lodging Production', 'NonLodging Training', 'NonLodging Nesting', 'NonLodging Extended Nesting', 'NonLodging Production', 'Production', 'LWD/Movement', 'Reason for Attrition', 'Attrition Type', 'ATT_Reason_LV3', 'Detail Status', 'AON', 'LG Tenure', 'NL Tenure', 'Concurrency', 'Status', 'LOB_2', 'LOB_3', 'Performance_Calculation', 'Stage', 'HC Open By Week', 'HC Closed By Week', 'HC Open By Month', 'HC Closed By Month', 'ATT/Movement', 'ATT', 'Movement', 'CSG', 'Mini TL - Email', 'Mini TL - Short Name', 'Mini TL Start Date', 'File Name', 'Export Time']\n"
     ]
    }
   ],
   "source": [
    "PERFORMANCE_INPUT = input_data(folder_paths[\"input_performance\"])\n",
    "\n",
    "existing_cols = set(PERFORMANCE_INPUT.columns)\n",
    "\n",
    "columns_to_cast = {\n",
    "    \"NPS Raw Score\": pl.Int64,\n",
    "    \"Submitted Date\": pl.Date,\n",
    "    \"Started Time\": pl.Datetime,\n",
    "    \"Joined Time\": pl.Datetime,\n",
    "    \"Submitted Time\": pl.Datetime,\n",
    "    \"Left Time\": pl.Datetime,\n",
    "    \"Handle Time (Sum)\": pl.Float64,\n",
    "    \"Hold Time (Sum)\": pl.Float64,\n",
    "    \"Talk Time (Sum)\": pl.Float64,\n",
    "    \"Wrap Up Time (Sum)\": pl.Float64,\n",
    "    \"CCR15\": pl.Int64,\n",
    "    \"CCR24\": pl.Int64,\n",
    "    \"CCR48\": pl.Int64,\n",
    "    \"CCR72\": pl.Int64,\n",
    "    \"Survey Submitted (Count)\": pl.Int64,\n",
    "    \"Response Time (Sum)\": pl.Float64,\n",
    "    \"Response Time (Avg)\": pl.Float64,\n",
    "    \"Concurrency\": pl.Float64,\n",
    "}\n",
    "\n",
    "datetime_cols = [\"Started Time\", \"Joined Time\", \"Submitted Time\", \"Left Time\"]\n",
    "\n",
    "casts = []\n",
    "\n",
    "for col, dtype in columns_to_cast.items():\n",
    "    if col in existing_cols:\n",
    "        if col == \"Submitted Date\":\n",
    "            casts.append(pl.col(col).str.strptime(pl.Date, \"%m/%d/%Y\", strict=False))\n",
    "        elif col in datetime_cols:\n",
    "            casts.append(\n",
    "                pl.when(pl.col(col).str.contains(r\"^\\d{4}-\\d{2}-\\d{2}\"))  # ISO: YYYY-MM-DD\n",
    "                  .then(pl.col(col).str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\", strict=False))\n",
    "                .when(pl.col(col).str.contains(r\"^\\d{1,2}/\\d{1,2}/\\d{4}\"))  # US: M/D/YYYY\n",
    "                  .then(pl.col(col).str.strptime(pl.Datetime, \"%m/%d/%Y %H:%M\", strict=False))\n",
    "                .otherwise(None)\n",
    "                .alias(col)\n",
    "            )\n",
    "        elif dtype == pl.Float64:\n",
    "            casts.append(pl.col(col).str.replace_all(\",\", \"\").cast(pl.Float64))\n",
    "        else:\n",
    "            casts.append(pl.col(col).cast(dtype))\n",
    "\n",
    "PERFORMANCE_CHANGED_TYPE = PERFORMANCE_INPUT.with_columns(casts)\n",
    "\n",
    "PERFORMANCE_NEXT_STEP = PERFORMANCE_CHANGED_TYPE.with_columns([\n",
    "    pl.col(\"Joined Time\").dt.date().alias(\"Joined Date\")\n",
    "])\n",
    "\n",
    "PERFORMANCE_NEXT_STEP = PERFORMANCE_NEXT_STEP.with_columns([\n",
    "    (pl.col(\"Joined Time\") + pl.duration(hours=14)).alias(\"Join Time (VNT)\"),\n",
    "    (pl.col(\"Joined Time\") + pl.duration(hours=14)).dt.date().alias(\"Join Date (VNT)\")\n",
    "])\n",
    "\n",
    "HC_MASTER_DATABASE = input_data(folder_paths[\"hc_extend_by_month\"])\n",
    "HC_MASTER_DATABASE = HC_MASTER_DATABASE.rename({'Date Start Week': 'Week_Monday'})\n",
    "\n",
    "HC_MASTER_DATABASE = HC_MASTER_DATABASE.with_columns([\n",
    "    pl.col('Date').str.strptime(pl.Date, \"%Y-%m-%d\", strict=False)\n",
    "])\n",
    "print(HC_MASTER_DATABASE.columns)\n",
    "hc_master_selected = HC_MASTER_DATABASE.select([\n",
    "    \"Date\",\"Email Id\", \"OracleID\", \"People ID\", \"IEX ID\", \"Employee Name\", \"Alias\", \"Designation\", \n",
    "    \"Supervisor Name\", \"Wave\", \"LOB\", 'LG Tenure', 'NL Tenure', \"AON\", 'Mini TL - Email', 'Mini TL - Short Name', 'Mini TL Start Date'\n",
    "]).unique()\n",
    "hc_master_selected = hc_master_selected.rename({'Mini TL - Short Name': 'Mini TL'})\n",
    "performance_merged = PERFORMANCE_NEXT_STEP.join(\n",
    "    hc_master_selected,\n",
    "    left_on=[\"Joined Date\",\"Agent Email ID\"],\n",
    "    right_on=[\"Date\",\"Email Id\"],\n",
    "    how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Agent Vendor Location', 'Latest VA Product', 'Language', 'Queue Name', 'Channel Type', 'Latest VA Intent', 'Conversation Id', 'Initiated Outbound (Yes / No)', 'NPS Raw Score', 'Channel Address', 'Submitted Date', 'Has Followup Agent Assisted (Yes / No)', 'Answer', 'Customer Engagement', 'Agent Queue Group Name', 'Has Followup Within 72 Hours (Yes / No)', 'Started Time', 'Joined Time', 'Agent Email ID', 'Requeued (Yes / No)', 'Question Category', 'Submitted Time', 'Ended Time', 'Left Time', 'Completed (Yes/No)', 'Close Reason', 'Chat Agent First Response Time', 'Participant Joined Half Hour Interval', 'Handle Time (Sum)', 'Hold Time (Sum)', 'Talk Time (Sum)', 'Wrap Up Time (Sum)', 'Conversation Agent Disconnect', 'Conversation System Disconnect', 'Short Conversation Count', 'CCR15', 'CCR24', 'Survey Submitted (Count)', 'Response Time (Sum)', 'Response Time (Avg)', 'CCR48', 'CCR72', 'Concurrency', 'File Name', 'Export Time', 'Joined Date', 'Join Time (VNT)', 'Join Date (VNT)', 'OracleID', 'People ID', 'IEX ID', 'Employee Name', 'Alias', 'Designation', 'Supervisor Name', 'Wave', 'LOB', 'LG Tenure', 'NL Tenure', 'AON', 'Mini TL - Email', 'Mini TL', 'Mini TL Start Date', '_lc', '_aob', '_promoter', '_detractor', '_neutral', '_survey', '_fup_72', '_rr', '_PST.Date', '_PST.Month', '_PST.Week', '_PST.Year', '_conver_unique', 'Agent', '_Date', 'Interval Joined', 'Tenure', '_nps_type']\n"
     ]
    }
   ],
   "source": [
    "performance_processed = performance_merged.with_columns([\n",
    "    pl.when(\n",
    "        (pl.col(\"Handle Time (Sum)\") >= 1500) & (pl.col(\"LOB\") == \"Lodging\")\n",
    "        | (pl.col(\"Handle Time (Sum)\") >= 2700) & (pl.col(\"LOB\") == \"Non_Lodging\")\n",
    "    )\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"_lc\"),\n",
    "    \n",
    "    pl.when(pl.col(\"Initiated Outbound (Yes / No)\") == \"Yes\")\n",
    "      .then(1)\n",
    "      .otherwise(0)\n",
    "      .alias(\"_aob\"),\n",
    "\n",
    "    pl.when(pl.col(\"NPS Raw Score\").is_in([9, 10]))\n",
    "      .then(1)\n",
    "      .otherwise(0)\n",
    "      .alias(\"_promoter\"),\n",
    "\n",
    "    pl.when((pl.col(\"NPS Raw Score\").is_in([0,1,2,3,4,5,6])) & (pl.col(\"NPS Raw Score\") <= 6))\n",
    "      .then(1)\n",
    "      .otherwise(0)\n",
    "      .alias(\"_detractor\"),\n",
    "\n",
    "    pl.when(pl.col(\"NPS Raw Score\").is_in([7,8]))\n",
    "      .then(1)\n",
    "      .otherwise(0)\n",
    "      .alias(\"_neutral\"),\n",
    "\n",
    "    pl.col(\"Survey Submitted (Count)\").alias(\"_survey\"),\n",
    "    pl.col(\"CCR72\").alias(\"_fup_72\"),\n",
    "    (1 - pl.col(\"CCR72\")).alias(\"_rr\"),\n",
    "\n",
    "    pl.col(\"Joined Time\").dt.date().alias(\"_PST.Date\"),\n",
    "    pl.col(\"Joined Time\").dt.strftime(\"%y_%m\").alias(\"_PST.Month\"),\n",
    "    pl.col(\"Joined Time\").dt.week().alias(\"_PST.Week\"),\n",
    "    pl.col(\"Joined Time\").dt.year().alias(\"_PST.Year\"),\n",
    "    pl.concat_str([\n",
    "        pl.col(\"Agent Email ID\").cast(pl.Utf8),\n",
    "        pl.col(\"Conversation Id\").cast(pl.Utf8),\n",
    "        pl.col(\"Joined Time\").dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    ]).alias(\"_conver_unique\"),\n",
    "    pl.when(pl.col(\"LOB\").is_in([\"Non_Lodging\",\"Lodging\"]))\n",
    "      .then(pl.lit(\"agent\"))\n",
    "      .otherwise(0)\n",
    "      .alias(\"Agent\"),\n",
    "    pl.col(\"Joined Date\").alias(\"_Date\"),\n",
    "    pl.col(\"Participant Joined Half Hour Interval\").alias(\"Interval Joined\"),\n",
    "    pl.when(pl.col(\"LOB\") == \"Lodging\")\n",
    "      .then(pl.col(\"LG Tenure\"))\n",
    "      .when(pl.col(\"LOB\") == \"Non_Lodging\")\n",
    "      .then(pl.col(\"NL Tenure\"))\n",
    "      .otherwise(None)\n",
    "      .alias(\"Tenure\"),\n",
    "    pl.when(\n",
    "        pl.col(\"Agent Queue Group Name\").is_in([\"Chat_OD_EN_Lodging\", \"Chat_OD_EN_Car_Activity\"])\n",
    "    )\n",
    "    .then(pl.lit(\"LG Chat\"))\n",
    "    .when(pl.col(\"Agent Queue Group Name\") == \"Chat_OD_EN_Dual_GDS\")\n",
    "    .then(pl.lit(\"NL Chat\"))\n",
    "    .otherwise(None)\n",
    "    .alias(\"LOB\")\n",
    "])\n",
    "\n",
    "performance_processed = performance_processed.with_columns([\n",
    "    pl.when(pl.col(\"_promoter\") == 1)\n",
    "      .then(pl.lit(\"promoter\"))\n",
    "    .when(pl.col(\"_detractor\") == 1)\n",
    "      .then(pl.lit(\"detractor\"))\n",
    "    .when(pl.col(\"_neutral\") == 1)\n",
    "      .then(pl.lit(\"neutral\"))\n",
    "    .otherwise(pl.lit(\"no_survey\"))\n",
    "    .alias(\"_nps_type\")\n",
    "])\n",
    "\n",
    "print(performance_processed.columns)\n",
    "\n",
    "selected_columns = [\n",
    "    \"Export Time\",\"File Name\",\"Latest VA Product\", \"Language\", \"Latest VA Intent\", \"Conversation Id\",\n",
    "    \"NPS Raw Score\", \"Interval Joined\", \"Answer\", \"Customer Engagement\",\n",
    "    \"Agent Queue Group Name\", \"Started Time\", \"Joined Time\", \"Agent Email ID\",\n",
    "    \"Requeued (Yes / No)\", \"Question Category\", \"Submitted Date\", \"Ended Time\",\n",
    "    \"Left Time\", \"Handle Time (Sum)\", \"Hold Time (Sum)\", \"Talk Time (Sum)\",\n",
    "    \"Wrap Up Time (Sum)\", \"Response Time (Sum)\", \"Response Time (Avg)\",\n",
    "    \"CCR72\", \"_PST.Date\", \"_PST.Month\", \"_PST.Year\", \"_aob\", \"LOB\",\n",
    "    \"_conver_unique\", \"_nps_type\", \"_promoter\", \"_detractor\", \"_neutral\",\n",
    "    \"_survey\", \"_PST.Week\", \"_lc\", \"AON\", \"Tenure\", \"OracleID\", \"People ID\",\n",
    "    \"IEX ID\", \"Employee Name\", \"Alias\", \"Designation\", \"Supervisor Name\",\n",
    "    \"Wave\", \"_Date\", \"Agent\",\"Mini TL - Email\", \"Mini TL\", \"Mini TL Start Date\"\n",
    "]\n",
    "\n",
    "performance_filtered = performance_processed.select(selected_columns)\n",
    "performance_filtered = performance_filtered.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25_04.csv', '25_06.csv', '25_05.csv', '25_02.csv', '25_03.csv']\n",
      "shape: (1, 2)\n",
      "┌─────────────────────┬─────────────────────┐\n",
      "│ Joined_Time_Min     ┆ Joined_Time_Max     │\n",
      "│ ---                 ┆ ---                 │\n",
      "│ datetime[μs]        ┆ datetime[μs]        │\n",
      "╞═════════════════════╪═════════════════════╡\n",
      "│ 2025-02-01 00:00:22 ┆ 2025-06-16 17:59:48 │\n",
      "└─────────────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "performance_unique = performance_filtered.filter(\n",
    "    pl.col(\"File Name\").str.replace(r\"\\.csv$\", \"\").str.contains(r\"^25_\\d{2}$\")\n",
    ")\n",
    "\n",
    "unique_file_names_list_1 = (performance_unique.select(\"File Name\").unique().to_series().to_list())\n",
    "joined_time_stats = performance_unique.select([pl.col(\"Joined Time\").min().alias(\"Joined_Time_Min\"),pl.col(\"Joined Time\").max().alias(\"Joined_Time_Max\")])\n",
    "print(unique_file_names_list_1)\n",
    "print(joined_time_stats)\n",
    "\n",
    "performance_unique = performance_unique.drop([\"Export Time\", \"File Name\"])\n",
    "performance_unique = performance_unique.unique()\n",
    "\n",
    "for month, group in performance_unique.group_by('_PST.Month'):\n",
    "    month_value = month[0]\n",
    "    file_name = f\"{month_value}.csv\"\n",
    "    file_path = os.path.join(folder_paths[\"output_performance_combine\"], file_name)\n",
    "    \n",
    "    group.write_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25_06_1.csv', '25_06_2.csv']\n"
     ]
    }
   ],
   "source": [
    "performance_duplicate = performance_filtered.filter(pl.col(\"File Name\").str.count_matches(\"_\").eq(2))\n",
    "\n",
    "unique_file_names_list_2 = (performance_duplicate.select(\"File Name\").unique().to_series().to_list())\n",
    "print(unique_file_names_list_2)\n",
    "\n",
    "performance_duplicate = performance_filtered.with_columns([\n",
    "    pl.col(\"Export Time\").dt.date().alias(\"Export Date\")\n",
    "])\n",
    "\n",
    "grouped = performance_duplicate.group_by([\"Export Date\", \"_PST.Month\"])\n",
    "\n",
    "for (export_date, month_value), group in grouped:\n",
    "    export_date_str = export_date.strftime(\"%Y-%m-%d\")\n",
    "    file_name = f\"{export_date_str}_{month_value}.csv\"\n",
    "    file_path = os.path.join(folder_paths[\"output_performance_compare\"], file_name)\n",
    "    group.write_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
