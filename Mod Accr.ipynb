{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import date, timedelta\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular / Appeal\n",
    "from_DATE = '2023-11-05'\n",
    "to_DATE = '2023-11-25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def convert_datetime(a):\n",
    "    date_formats = [\"%Y-%m-%d %H:%M:%S.%f\", \n",
    "                    \"%Y-%m-%d %H:%M:%S\", \n",
    "                    \"%m/%d/%Y %H:%M\",\n",
    "                    \"%m-%d-%Y %H:%M\", \n",
    "                    \"%m/%d/%Y\", \n",
    "                    \"%Y-%m-%d\", \n",
    "                    \"%H:%M.%f\",\n",
    "                    \"%m/%d/%Y %H:%M:%S\"] \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(str(a), fmt).strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    try:\n",
    "        return (datetime(1899, 12, 30) + timedelta(days=float(a))).strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if not re.match(\"\\d+:\\d+:\\d+(\\.\\d+)?\", str(a)):\n",
    "        return str(a)\n",
    "    return  \n",
    "     \n",
    "def input_data_excel( data_dir  ):\n",
    "    data_dir = data_dir\n",
    "    out_dir = '.'\n",
    "    list_files = []\n",
    "    for filename in pathlib.Path(data_dir).glob('**/*.xlsx'):\n",
    "        list_files.append(filename)\n",
    "    df1 = pd.concat(map(pd.read_excel, list_files),   ignore_index=True)\n",
    "    return df1\n",
    "\n",
    "def input_data_csv( data_dir  ):\n",
    "    data_dir = data_dir\n",
    "    out_dir = '.'\n",
    "    list_files = []\n",
    "    for filename in pathlib.Path(data_dir).glob('**/*.csv'):\n",
    "        list_files.append(filename)\n",
    "    df1 = pd.concat(map(pd.read_csv, list_files),   ignore_index=True)\n",
    "    return df1\n",
    "\n",
    "def input_data( data_dir  ):\n",
    "    data_dir = data_dir\n",
    "    out_dir = '.'\n",
    "    list_files = []\n",
    "    for filename in pathlib.Path(data_dir).glob('**/*.xlsx'):\n",
    "        df=pd.concat(pd.read_excel(filename,sheet_name=None, skiprows=0))\n",
    "        list_files.append(df)\n",
    "    df1 = pd.concat(map(lambda file: pd.read_csv(file), list_files), ignore_index=True)\n",
    "    return df1\n",
    "def filter_time(df, column_name, from_date, to_date, selected_columns):\n",
    "    filter_rawdata = df[(df[column_name].dt.strftime('%Y-%m-%d') >= from_date) & (df[column_name].dt.strftime('%Y-%m-%d') <= to_date)]\n",
    "    filter_rawdata = filter_rawdata[selected_columns]\n",
    "    return filter_rawdata\n",
    "def merge_csv_files_upl(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    dfs = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['source_file'] = os.path.basename(file_path)\n",
    "            df.columns = df.columns.str.strip().str.lower().map(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "            df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    cols_count = merged_df.columns.value_counts()\n",
    "    duplicated_cols = cols_count[cols_count > 1].index.tolist()\n",
    "    renamed_cols = {}\n",
    "    for col in duplicated_cols:\n",
    "        count = 1\n",
    "        for idx in range(len(merged_df.columns)):\n",
    "            if merged_df.columns[idx] == col:\n",
    "                renamed_cols[col] = f\"{col}.{count}\"\n",
    "                count += 1\n",
    "    merged_df = merged_df.rename(columns=renamed_cols)\n",
    "    return merged_df\n",
    "def merge_csv_files_appeal(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path,dtype={'BPO_QA_Task ID': object,'Object_ID':object,'Queue _ID':object})\n",
    "            df['BPO QA Date'] = df['BPO QA Date'].apply(convert_datetime)\n",
    "            df['Week'] = os.path.basename(file_path).replace('.csv', '')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    return merged_df\n",
    "def merge_csv_files_sideproject(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path,dtype={'BPO_QA_Task ID': object,'Object_ID':object,'Queue _ID':object})\n",
    "            df['Week'] = os.path.basename(file_path).replace('.csv', '')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    return merged_df\n",
    "def input_data( data_dir  ):\n",
    "    data_dir = data_dir\n",
    "    out_dir = '.'\n",
    "    list_files = []\n",
    "    for filename in pathlib.Path(data_dir).glob('**/*.xlsx'):\n",
    "        df=pd.concat(pd.read_excel(filename,sheet_name=None, skiprows=0))\n",
    "        list_files.append(df)\n",
    "    df1 = pd.concat(list_files,   ignore_index=True)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supporting \n",
    "\n",
    "#Queue\n",
    "queue_list = pd.read_excel('Support_dashboard.xlsx',sheet_name='Queue List',dtype={'MOD QUEUE ID':object,'QA QUEUE ID':object})\n",
    "queue_list = pd.DataFrame(queue_list)\n",
    "queue_list = queue_list.dropna(subset=['QA QUEUE NAME'])\n",
    "\n",
    "#Alternation\n",
    "shadow_table = pd.read_excel('Support_dashboard.xlsx',sheet_name='Shadow')\n",
    "\n",
    "\n",
    "#Week\n",
    "week_list = pd.read_excel('Support_dashboard.xlsx',sheet_name='Week')\n",
    "month_mapping = {\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec'\n",
    "}\n",
    "week_list['Month'] = week_list['Month'].map(month_mapping)\n",
    "\n",
    "#Policy Errors\n",
    "policy_errors_list = pd.read_excel('Support_dashboard.xlsx',sheet_name='Policy Errors').values\n",
    "policy_errors_list = [item for sublist in policy_errors_list for item in sublist]\n",
    "\n",
    "#PIP Tracker\n",
    "pip_rawdata = pd.read_excel('Support_dashboard.xlsx',sheet_name='PIP_Tracker')\n",
    "\n",
    "#Data full alternation\n",
    "data_full_alternation = pd.read_excel('linemanager_full.xlsx')\n",
    "data_full_alternation = data_full_alternation[data_full_alternation['Role'].str.contains('Operator')]\n",
    "data_full_alternation = data_full_alternation[['EffectDate','Email','LineManager','Batch','Task','ProductionTenure','Role']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EffectDate</th>\n",
       "      <th>Email</th>\n",
       "      <th>LineManager</th>\n",
       "      <th>Task</th>\n",
       "      <th>IPR_transfer</th>\n",
       "      <th>IPR_Seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209833</th>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209834</th>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209835</th>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209836</th>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209837</th>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186747 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EffectDate                       Email        LineManager     Task  \\\n",
       "3797   2022-09-05  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3798   2022-09-06  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3799   2022-09-07  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3800   2022-09-08  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3801   2022-09-09  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "...           ...                         ...                ...      ...   \n",
       "209833 2023-05-18  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209834 2023-05-19  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209835 2023-05-20  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209836 2023-05-21  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209837 2023-05-22  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "\n",
       "       IPR_transfer IPR_Seniority  \n",
       "3797             No           NaT  \n",
       "3798             No           NaT  \n",
       "3799             No           NaT  \n",
       "3800             No           NaT  \n",
       "3801             No           NaT  \n",
       "...             ...           ...  \n",
       "209833           No           NaT  \n",
       "209834           No           NaT  \n",
       "209835           No           NaT  \n",
       "209836           No           NaT  \n",
       "209837           No           NaT  \n",
       "\n",
       "[186747 rows x 6 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check chuyển team IPR Alernation\n",
    "data_full_alternation_copy = data_full_alternation[['EffectDate','Email','LineManager','Task']]\n",
    "data_full_alternation_copy = data_full_alternation_copy.sort_values(by=['Email', 'EffectDate'], ascending=True)\n",
    "current_date = datetime.now()\n",
    "data_full_alternation_copy = data_full_alternation_copy[data_full_alternation_copy['EffectDate'] <= current_date]\n",
    "data_full_alternation_copy['IPR_transfer'] = 'No'\n",
    "mask_counterfeit = data_full_alternation_copy['Task'].isin(['Counterfeit_ds', 'Counterfeit_ns'])\n",
    "counterfeit_rows = data_full_alternation_copy[mask_counterfeit]\n",
    "mask_not_counterfeit = ~data_full_alternation_copy['Task'].isin(['Counterfeit_ds', 'Counterfeit_ns'])\n",
    "not_counterfeit_rows = data_full_alternation_copy[mask_not_counterfeit]\n",
    "last_task = None\n",
    "for index, row in data_full_alternation_copy.iterrows():\n",
    "    if last_task is None or row['Email'] != last_task['Email']:\n",
    "        last_task = row\n",
    "        continue\n",
    "    if last_task['Task'] not in ['Counterfeit_ds', 'Counterfeit_ns'] and row['Task'] in ['Counterfeit_ds', 'Counterfeit_ns']:\n",
    "        data_full_alternation_copy.at[index, 'IPR_transfer'] = 'Yes'\n",
    "    last_task = row\n",
    "ipr_transfer_tracker = data_full_alternation_copy.copy()\n",
    "ipr_transfer_tracker.loc[ipr_transfer_tracker['IPR_transfer'] == 'Yes', 'IPR_Seniority'] = ipr_transfer_tracker.loc[ipr_transfer_tracker['IPR_transfer'] == 'Yes', 'EffectDate'] + timedelta(days=14)\n",
    "ipr_transfer_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERFORMANCE LEVEL</th>\n",
       "      <th>NAME</th>\n",
       "      <th>MOD EMAIL</th>\n",
       "      <th>START DATE</th>\n",
       "      <th>END DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>PHẠM ĐOÀN ANH VI</td>\n",
       "      <td>vi.pda@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-19 14:15:00</td>\n",
       "      <td>2023-09-19 14:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>TRẦN THIỆN TUẤN</td>\n",
       "      <td>tuan.tt@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-19 14:15:00</td>\n",
       "      <td>2023-09-19 14:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>NGUYỄN CHÍ TÀI</td>\n",
       "      <td>tai.nc@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-19 00:30:00</td>\n",
       "      <td>2023-09-19 00:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>NGUYỄN NGÔ TRƯỜNG DUY</td>\n",
       "      <td>duy.nnt@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-19 14:25:00</td>\n",
       "      <td>2023-09-19 14:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>LÂM TRÚC MAI</td>\n",
       "      <td>mai.lt1@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-20 15:35:00</td>\n",
       "      <td>2023-09-20 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>ĐỖ THỊ THÙY TRANG</td>\n",
       "      <td>trang.dtt1@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-21 22:30:00</td>\n",
       "      <td>2023-09-21 22:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>ĐOÀN THỊ XUÂN HƯƠNG</td>\n",
       "      <td>huong.dtx@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-21 14:50:00</td>\n",
       "      <td>2023-09-21 15:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>TRƯƠNG NGỌC QUANG</td>\n",
       "      <td>quang.tn@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-22 16:50:00</td>\n",
       "      <td>2023-09-22 17:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>VÕ THỊ BÍCH PHƯƠNG</td>\n",
       "      <td>phuong.vtb3@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-22 17:25:00</td>\n",
       "      <td>2023-09-22 17:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>ƯNG THÁI THÀNH</td>\n",
       "      <td>thanh.ut@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-22 17:30:00</td>\n",
       "      <td>2023-09-22 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>PHẠM ĐOÀN ANH VI</td>\n",
       "      <td>vi.pda@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-30 20:11:00</td>\n",
       "      <td>2023-09-30 20:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>NGUYỄN CHÍ TÀI</td>\n",
       "      <td>tai.nc@trans-cosmos.com.vn</td>\n",
       "      <td>2023-09-30 00:45:00</td>\n",
       "      <td>2023-09-30 01:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>VÕ THỊ BÍCH PHƯƠNG</td>\n",
       "      <td>phuong.vtb3@trans-cosmos.com.vn</td>\n",
       "      <td>2023-10-01 12:15:00</td>\n",
       "      <td>2023-10-01 12:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>LÂM TRÚC MAI</td>\n",
       "      <td>mai.lt1@trans-cosmos.com.vn</td>\n",
       "      <td>2023-10-01 16:30:00</td>\n",
       "      <td>2023-10-01 16:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>ĐOÀN THỊ XUÂN HƯƠNG</td>\n",
       "      <td>huong.dtx@trans-cosmos.com.vn</td>\n",
       "      <td>2023-10-01 14:30:00</td>\n",
       "      <td>2023-10-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TOP PERFORMANCE</td>\n",
       "      <td>ƯNG THÁI THÀNH</td>\n",
       "      <td>thanh.ut@trans-cosmos.com.vn</td>\n",
       "      <td>2023-10-01 12:50:00</td>\n",
       "      <td>2023-10-01 13:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>TRẦN THIỆN TUẤN</td>\n",
       "      <td>tuan.tt@trans-cosmos.com.vn</td>\n",
       "      <td>2023-10-02 13:15:00</td>\n",
       "      <td>2023-10-02 13:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BOTTOM PERFORMANCE</td>\n",
       "      <td>ĐỖ THỊ THÙY TRANG</td>\n",
       "      <td>trang.dtt1@trans-cosmos.com.vn</td>\n",
       "      <td>2023-10-02 21:30:00</td>\n",
       "      <td>2023-10-02 21:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PERFORMANCE LEVEL                   NAME  \\\n",
       "0   BOTTOM PERFORMANCE       PHẠM ĐOÀN ANH VI   \n",
       "1   BOTTOM PERFORMANCE        TRẦN THIỆN TUẤN   \n",
       "2      TOP PERFORMANCE         NGUYỄN CHÍ TÀI   \n",
       "3      TOP PERFORMANCE  NGUYỄN NGÔ TRƯỜNG DUY   \n",
       "4      TOP PERFORMANCE           LÂM TRÚC MAI   \n",
       "5   BOTTOM PERFORMANCE      ĐỖ THỊ THÙY TRANG   \n",
       "6      TOP PERFORMANCE    ĐOÀN THỊ XUÂN HƯƠNG   \n",
       "7   BOTTOM PERFORMANCE      TRƯƠNG NGỌC QUANG   \n",
       "8   BOTTOM PERFORMANCE     VÕ THỊ BÍCH PHƯƠNG   \n",
       "9      TOP PERFORMANCE         ƯNG THÁI THÀNH   \n",
       "10  BOTTOM PERFORMANCE       PHẠM ĐOÀN ANH VI   \n",
       "11     TOP PERFORMANCE         NGUYỄN CHÍ TÀI   \n",
       "12  BOTTOM PERFORMANCE     VÕ THỊ BÍCH PHƯƠNG   \n",
       "13     TOP PERFORMANCE           LÂM TRÚC MAI   \n",
       "14     TOP PERFORMANCE    ĐOÀN THỊ XUÂN HƯƠNG   \n",
       "15     TOP PERFORMANCE         ƯNG THÁI THÀNH   \n",
       "16  BOTTOM PERFORMANCE        TRẦN THIỆN TUẤN   \n",
       "17  BOTTOM PERFORMANCE      ĐỖ THỊ THÙY TRANG   \n",
       "\n",
       "                          MOD EMAIL          START DATE            END DATE  \n",
       "0        vi.pda@trans-cosmos.com.vn 2023-09-19 14:15:00 2023-09-19 14:45:00  \n",
       "1       tuan.tt@trans-cosmos.com.vn 2023-09-19 14:15:00 2023-09-19 14:35:00  \n",
       "2        tai.nc@trans-cosmos.com.vn 2023-09-19 00:30:00 2023-09-19 00:50:00  \n",
       "3       duy.nnt@trans-cosmos.com.vn 2023-09-19 14:25:00 2023-09-19 14:45:00  \n",
       "4       mai.lt1@trans-cosmos.com.vn 2023-09-20 15:35:00 2023-09-20 16:00:00  \n",
       "5    trang.dtt1@trans-cosmos.com.vn 2023-09-21 22:30:00 2023-09-21 22:45:00  \n",
       "6     huong.dtx@trans-cosmos.com.vn 2023-09-21 14:50:00 2023-09-21 15:20:00  \n",
       "7      quang.tn@trans-cosmos.com.vn 2023-09-22 16:50:00 2023-09-22 17:20:00  \n",
       "8   phuong.vtb3@trans-cosmos.com.vn 2023-09-22 17:25:00 2023-09-22 17:55:00  \n",
       "9      thanh.ut@trans-cosmos.com.vn 2023-09-22 17:30:00 2023-09-22 18:00:00  \n",
       "10       vi.pda@trans-cosmos.com.vn 2023-09-30 20:11:00 2023-09-30 20:41:00  \n",
       "11       tai.nc@trans-cosmos.com.vn 2023-09-30 00:45:00 2023-09-30 01:15:00  \n",
       "12  phuong.vtb3@trans-cosmos.com.vn 2023-10-01 12:15:00 2023-10-01 12:35:00  \n",
       "13      mai.lt1@trans-cosmos.com.vn 2023-10-01 16:30:00 2023-10-01 16:45:00  \n",
       "14    huong.dtx@trans-cosmos.com.vn 2023-10-01 14:30:00 2023-10-01 15:00:00  \n",
       "15     thanh.ut@trans-cosmos.com.vn 2023-10-01 12:50:00 2023-10-01 13:05:00  \n",
       "16      tuan.tt@trans-cosmos.com.vn 2023-10-02 13:15:00 2023-10-02 13:45:00  \n",
       "17   trang.dtt1@trans-cosmos.com.vn 2023-10-02 21:30:00 2023-10-02 21:45:00  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_table['SHADOW DATE'] = pd.to_datetime(shadow_table['SHADOW DATE'])\n",
    "shadow_table['STARTING TIME'] = pd.to_datetime(shadow_table['STARTING TIME'], format='%H:%M:%S').dt.time\n",
    "shadow_table['ENDING TIME'] = pd.to_datetime(shadow_table['ENDING TIME'], format='%H:%M:%S').dt.time\n",
    "shadow_table['START DATE'] = pd.to_datetime(shadow_table['SHADOW DATE'].astype(str) + ' ' + shadow_table['STARTING TIME'].astype(str))\n",
    "shadow_table['END DATE'] = pd.to_datetime(shadow_table['SHADOW DATE'].astype(str) + ' ' + shadow_table['ENDING TIME'].astype(str))\n",
    "shadow_table_usefull = shadow_table[['PERFORMANCE LEVEL', 'NAME', 'MOD EMAIL','START DATE', 'END DATE']]\n",
    "shadow_table_usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shadow_rawdata = input_data_csv('D:/New folder (3)')\n",
    "# shadow_rawdata = shadow_rawdata[['title', 'task_id', '1_verifier', '1_resolve_time','1_duration']]\n",
    "# merged_df = shadow_table_usefull.merge(shadow_rawdata, left_on='MOD EMAIL', right_on='1_verifier')\n",
    "# shadow_df = merged_df[(merged_df['1_resolve_time'] >= merged_df['START DATE']) & (merged_df['1_resolve_time'] <= merged_df['END DATE'])]\n",
    "# shadow_df = shadow_df.groupby(by=['MOD EMAIL','title','START DATE','END DATE'],as_index=False).agg({'task_id':'count','1_duration':'mean'})\n",
    "# shadow_df.to_excel('shadow.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip_rawdata_clean = pd.melt(pip_rawdata, id_vars=['Mod Email', 'Superior', 'Task', 'PIP Level Progress', 'PIP Stage Progress', 'Team', 'QA'],\n",
    "#                       value_vars=['Stage 1', 'Stage 2', 'Stage 3', 'Stage 4', 'Stage 5', 'Stage 6', 'Stage 7'],\n",
    "#                       var_name='Stage', value_name='PIP (Week) Processing')\n",
    "# pip_rawdata_clean = pip_rawdata_clean.dropna(subset=['PIP (Week) Processing'])\n",
    "# pip_rawdata_clean = pd.merge(pip_rawdata_clean,week_list,how='left',left_on='PIP (Week) Processing',right_on='Mod_Week')\n",
    "# pip_rawdata_clean[['PIP (Week) Processing','Date','Mod Email', 'Superior', 'Task', 'PIP Level Progress','PIP Stage Progress', 'Team', 'QA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = {\n",
    "    \"Regular\":['Livestream', 'IPR', 'Seller', 'Anchor Video','CB Product','LL Product'],\n",
    "    \"Appeal\":['Appeal'],\n",
    "    \"Side Project\":['Side Project'],\n",
    "    \"E-UPL\":['E-UPL'],\n",
    "    \"G-UPL\":['G-UPL'],\n",
    "}\n",
    "\n",
    "aliases_final_decision = {\"Failed appeal\":['failed appeal','mod wrong','mods wrong','r1 wrong','r2 wrong'] ,\n",
    "            \"Edge case\":['edge case', 'borderline','boderline'],\n",
    "            \"Appeal successfully\":['appeal successfully','qa wrong','qas wrong','mod correct','bo wrong','tl wrong'],\n",
    "            }\n",
    "\n",
    "aliases = {\n",
    "    \"Not Approve\": ['\"audit_status\":400','\"status\":400','\":400,\"','400','disapproval', 'disapproved','not approval','not approve' ,'notapproval','disapprove','not approved','violation','reject'],\n",
    "    \"Approve\": ['\"audit_status\":200','approve','\"status\":200' ,'approval', 'approved','200','general']\n",
    "}\n",
    "\n",
    "filter_week_func = {'W44','W45','W46','W47'}\n",
    "#'W1','W2','W3','W4','W5','W6','W7','W8','W9','W10','W11','W12','W13','W14','W15','W16','W17','W18','W19','W20','W21','W22','W23','W24','W25','W26','W27','W28','W29','W30','W31','W32','W33','W34','W35','W36','W37','W38','W39','W40'\n",
    "def filter_week(df,W,cp):\n",
    "    df = df[df['Week'].str.contains('|'.join(W))]\n",
    "    df = df[df['COMPOUND'].isin(cp)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIVE PRODUCTIVITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# live_prod_rawdata = input_data_csv('Live - Prod by date')\n",
    "# live_prod_rawdata['Date'] = pd.to_datetime(live_prod_rawdata['Date'].apply(convert_datetime))\n",
    "# live_prod_rawdata = pd.merge(live_prod_rawdata,queue_list,how='left',left_on='Queue Title',right_on='MOD QUEUE NAME')\n",
    "# live_prod = pd.merge(live_prod_rawdata,week_list,how='left',on='Date')\n",
    "# live_prod = live_prod[['Mod_Week','Date', 'Queue Title','QA QUEUE NAME', 'Moderator', 'Queue ID','No. of Moderation Tasks']]\n",
    "# live_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\2114196068.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  People_Round_rawdata.rename(columns={'People':'Moderators Name',\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\2114196068.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  People_Round_rawdata[['Moderation Date','End date']] = People_Round_rawdata['Selected duration'].str.split('~', expand=True, n=1)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\2114196068.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  People_Round_rawdata[['Moderation Date','End date']] = People_Round_rawdata['Selected duration'].str.split('~', expand=True, n=1)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\2114196068.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  People_Round_rawdata['Moderation Date'] = pd.to_datetime(People_Round_rawdata['Moderation Date'].apply(convert_datetime))\n"
     ]
    }
   ],
   "source": [
    "People_statistic_append = input_data('People Daily')\n",
    "People_statistic_append= People_statistic_append[People_statistic_append['People']!=\"汇总/All\"]\n",
    "People_Round_rawdata = People_statistic_append[['Selected duration',\n",
    "                                      'Sampling Queue',\n",
    "                                      'People',\n",
    "                                      'No. of Samples']]\n",
    "People_Round_rawdata.rename(columns={'People':'Moderators Name',\n",
    "                             'Sampling Queue':'Queue Name',\n",
    "                             'No. of Samples':'Sample Size'},inplace=True)\n",
    "#Split duration\n",
    "People_Round_rawdata[['Moderation Date','End date']] = People_Round_rawdata['Selected duration'].str.split('~', expand=True, n=1)\n",
    "People_Round_rawdata['Moderation Date'] = pd.to_datetime(People_Round_rawdata['Moderation Date'].apply(convert_datetime))\n",
    "People_Round_rawdata = People_Round_rawdata.drop_duplicates()\n",
    "People_Round_rawdata = pd.merge(People_Round_rawdata,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "People_Round_rawdata = People_Round_rawdata[['Mod_Week','Moderation Date','Queue Name','Moderators Name','Sample Size']].rename(columns={'Mod_Week':'Week'})\n",
    "People_Round = People_Round_rawdata.groupby(by=['Week','Moderation Date','Queue Name','Moderators Name'],as_index=False).agg({'Sample Size':'sum'})\n",
    "for week in People_Round['Week'].unique():\n",
    "    df = People_Round[People_Round['Week'] == week]\n",
    "    df.to_csv(f'Sample Size All Queues/Regular/{week}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\913736312.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  regular_appeal_diff_cases['mod_date'] = pd.to_datetime(regular_appeal_diff_cases['mod_date'].apply(convert_datetime))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Week\n",
       "W1 (12.31 - 01.06)     1082\n",
       "W13 (03.25 - 03.31)    1030\n",
       "W2 (01.07 - 01.13)      832\n",
       "W8 (02.18 - 02.24)      719\n",
       "W5 (01.28 - 02.03)      692\n",
       "W3 (01.14 - 01.20)      663\n",
       "W9 (02.25 - 03.03)      656\n",
       "W7 (02.11 - 02.17)      642\n",
       "W10 (03.04 - 03.10)     616\n",
       "W6 (02.04 - 02.10)      603\n",
       "W21 (05.22 - 05.28)     562\n",
       "W11 (03.11 - 03.17)     546\n",
       "W4 (01.21 - 01.27)      543\n",
       "W16 (04.17 - 04.23)     542\n",
       "W17 (04.24 - 04.30)     541\n",
       "W12 (03.18 - 03.24)     539\n",
       "W20 (05.15 - 05.21)     514\n",
       "W25 (06.19 - 06.25)     509\n",
       "W23 (06.05 - 06.11)     498\n",
       "W22 (05.29 - 05.06)     494\n",
       "W16 (04.15 - 04.21)     485\n",
       "W14 (04.01 - 04.07)     474\n",
       "W15 (04.08 - 04.14)     462\n",
       "W24 (06.12 - 06.18)     450\n",
       "W18 (05.01 - 05.07)     435\n",
       "W26 (06.26 - 07.02)     428\n",
       "W19 (05.08 - 05.14)     353\n",
       "W28 (07.09 - 07.15)     287\n",
       "W27 (07.03 - 07.08)     264\n",
       "W29 (07.16 - 07.22)     259\n",
       "W32 (08.06 - 08.12)     255\n",
       "W38 (09.17 - 09.23)     252\n",
       "W31 (07.30 - 08.05)     248\n",
       "W34 (08.20 - 08.26)     243\n",
       "W35 (08.27 - 09.02)     239\n",
       "W46 (11.12 - 11.18)     238\n",
       "W33 (08.13 - 08.19)     233\n",
       "W39 (09.24 - 09.30)     232\n",
       "W37 (09.10 - 09.16)     230\n",
       "W36 (09.03 - 09.09)     229\n",
       "W30 (07.23 - 07.29)     222\n",
       "W47 (11.19 - 11.25)     218\n",
       "W40 (10.01 - 10.07)     212\n",
       "W42 (10.15 - 10.21)     203\n",
       "W44 (10.29 - 11.04)     198\n",
       "W45 (11.05 - 11.11)     189\n",
       "W43 (10.22 - 10.28)     188\n",
       "W41 (10.08 - 10.14)     187\n",
       "W48 (11.26 - 12.02)     108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regular_appeal_rawdata_diff_case\n",
    "\n",
    "regular_appeal_Rawdata = merge_csv_files_appeal('Regular_appeal')\n",
    "regular_appeal_Rawdata = regular_appeal_Rawdata[~regular_appeal_Rawdata['Queue Name'].isnull()]\n",
    "regular_appeal_Rawdata['mod_date'] = pd.to_datetime(regular_appeal_Rawdata['mod_date'].apply(convert_datetime))\n",
    "regular_appeal_Rawdata['Final Decision'] = regular_appeal_Rawdata['Final Decision'].fillna('Mod correct')\n",
    "for k, v in aliases_final_decision.items():\n",
    "    pat = '|'.join(v)\n",
    "    regular_appeal_Rawdata.loc[regular_appeal_Rawdata['Final Decision'].str.contains(pat, case=False),'Final Decision'] = k\n",
    "BPO_QA_Decision_keep_values = ['Failed appeal', 'Appeal successfully', 'Edge case','Mod correct']\n",
    "temp_col = regular_appeal_Rawdata['Final Decision'].copy()\n",
    "temp_col[~temp_col.isin(BPO_QA_Decision_keep_values)] = 'Failed appeal'\n",
    "regular_appeal_Rawdata['Final Decision'] = temp_col\n",
    "regular_appeal_diff_cases = regular_appeal_Rawdata[(regular_appeal_Rawdata['Final Decision']==\"Failed appeal\") | (regular_appeal_Rawdata['Final Decision']==\"Edge case\")]\n",
    "regular_appeal_diff_cases['mod_date'] = pd.to_datetime(regular_appeal_diff_cases['mod_date'].apply(convert_datetime))\n",
    "regular_appeal_diff_cases['Week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular\n",
    "regular_sample_size = input_data_csv('Sample Size All Queues/Regular')\n",
    "regular_sample_size ['Moderation Date'] = pd.to_datetime(regular_sample_size ['Moderation Date'].apply(convert_datetime))\n",
    "regular_sample_size = regular_sample_size.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\3341213000.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  regular_mod_wrong['mod_date'] = pd.to_datetime(regular_mod_wrong['mod_date'].apply(convert_datetime))\n"
     ]
    }
   ],
   "source": [
    "#Diff case - Regular\n",
    "regular_mod_wrong = regular_appeal_diff_cases.dropna(subset=['Final Decision'])\n",
    "regular_mod_wrong = regular_appeal_diff_cases.loc[(~regular_appeal_diff_cases['Queue Name'].str.contains(r\"\\b.ppeal .udit\\b\")) & (regular_appeal_diff_cases['Final Decision'] == \"Failed appeal\")]\n",
    "regular_mod_wrong['mod_date'] = pd.to_datetime(regular_mod_wrong['mod_date'].apply(convert_datetime))\n",
    "regular_mod_wrong = regular_mod_wrong.groupby(by=['mod_date','Queue Name','mod'], as_index=False).agg({'object id':'count'})\n",
    "regular_mod_wrong = regular_mod_wrong[['mod_date','Queue Name','mod','object id']].rename(columns={'mod_date':'Moderation Date',\n",
    "                                                                                                      'Queue Name':'Queue Name',\n",
    "                                                                                                      'mod':'Moderators Name',\n",
    "                                                                                                      'object id':'Mods Wrong'})\n",
    "regular_mod_wrong['Moderation Date'] = pd.to_datetime(regular_mod_wrong['Moderation Date'])\n",
    "regular_mod_wrong = pd.merge(regular_mod_wrong,week_list,how='left',left_on='Moderation Date',right_on='Date').rename(columns={'Mod_Week':'Week'})\n",
    "regular_mod_wrong = regular_mod_wrong[['Week','Moderation Date','Queue Name','Moderators Name','Mods Wrong']]                \n",
    "for week in regular_mod_wrong['Week'].unique():\n",
    "    df = regular_mod_wrong[regular_mod_wrong['Week'] == week]\n",
    "    df.to_csv(f'False case All Queues/Regular/{week}.csv', index=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appeal\n",
    "qa_raw_appeal = input_data_csv('Appeal daily')\n",
    "qa_raw_appeal['1_verifier'] = qa_raw_appeal['1_verifier'].str.replace('robot_estimate@','')\n",
    "qa_raw_appeal = qa_raw_appeal[qa_raw_appeal['1_verifier'].str.contains('@trans-cosmos.com.vn')]\n",
    "qa_raw_appeal = qa_raw_appeal[qa_raw_appeal['2_resolve_time'].notnull()]\n",
    "qa_raw_appeal = qa_raw_appeal.drop_duplicates(subset='task_id',keep='last')\n",
    "qa_raw_appeal['1_resolve_time'] = pd.to_datetime(qa_raw_appeal['1_resolve_time'].apply(convert_datetime))\n",
    "qa_raw_appeal['2_resolve_time'] = pd.to_datetime(qa_raw_appeal['2_resolve_time'].apply(convert_datetime))\n",
    "appeal_sample_size_ex = qa_raw_appeal.groupby(by=['1_resolve_time','title','1_verifier'],as_index=False).agg({'task_id':'count'}).sort_values(by=['1_resolve_time'],ascending=True).rename(columns={'1_resolve_time':'Moderation Date','title':'Queue Name','1_verifier':'Moderators Name','task_id':'Sample Size'})\n",
    "appeal_sample_size_ex = pd.merge(appeal_sample_size_ex,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "appeal_sample_size_ex = appeal_sample_size_ex[['Mod_Week','Moderation Date','Queue Name','Moderators Name','Sample Size']].rename(columns={'Mod_Week':'Week'})\n",
    "for week in appeal_sample_size_ex['Week'].unique():\n",
    "    df = appeal_sample_size_ex[appeal_sample_size_ex['Week'] == week]\n",
    "    df.to_csv(f'Sample Size All Queues/Appeal/{week}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "appeal_sample_size = input_data_csv('Sample Size All Queues/Appeal')\n",
    "appeal_sample_size ['Moderation Date'] = pd.to_datetime(appeal_sample_size ['Moderation Date'].apply(convert_datetime))\n",
    "appeal_sample_size = appeal_sample_size.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\2329938305.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  appeal_mod_wrong['mod_date'] = appeal_mod_wrong['mod_date'].apply(convert_datetime)\n"
     ]
    }
   ],
   "source": [
    "#Diff case - Appeal\n",
    "appeal_mod_wrong = regular_appeal_diff_cases.loc[(regular_appeal_diff_cases['Queue Name'].str.contains(r\"\\b.ppeal .udit\\b\")) & (regular_appeal_diff_cases['Final Decision']==\"Failed appeal\")]\n",
    "appeal_mod_wrong['mod_date'] = appeal_mod_wrong['mod_date'].apply(convert_datetime)\n",
    "appeal_mod_wrong = appeal_mod_wrong.groupby(by=['mod_date','Queue Name','mod'],as_index=False).agg({'object id':'count'})\n",
    "appeal_mod_wrong = appeal_mod_wrong[['mod_date','Queue Name','mod','object id']].rename(columns={'mod_date':'Moderation Date',\n",
    "                                                                                                      'Queue Name':'Queue Name',\n",
    "                                                                                                      'mod':'Moderators Name',\n",
    "                                                                                                      'object id':'Mods Wrong'})\n",
    "appeal_mod_wrong['Moderation Date'] = pd.to_datetime(appeal_mod_wrong['Moderation Date'])\n",
    "appeal_mod_wrong = pd.merge(appeal_mod_wrong,week_list,how='left',left_on='Moderation Date',right_on='Date').rename(columns={'Mod_Week':'Week'})\n",
    "appeal_mod_wrong = appeal_mod_wrong[['Week','Moderation Date','Queue Name','Moderators Name','Mods Wrong']]\n",
    "for week in appeal_mod_wrong['Week'].unique():\n",
    "    df = appeal_mod_wrong[appeal_mod_wrong['Week'] == week]\n",
    "    df.to_csv(f'False case All Queues/Appeal/{week}.csv', index=False)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEWBIE INFLUENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Reported Week', 'Compound', 'Queue Name', 'Queue ID', 'mod', 'TL',\n",
      "       'mod_date', 'object id', 'mod_result', 'mod_reason', 'mod_aht',\n",
      "       'BPO QA', 'BPO QA Date', 'BPO QA Task ID', 'BPO QA Link',\n",
      "       'BPO QA Result', 'BPO QA Reason', 'Diff case', 'To be appeal (Y/N)',\n",
      "       '[TL Remarks]', 'BPO QA Handler', 'Final Decision', 'Final False Error',\n",
      "       'Policy Error', 'Error Category 1', 'Error Category 2',\n",
      "       'Error Category 3', 'Mod RCA from Rock', 'Remark', 'Screenshot',\n",
      "       '[BD] QA Handler', 'BD QA Agree/Disagree', 'BD QA Approve/ Reject',\n",
      "       'BD QA Decision', 'Final False Error.1', 'Wrong Tagging',\n",
      "       '[BD] Comments', 'Screenshot.1', 'Policy screenshot', 'Week', 'Month',\n",
      "       'Date & Time Dump', '[BD] Remarks', 'Policy Screenshot', 'Date',\n",
      "       'RCA lv1', 'RCA lv2', 'RCA lv3', 'Policy Error.1', 'Policy error',\n",
      "       'Policy error_1', 'Policy error_2', 'Final_False_Error',\n",
      "       'Wrong_Tagging', 'LineManager', '#REF!', '#REF!.1', '#REF!.2',\n",
      "       '#REF!.3', '#REF!.4', '#REF!.5'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Edge case</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Failed appeal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reported Week</th>\n",
       "      <th></th>\n",
       "      <th>W44 (10.29 - 11.04)</th>\n",
       "      <th>W45 (11.05 - 11.11)</th>\n",
       "      <th>W46 (11.12 - 11.18)</th>\n",
       "      <th>W47 (11.19 - 11.25)</th>\n",
       "      <th>W44 (10.29 - 11.04)</th>\n",
       "      <th>W45 (11.05 - 11.11)</th>\n",
       "      <th>W46 (11.12 - 11.18)</th>\n",
       "      <th>W47 (11.19 - 11.25)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Appeal</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CB Product</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IPR</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LL Product</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>61</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Livestream</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Seller</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Compound           Edge case                      \\\n",
       "Reported Week               W44 (10.29 - 11.04) W45 (11.05 - 11.11)   \n",
       "0              Anchor Video                   5                   3   \n",
       "1                    Appeal                   2                   0   \n",
       "2                CB Product                   1                   1   \n",
       "3                       IPR                   6                   5   \n",
       "4                LL Product                   1                   1   \n",
       "5                Livestream                   4                   6   \n",
       "6                    Seller                   5                   3   \n",
       "\n",
       "                                                            Failed appeal  \\\n",
       "Reported Week W46 (11.12 - 11.18) W47 (11.19 - 11.25) W44 (10.29 - 11.04)   \n",
       "0                               3                   2                  32   \n",
       "1                               0                   0                   8   \n",
       "2                               2                   0                  13   \n",
       "3                               8                   4                  42   \n",
       "4                               6                   3                  51   \n",
       "5                               4                   4                  18   \n",
       "6                               8                   5                  10   \n",
       "\n",
       "                                                                           \n",
       "Reported Week W45 (11.05 - 11.11) W46 (11.12 - 11.18) W47 (11.19 - 11.25)  \n",
       "0                              40                  37                  33  \n",
       "1                               6                   6                  18  \n",
       "2                              11                  16                  10  \n",
       "3                              41                  48                  58  \n",
       "4                              45                  61                  67  \n",
       "5                              19                  27                   9  \n",
       "6                               8                  12                   5  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_edge_cases = regular_appeal_Rawdata.copy()\n",
    "print(failed_edge_cases.columns)\n",
    "failed_edge_cases['BPO QA Date'] = pd.to_datetime(failed_edge_cases['BPO QA Date'].apply(convert_datetime))\n",
    "failed_edge_cases = failed_edge_cases.groupby(['Reported Week','Compound','BPO QA Date','Queue Name','mod'], as_index=False).apply(lambda x: pd.Series({\n",
    "    'Edge case': (x['Final Decision'] == 'Edge case').sum(),\n",
    "    'Failed appeal': (x['Final Decision'] == 'Failed appeal').sum()\n",
    "}))\n",
    "mod_wrong_temp = pd.merge(failed_edge_cases,queue_list,how='left',left_on='Queue Name',right_on='QA QUEUE NAME')\n",
    "mod_wrong_temp = pd.merge(mod_wrong_temp,data_full_alternation,how='left',left_on=['BPO QA Date','mod'],right_on=['EffectDate','Email'])\n",
    "mod_wrong_temp = mod_wrong_temp[mod_wrong_temp['Reported Week'].str.contains('|'.join(filter_week_func))]\n",
    "mod_wrong_temp = mod_wrong_temp[['Reported Week','Compound','Queue Name','mod','Batch','ProductionTenure','Edge case','Failed appeal']]\n",
    "mod_wrong_temp.to_excel('newbie influence tracker.xlsx',index=False)\n",
    "pv_mod_wrong_temp = pd.pivot_table(mod_wrong_temp,values=['Edge case','Failed appeal'],index=['Compound'],columns='Reported Week',aggfunc='sum')\n",
    "pv_mod_wrong_temp = pv_mod_wrong_temp.fillna(\"---\")\n",
    "pv_mod_wrong_temp = pv_mod_wrong_temp.reset_index()\n",
    "pv_mod_wrong_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shop UPL\n",
    "E_UPL_rawdata = merge_csv_files_upl('E_UPL')\n",
    "E_UPL_rawdata['Queue Name'] = E_UPL_rawdata['queue_name']\n",
    "E_UPL_rawdata['Moderators Name'] = E_UPL_rawdata['mod_name'].fillna(E_UPL_rawdata['1st_mod_name'])\n",
    "E_UPL_rawdata['Moderators Name 2'] = E_UPL_rawdata['2nd_mod_name']\n",
    "E_UPL_rawdata['Count'] = E_UPL_rawdata['object_id']\n",
    "E_UPL_rawdata['Moderation Date'] = pd.to_datetime(E_UPL_rawdata['1st_date'].apply(convert_datetime))\n",
    "E_UPL_rawdata['QA Date'] = pd.to_datetime(E_UPL_rawdata['2nd_date'].apply(convert_datetime))\n",
    "E_UPL_rawdata['Error Category 1'] = E_UPL_rawdata['error_category_1']\n",
    "E_UPL_rawdata['Error Category 2'] = E_UPL_rawdata['error_category_2']\n",
    "E_UPL_rawdata['Error Category 3'] = E_UPL_rawdata['error_category_3']\n",
    "\n",
    "E_UPL_rawdata= E_UPL_rawdata[~E_UPL_rawdata['Queue Name'].isnull()]\n",
    "E_UPL_rawdata = E_UPL_rawdata.sort_values(by='Moderation Date', ascending=True)\n",
    "def adjust_results(row):\n",
    "    if pd.isnull(row['3rd_result']):\n",
    "        row['QA Result'] = row['2nd_result']\n",
    "        row['QA Reason'] = row['2nd_rejection_reason']\n",
    "        row['Mod 2 Result'] = None\n",
    "        row['Mod 2 Reason'] = None\n",
    "        row['Mod 1 Result'] = row['1st_result']\n",
    "        row['Mod 1 Reason'] = row['1st_rejection_reason']\n",
    "    else:\n",
    "        row['QA Result'] = row['3rd_result']\n",
    "        row['QA Reason'] = row['3rd_rejection_reason']\n",
    "        row['Mod 2 Result'] = row['2nd_result']\n",
    "        row['Mod 2 Reason'] = row['2nd_rejection_reason']\n",
    "        row['Mod 1 Result'] = row['1st_result']\n",
    "        row['Mod 1 Reason'] = row['1st_rejection_reason']\n",
    "    return row\n",
    "\n",
    "E_UPL_rawdata = E_UPL_rawdata.apply(adjust_results, axis=1)\n",
    "E_UPL_rawdata = pd.merge(E_UPL_rawdata,week_list,how='left',left_on='Moderation Date',right_on='Date').rename(columns={'UPL_Week':'Week'})\n",
    "def fill_final_decision(row):\n",
    "    valid_values = ['Failed appeal', 'Edge case', 'Appeal successfully']\n",
    "    for column in ['final_decision_(pbo)', 'bd_qa_decision', '[bpo_qa]_decision']:\n",
    "        if row[column] in valid_values:\n",
    "            return row[column]\n",
    "        elif pd.notnull(row[column]):\n",
    "            return row[column]\n",
    "    return ''\n",
    "E_UPL_rawdata['Final Decision'] = E_UPL_rawdata.apply(fill_final_decision, axis=1)\n",
    "E_UPL_rawdata['Final Decision'] = E_UPL_rawdata['Final Decision'].fillna('Mod correct')\n",
    "for k, v in aliases_final_decision.items():\n",
    "    pat = '|'.join(v)\n",
    "    E_UPL_rawdata.loc[E_UPL_rawdata['Final Decision'].str.contains(pat, case=False),'Final Decision'] = k\n",
    "def set_policy_error(row):\n",
    "    if row['Final Decision'] in ['Failed appeal', 'Edge case']:\n",
    "        return row['2nd_rejection_reason']\n",
    "    else:\n",
    "        return row['1st_rejection_reason']\n",
    "E_UPL_rawdata['Policy Error'] = E_UPL_rawdata.apply(set_policy_error, axis=1) \n",
    "def check_approval_status(value):\n",
    "    for status, keywords in aliases.items():\n",
    "        found_keywords = [keyword for keyword in keywords if keyword in value.lower()]\n",
    "        if found_keywords:\n",
    "            return status\n",
    "    return None\n",
    "columns_to_check = ['Mod 1 Result', 'Mod 2 Result', 'QA Result']\n",
    "for column in columns_to_check:\n",
    "    E_UPL_rawdata[column] = E_UPL_rawdata[column].apply(lambda x: check_approval_status(x) if isinstance(x, str) else np.nan)            \n",
    "def get_moderation_error_round(row):\n",
    "    if row['Final Decision'] == 'Failed appeal':\n",
    "        if row['Mod 1 Result'] != row['QA Result']:\n",
    "            return '1st wrong'\n",
    "        elif row['Mod 2 Result'] != row['QA Result']:\n",
    "            return '2nd wrong'\n",
    "    return ''\n",
    "E_UPL_rawdata['Moderation_Error_Round'] = E_UPL_rawdata.apply(get_moderation_error_round, axis=1)\n",
    "\n",
    "E_UPL_lineup = E_UPL_rawdata[['Moderation Date','Queue Name','Moderators Name','Moderators Name 2','Count','Moderation_Error_Round']]\n",
    "E_UPL_lineup_1 = E_UPL_lineup[['Moderation Date','Queue Name','Moderators Name','Count','Moderation_Error_Round']]\n",
    "E_UPL_lineup_2 = E_UPL_lineup[['Moderation Date','Queue Name','Moderators Name 2','Count','Moderation_Error_Round']]\n",
    "\n",
    "E_UPL_lineup_1_sample_size = E_UPL_lineup_1.groupby(['Moderation Date', 'Queue Name', 'Moderators Name'], as_index=False)['Count'].count()\n",
    "E_UPL_lineup_2_sample_size = E_UPL_lineup_2.groupby(['Moderation Date', 'Queue Name', 'Moderators Name 2'], as_index=False)['Count'].count()\n",
    "E_UPL_lineup_sample_size = pd.concat([E_UPL_lineup_1_sample_size, E_UPL_lineup_2_sample_size], ignore_index=True)\n",
    "E_UPL_lineup_sample_size['Moderators Name'] = E_UPL_lineup_sample_size['Moderators Name'].fillna(E_UPL_lineup_sample_size['Moderators Name 2'])\n",
    "E_UPL_lineup_sample_size.drop(['Moderators Name 2'], axis=1, inplace=True)\n",
    "\n",
    "E_UPL_sample_size = pd.merge(E_UPL_lineup_sample_size,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "E_UPL_sample_size = E_UPL_sample_size.rename(columns={'Count': 'Sample Size','UPL_Week':'Week'})\n",
    "E_UPL_sample_size = E_UPL_sample_size[['Week','Moderation Date','Queue Name','Moderators Name','Sample Size']]\n",
    "for week in E_UPL_sample_size['Week'].unique():\n",
    "    df = E_UPL_sample_size[E_UPL_sample_size['Week'] == week]\n",
    "    df.to_csv(f'Sample Size All Queues/E_UPL/{week}.csv', index=False)\n",
    "E_UPL_lineup_1_mod_wrong = E_UPL_lineup_1.groupby(['Moderation Date', 'Queue Name', 'Moderators Name'])['Moderation_Error_Round'].apply(lambda x: ((x == '1st wrong')).sum()).reset_index(name='Mods Wrong')\n",
    "E_UPL_lineup_2_mod_wrong = E_UPL_lineup_2[~E_UPL_lineup_2['Moderators Name 2'].isnull()]\n",
    "E_UPL_lineup_2_mod_wrong = E_UPL_lineup_2_mod_wrong.groupby(['Moderation Date', 'Queue Name', 'Moderators Name 2'])['Moderation_Error_Round'].apply(lambda x: ((x == '2nd wrong')).sum()).reset_index(name='Mods Wrong')\n",
    "E_UPL_lineup_mod_wrong = pd.concat([E_UPL_lineup_1_mod_wrong, E_UPL_lineup_2_mod_wrong], ignore_index=True)\n",
    "E_UPL_lineup_mod_wrong['Moderators Name'] = E_UPL_lineup_mod_wrong['Moderators Name'].fillna(E_UPL_lineup_mod_wrong['Moderators Name 2'])\n",
    "E_UPL_lineup_mod_wrong.drop(['Moderators Name 2'], axis=1, inplace=True)\n",
    "E_UPL_mod_wrong = pd.merge(E_UPL_lineup_mod_wrong,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "E_UPL_mod_wrong = E_UPL_mod_wrong.rename(columns={'UPL_Week':'Week'})\n",
    "E_UPL_mod_wrong = E_UPL_mod_wrong[['Week','Moderation Date','Queue Name','Moderators Name','Mods Wrong']]\n",
    "for week in E_UPL_mod_wrong['Week'].unique():\n",
    "    df = E_UPL_mod_wrong[E_UPL_mod_wrong['Week'] == week]\n",
    "    df.to_csv(f'False case All Queues/E_UPL/{week}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gen UPL\n",
    "G_UPL_rawdata = merge_csv_files_upl('G_UPL')\n",
    "G_UPL_rawdata['Queue Name'] =  G_UPL_rawdata['queue_name'].fillna(G_UPL_rawdata['title'])\n",
    "G_UPL_rawdata['Moderators Name'] = G_UPL_rawdata['1st_name'].fillna(G_UPL_rawdata['round_1'])\n",
    "G_UPL_rawdata['Moderators Name 2'] = G_UPL_rawdata['round_2']\n",
    "G_UPL_rawdata['Count'] = G_UPL_rawdata['object_id']\n",
    "G_UPL_rawdata['Moderation Date'] = pd.to_datetime(G_UPL_rawdata['1st_date'].apply(convert_datetime)).fillna(pd.to_datetime(G_UPL_rawdata['1_resolve_time'].apply(convert_datetime)))\n",
    "G_UPL_rawdata['[bpo_qa]_decision'] = G_UPL_rawdata['[bpo_qa]_decision'].fillna(G_UPL_rawdata['result'])\n",
    "G_UPL_rawdata['Error Category 1'] = G_UPL_rawdata['error_category_1']\n",
    "G_UPL_rawdata['Error Category 2'] = G_UPL_rawdata['error_category_2']\n",
    "G_UPL_rawdata['Error Category 3'] = G_UPL_rawdata['error_category_3']\n",
    "G_UPL_rawdata= G_UPL_rawdata[~G_UPL_rawdata['Queue Name'].isnull()]\n",
    "G_UPL_rawdata = G_UPL_rawdata.sort_values(by='Moderation Date', ascending=True)\n",
    "def adjust_results(row):\n",
    "    if pd.isnull(row['final_result']):\n",
    "        row['QA Result'] = row['2nd_result']\n",
    "        row['QA Reason'] = row['2nd_rejection_reason']\n",
    "        row['Mod 2 Result'] = None\n",
    "        row['Mod 2 Reason'] = None\n",
    "        row['Mod 1 Result'] = row['1st_result']\n",
    "        row['Mod 1 Reason'] = row['1st_rejection_reason']\n",
    "    else:\n",
    "        row['QA Result'] = row['final_result']\n",
    "        row['QA Reason'] = row['wrong_label']\n",
    "        row['Mod 2 Result'] = row['result_2']\n",
    "        mod_2_reason_values = [str(row[f'2_annotation.{i}']).lower() for i in range(1, 5) if not pd.isnull(row[f'2_annotation.{i}'])]\n",
    "        row['Mod 2 Reason'] = ', '.join(mod_2_reason_values) if mod_2_reason_values else np.nan\n",
    "        row['Mod 1 Result'] = row['result_1']\n",
    "        mod_1_reason_values = [str(row[f'1_annotation.{i}']).lower() for i in range(1, 5) if not pd.isnull(row[f'1_annotation.{i}'])]\n",
    "        row['Mod 2 Reason'] = ', '.join(mod_1_reason_values) if mod_1_reason_values else np.nan\n",
    "    return row\n",
    "G_UPL_rawdata = G_UPL_rawdata.apply(adjust_results, axis=1)\n",
    "G_UPL_rawdata = G_UPL_rawdata.rename(columns={'source_file':'Week'})\n",
    "def fill_final_decision(row):\n",
    "    valid_values = ['Failed appeal', 'Edge case', 'Appeal successfully']\n",
    "    for column in ['final_result','final_decision_(pbo)', 'bd_qa_decision', '[bpo_qa]_decision']:\n",
    "        if row[column] in valid_values:\n",
    "            return row[column]\n",
    "        elif pd.notnull(row[column]):\n",
    "            return row[column]\n",
    "    return ''\n",
    "G_UPL_rawdata['Final Decision'] = G_UPL_rawdata.apply(fill_final_decision, axis=1)\n",
    "G_UPL_rawdata['Final Decision'] = G_UPL_rawdata['Final Decision'].fillna('Mod correct')\n",
    "for k, v in aliases_final_decision.items():\n",
    "    pat = '|'.join(v)\n",
    "    G_UPL_rawdata.loc[G_UPL_rawdata['Final Decision'].str.contains(pat, case=False),'Final Decision'] = k\n",
    "def set_policy_error(row):\n",
    "    if row['Final Decision'] in ['Failed appeal', 'Edge case']:\n",
    "        return row['2nd_rejection_reason']\n",
    "    else:\n",
    "        return row['1st_rejection_reason']\n",
    "G_UPL_rawdata['Policy Error'] = G_UPL_rawdata.apply(set_policy_error, axis=1) \n",
    "def check_approval_status(value):\n",
    "    for status, keywords in aliases.items():\n",
    "        found_keywords = [keyword for keyword in keywords if keyword in value.lower()]\n",
    "        if found_keywords:\n",
    "            return status\n",
    "    return None\n",
    "columns_to_check = ['Mod 1 Result', 'Mod 2 Result', 'QA Result']\n",
    "for column in columns_to_check:\n",
    "    G_UPL_rawdata[column] = G_UPL_rawdata[column].apply(lambda x: check_approval_status(x) if isinstance(x, str) else np.nan)            \n",
    "def get_moderation_error_round(row):\n",
    "    if row['Final Decision'] == 'Failed appeal':\n",
    "        if row['Mod 1 Result'] != row['QA Result']:\n",
    "            return '1st wrong'\n",
    "        elif row['Mod 2 Result'] != row['QA Result']:\n",
    "            return '2nd wrong'\n",
    "    return ''\n",
    "G_UPL_rawdata['Moderation_Error_Round'] = G_UPL_rawdata.apply(get_moderation_error_round, axis=1)\n",
    "\n",
    "G_UPL_lineup = G_UPL_rawdata[['Moderation Date','Queue Name','Moderators Name','Moderators Name 2','Count','Moderation_Error_Round']]\n",
    "G_UPL_lineup_1 = G_UPL_lineup[['Moderation Date','Queue Name','Moderators Name','Count','Moderation_Error_Round']]\n",
    "G_UPL_lineup_2 = G_UPL_lineup[['Moderation Date','Queue Name','Moderators Name 2','Count','Moderation_Error_Round']]\n",
    "\n",
    "G_UPL_lineup_1_sample_size = G_UPL_lineup_1.groupby(['Moderation Date', 'Queue Name', 'Moderators Name'], as_index=False)['Count'].count()\n",
    "G_UPL_lineup_2_sample_size = G_UPL_lineup_2.groupby(['Moderation Date', 'Queue Name', 'Moderators Name 2'], as_index=False)['Count'].count()\n",
    "G_UPL_lineup_sample_size = pd.concat([G_UPL_lineup_1_sample_size, G_UPL_lineup_2_sample_size], ignore_index=True)\n",
    "G_UPL_lineup_sample_size['Moderators Name'] = G_UPL_lineup_sample_size['Moderators Name'].fillna(G_UPL_lineup_sample_size['Moderators Name 2'])\n",
    "G_UPL_lineup_sample_size.drop(['Moderators Name 2'], axis=1, inplace=True)\n",
    "\n",
    "G_UPL_sample_size = pd.merge(G_UPL_lineup_sample_size,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "G_UPL_sample_size = G_UPL_sample_size.rename(columns={'Count': 'Sample Size','UPL_Week':'Week'})\n",
    "G_UPL_sample_size = G_UPL_sample_size[['Week','Moderation Date','Queue Name','Moderators Name','Sample Size']]\n",
    "for week in G_UPL_sample_size['Week'].unique():\n",
    "    df = G_UPL_sample_size[G_UPL_sample_size['Week'] == week]\n",
    "    df.to_csv(f'Sample Size All Queues/G_UPL/{week}.csv', index=False)\n",
    "G_UPL_lineup_1_mod_wrong = G_UPL_lineup_1.groupby(['Moderation Date', 'Queue Name', 'Moderators Name'])['Moderation_Error_Round'].apply(lambda x: ((x == '1st wrong')).sum()).reset_index(name='Mods Wrong')\n",
    "G_UPL_lineup_2_mod_wrong = G_UPL_lineup_2[~G_UPL_lineup_2['Moderators Name 2'].isnull()]\n",
    "G_UPL_lineup_2_mod_wrong = G_UPL_lineup_2_mod_wrong.groupby(['Moderation Date', 'Queue Name', 'Moderators Name 2'])['Moderation_Error_Round'].apply(lambda x: ((x == '2nd wrong')).sum()).reset_index(name='Mods Wrong')\n",
    "G_UPL_lineup_mod_wrong = pd.concat([G_UPL_lineup_1_mod_wrong, G_UPL_lineup_2_mod_wrong], ignore_index=True)\n",
    "G_UPL_lineup_mod_wrong['Moderators Name'] = G_UPL_lineup_mod_wrong['Moderators Name'].fillna(G_UPL_lineup_mod_wrong['Moderators Name 2'])\n",
    "G_UPL_lineup_mod_wrong.drop(['Moderators Name 2'], axis=1, inplace=True)\n",
    "G_UPL_mod_wrong = pd.merge(G_UPL_lineup_mod_wrong,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "G_UPL_mod_wrong = G_UPL_mod_wrong.rename(columns={'UPL_Week':'Week'})\n",
    "G_UPL_mod_wrong = G_UPL_mod_wrong[['Week','Moderation Date','Queue Name','Moderators Name','Mods Wrong']]\n",
    "for week in G_UPL_mod_wrong['Week'].unique():\n",
    "    df = G_UPL_mod_wrong[G_UPL_mod_wrong['Week'] == week]\n",
    "    df.to_csv(f'False case All Queues/G_UPL/{week}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labeling\n",
    "labeling_rawdata = pd.read_excel('Labeling/Labeling accr.xlsx')\n",
    "labeling_rawdata = pd.merge(labeling_rawdata,week_list,how='left',left_on='Date',right_on='Date')\n",
    "labeling_sample_size = labeling_rawdata.groupby(['Labeling_Week','Date','Category','Email'],as_index=False)['Sample size (QA output)'].apply(lambda y: y[y > 0].sum())\n",
    "labeling_sample_size = labeling_sample_size[['Labeling_Week','Date','Category','Email','Sample size (QA output)']].rename(columns={'Date':'Moderation Date', 'Labeling_Week':'Week',\n",
    "                                                                                                            'Category':'Queue Name',\n",
    "                                                                                                            'Email':'Moderators Name',\n",
    "                                                                                                            'Sample size (QA output)':'Sample Size'}) \n",
    "labeling_sample_size['Moderation Date'] = pd.to_datetime(labeling_sample_size['Moderation Date'].apply(convert_datetime))\n",
    " \n",
    "labeling_mod_wrong = labeling_rawdata.groupby(['Labeling_Week','Date','Category','Email'],as_index=False)['Mod wrong tagging'].apply(lambda y: y[y > 0].sum())\n",
    "labeling_mod_wrong = labeling_mod_wrong[['Labeling_Week','Date','Category','Email','Mod wrong tagging']].rename(columns={'Date':'Moderation Date', 'Labeling_Week':'Week',\n",
    "                                                                                                            'Category':'Queue Name',\n",
    "                                                                                                            'Email':'Moderators Name',\n",
    "                                                                                                            'Mod wrong tagging':'Mods Wrong'})  \n",
    "labeling_mod_wrong['Moderation Date'] = pd.to_datetime(labeling_mod_wrong['Moderation Date'].apply(convert_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Side project\n",
    "side_project_rawdata = merge_csv_files_sideproject('Side_project')\n",
    "side_project_rawdata['mod_date'] = pd.to_datetime(side_project_rawdata['mod_date'].apply(convert_datetime))            \n",
    "side_project_rawdata['Queue Name'] = side_project_rawdata['Queue Name'].replace('QA ?UG-2R-GnE?TTS-vi-VN', 'QA [UG-2R-GnE] TTS-vi-VN')\n",
    "side_project_rawdata['BD QA Decision'] = side_project_rawdata['BD QA Decision'].replace('---', '')\n",
    "\n",
    "def fill_final_decision(row):\n",
    "    valid_values = ['Failed appeal', 'Edge case', 'Appeal successfully']\n",
    "    \n",
    "    if row['BD QA Decision'] in valid_values:\n",
    "        return row['BD QA Decision']\n",
    "    elif pd.notnull(row['Final Decision']):\n",
    "        return row['Final Decision']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "side_project_rawdata['Final Decision'] = side_project_rawdata.apply(fill_final_decision, axis=1)\n",
    "side_project_rawdata['Final Decision'] = side_project_rawdata['Final Decision'].fillna('Mod correct')\n",
    "for k, v in aliases_final_decision.items():\n",
    "    pat = '|'.join(v)\n",
    "    side_project_rawdata.loc[side_project_rawdata['Final Decision'].str.contains(pat, case=False),'Final Decision'] = k\n",
    "Side_prj_sample_size = side_project_rawdata.groupby(by=['Week','mod_date','Queue Name','mod'],as_index=False).agg({'object id':'count'}).sort_values(by=['mod_date'],ascending=True).rename(columns={'mod_date':'Moderation Date','Queue Name':'Queue Name','mod':'Moderators Name','object id':'Sample Size'})\n",
    "Side_prj_sample_size = pd.merge(Side_prj_sample_size,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "Side_prj_sample_size = Side_prj_sample_size[['Week','Moderation Date','Queue Name','Moderators Name','Sample Size']]\n",
    "for week in Side_prj_sample_size['Week'].unique():\n",
    "    df = Side_prj_sample_size[Side_prj_sample_size['Week'] == week]\n",
    "    df.to_csv(f'Sample Size All Queues/Side_project/{week}.csv', index=False)\n",
    "#diff case - Side project\n",
    "Side_prj_mod_wrong = side_project_rawdata.groupby(['mod_date','Queue Name','mod'],as_index=False)['Final Decision'].apply(lambda y: y[y ==\"Failed appeal\"].count())\n",
    "Side_prj_mod_wrong = Side_prj_mod_wrong[['mod_date','Queue Name','mod','Final Decision']].rename(columns={'mod_date':'Moderation Date',\n",
    "                                                                                    'Queue Name':'Queue Name',\n",
    "                                                                                    'mod':'Moderators Name',\n",
    "                                                                                    'Final Decision':'Mods Wrong'})\n",
    "Side_prj_mod_wrong = pd.merge(Side_prj_mod_wrong,week_list,how='left',left_on='Moderation Date',right_on='Date').rename(columns={'Mod_Week':'Week'})\n",
    "Side_prj_mod_wrong = Side_prj_mod_wrong[['Week','Moderation Date','Queue Name','Moderators Name','Mods Wrong']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No-Anchor\n",
    "no_anchor_rawdata = merge_csv_files_sideproject('No-Anchor')\n",
    "no_anchor_rawdata['mod_date'] = pd.to_datetime(no_anchor_rawdata['mod_date'].apply(convert_datetime))            \n",
    "no_anchor_rawdata['BD QA Decision'] = no_anchor_rawdata['BD QA Decision'].replace('---', '')\n",
    "\n",
    "def fill_final_decision(row):\n",
    "    valid_values = ['Failed appeal', 'Edge case', 'Appeal successfully']\n",
    "    if row['BD QA Decision'] in valid_values:\n",
    "        return row['BD QA Decision']\n",
    "    elif pd.notnull(row['Final Decision']):\n",
    "        return row['Final Decision']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "no_anchor_rawdata['Final Decision'] = no_anchor_rawdata.apply(fill_final_decision, axis=1)\n",
    "no_anchor_rawdata['Final Decision'] = no_anchor_rawdata['Final Decision'].fillna('Mod correct')\n",
    "for k, v in aliases_final_decision.items():\n",
    "    pat = '|'.join(v)\n",
    "    no_anchor_rawdata.loc[no_anchor_rawdata['Final Decision'].str.contains(pat, case=False),'Final Decision'] = k\n",
    "no_anchor_sample_size = no_anchor_rawdata.groupby(by=['Week','mod_date','Queue Name','mod'],as_index=False).agg({'object id':'count'}).sort_values(by=['mod_date'],ascending=True).rename(columns={'mod_date':'Moderation Date','Queue Name':'Queue Name','mod':'Moderators Name','object id':'Sample Size'})\n",
    "no_anchor_sample_size = pd.merge(no_anchor_sample_size,week_list,how='left',left_on='Moderation Date',right_on='Date')\n",
    "no_anchor_sample_size = no_anchor_sample_size[['Week','Moderation Date','Queue Name','Moderators Name','Sample Size']]\n",
    "for week in no_anchor_sample_size['Week'].unique():\n",
    "    df = no_anchor_sample_size[no_anchor_sample_size['Week'] == week]\n",
    "    df.to_csv(f'Sample Size All Queues/No-Anchor/{week}.csv', index=False)\n",
    "#diff case - no-anchor\n",
    "no_anchor_mod_wrong = no_anchor_rawdata.groupby(['mod_date','Queue Name','mod'],as_index=False)['Final Decision'].apply(lambda y: y[y ==\"Failed appeal\"].count())\n",
    "no_anchor_mod_wrong = no_anchor_mod_wrong[['mod_date','Queue Name','mod','Final Decision']].rename(columns={'mod_date':'Moderation Date',\n",
    "                                                                                    'Queue Name':'Queue Name',\n",
    "                                                                                    'mod':'Moderators Name',\n",
    "                                                                                    'Final Decision':'Mods Wrong'})\n",
    "no_anchor_mod_wrong = pd.merge(no_anchor_mod_wrong,week_list,how='left',left_on='Moderation Date',right_on='Date').rename(columns={'Mod_Week':'Week'})\n",
    "no_anchor_mod_wrong = no_anchor_mod_wrong[['Week','Moderation Date','Queue Name','Moderators Name','Mods Wrong']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Exported Date', 'Week', 'Queue Category', 'Queue Name', 'Task ID',\n",
      "       'Object ID', 'Mod Date', 'Mod Email', 'Mod Name', 'Line Manager',\n",
      "       'Duration', 'R1 Result', 'Policy Error', 'R1 Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "unoficial_cases_raw = input_data_csv('Random_unofficial_queues') \n",
    "unoficial_cases_raw = unoficial_cases_raw.iloc[:,:14]\n",
    "unoficial_cases_raw['Mod Date'] = pd.to_datetime(unoficial_cases_raw['Mod Date'].apply(convert_datetime))   \n",
    "print(unoficial_cases_raw.columns)\n",
    "unoficial_sample_size = unoficial_cases_raw.groupby(by=['Week','Mod Date','Queue Name','Mod Email'],as_index=False).agg({'Object ID':'count'}).sort_values(by=['Mod Date'],ascending=True).rename(columns={'Mod Date':'Moderation Date','Queue Name':'Queue Name','Mod Email':'Moderators Name','Object ID':'Sample Size'})\n",
    "unoficial_sample_size = unoficial_sample_size[['Week','Moderation Date','Queue Name','Moderators Name','Sample Size']]\n",
    "\n",
    "unoficial_mod_wrong = unoficial_cases_raw.groupby(['Week','Mod Date','Queue Name','Mod Email'],as_index=False)['R1 Status'].apply(lambda y: y[y =='Mod Wrong'].count())\n",
    "unoficial_mod_wrong = unoficial_mod_wrong[['Week','Mod Date','Queue Name','Mod Email','R1 Status']].rename(columns={'Mod Date':'Moderation Date',\n",
    "                                                                                    'Queue Name':'Queue Name',\n",
    "                                                                                    'Mod Email':'Moderators Name',\n",
    "                                                                                    'R1 Status':'OEC/Backup Mod Wrong'})\n",
    "unoficial_mod_wrong = unoficial_mod_wrong[['Week','Moderation Date','Queue Name','Moderators Name','OEC/Backup Mod Wrong']]\n",
    "unoficial = pd.merge(unoficial_sample_size,unoficial_mod_wrong,how='left',left_on=['Week','Moderation Date','Queue Name','Moderators Name'],right_on=['Week','Moderation Date','Queue Name','Moderators Name'])\n",
    "unoficial = unoficial.groupby(by=['Week','Moderation Date','Queue Name','Moderators Name'],as_index=False).agg({'OEC/Backup Mod Wrong':'sum'})\n",
    "unoficial = unoficial[~unoficial['OEC/Backup Mod Wrong'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample_sizes = pd.concat([regular_sample_size, appeal_sample_size, E_UPL_sample_size, labeling_sample_size, Side_prj_sample_size,no_anchor_sample_size],axis=0)\n",
    "all_sample_sizes['Moderators Name'] = all_sample_sizes['Moderators Name'].str.replace('robot_estimate@','')\n",
    "all_sample_sizes = all_sample_sizes.drop_duplicates(subset=['Moderation Date','Queue Name','Moderators Name'],keep='first')\n",
    "for week in all_sample_sizes['Week'].unique():\n",
    "    df = all_sample_sizes[all_sample_sizes['Week'] == week]\n",
    "    df.to_csv(f'Sample Size All Queues/All/{week}.csv', index=False)\n",
    "\n",
    "all_mod_wrong =  pd.concat([regular_mod_wrong,appeal_mod_wrong,E_UPL_mod_wrong,labeling_mod_wrong,Side_prj_mod_wrong,no_anchor_mod_wrong],axis=0)\n",
    "all_mod_wrong['Moderators Name'] = all_mod_wrong['Moderators Name'].str.replace('robot_estimate@','')\n",
    "all_mod_wrong = all_mod_wrong.drop_duplicates()\n",
    "for week in all_mod_wrong['Week'].unique():\n",
    "    df = all_mod_wrong[all_mod_wrong['Week'] == week]\n",
    "    df.to_csv(f'False case All Queues/All/{week}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>COMPOUND</th>\n",
       "      <th>MOD QUEUE NAME</th>\n",
       "      <th>QA QUEUE NAME</th>\n",
       "      <th>Moderator</th>\n",
       "      <th>Final Decision</th>\n",
       "      <th>Error Category 1</th>\n",
       "      <th>Error Category 2</th>\n",
       "      <th>Error Category 3</th>\n",
       "      <th>quanity_failed_appeal</th>\n",
       "      <th>quanity_edge_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15400</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL Anchor Video 02</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>anh.pht@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. People</td>\n",
       "      <td>1.5 Policy Misinterpretation</td>\n",
       "      <td>1.5.1 Misinterpretation of the existing guideline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15401</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL Anchor Video 02</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>anh.tnm@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. People</td>\n",
       "      <td>1.4 Content Misinterpretation</td>\n",
       "      <td>1.4.1 Misinterpretation of the content</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15402</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL Anchor Video 02</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>hao.th@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. People</td>\n",
       "      <td>1.3 Negligence</td>\n",
       "      <td>1.3.4 Pursuing AHT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15403</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL Anchor Video 02</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>huy.ltk@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. People</td>\n",
       "      <td>1.5 Policy Misinterpretation</td>\n",
       "      <td>1.5.1 Misinterpretation of the existing guideline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15404</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL Anchor Video 02</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>kieu.nlp@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. People</td>\n",
       "      <td>1.3 Negligence</td>\n",
       "      <td>1.3.1 Mis-click/Mis-tagging</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16223</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>Seller</td>\n",
       "      <td>VN LL Seller On Boarding</td>\n",
       "      <td>[QA]VN LL Seller On Boarding</td>\n",
       "      <td>sang.ta@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. Mod_Enforcement</td>\n",
       "      <td>1.4 Mod_Policy Misinterpretation</td>\n",
       "      <td>1.4.1 Mod misinterpretation of the existing gu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16224</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>Seller</td>\n",
       "      <td>VN LL Seller On Boarding</td>\n",
       "      <td>[QA]VN LL Seller On Boarding</td>\n",
       "      <td>thanh.lvp@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. Mod_Enforcement</td>\n",
       "      <td>1.1 Mod_Negligence</td>\n",
       "      <td>1.1.4 Mod oversight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16225</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>Seller</td>\n",
       "      <td>VN VAT Number Check</td>\n",
       "      <td>QA VN VAT Number Check</td>\n",
       "      <td>dao.lnt@trans-cosmos.com.vn</td>\n",
       "      <td>Edge case</td>\n",
       "      <td>4. Platform/Tooling</td>\n",
       "      <td>4.2 Platform Issue</td>\n",
       "      <td>4.2.3 Access Issue</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16226</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>Seller</td>\n",
       "      <td>VN VAT Number Check</td>\n",
       "      <td>QA VN VAT Number Check</td>\n",
       "      <td>dara.kd@trans-cosmos.com.vn</td>\n",
       "      <td>Edge case</td>\n",
       "      <td>4. Platform/Tooling</td>\n",
       "      <td>4.2 Platform Issue</td>\n",
       "      <td>4.2.3 Access Issue</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16227</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>Seller</td>\n",
       "      <td>VN VAT Number Check</td>\n",
       "      <td>QA VN VAT Number Check</td>\n",
       "      <td>hieu.nm3@trans-cosmos.com.vn</td>\n",
       "      <td>Failed appeal</td>\n",
       "      <td>1. Mod_Enforcement</td>\n",
       "      <td>1.5 Mod_Process Knowledge Gap</td>\n",
       "      <td>1.5.5 Mod did not follow proper moderation pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Quarter Month                 Week      COMPOUND  \\\n",
       "15400      4.0   Nov  W44 (10.29 - 11.04)  Anchor Video   \n",
       "15401      4.0   Nov  W44 (10.29 - 11.04)  Anchor Video   \n",
       "15402      4.0   Nov  W44 (10.29 - 11.04)  Anchor Video   \n",
       "15403      4.0   Nov  W44 (10.29 - 11.04)  Anchor Video   \n",
       "15404      4.0   Nov  W44 (10.29 - 11.04)  Anchor Video   \n",
       "...        ...   ...                  ...           ...   \n",
       "16223      4.0   Nov  W47 (11.19 - 11.25)        Seller   \n",
       "16224      4.0   Nov  W47 (11.19 - 11.25)        Seller   \n",
       "16225      4.0   Nov  W47 (11.19 - 11.25)        Seller   \n",
       "16226      4.0   Nov  W47 (11.19 - 11.25)        Seller   \n",
       "16227      4.0   Nov  W47 (11.19 - 11.25)        Seller   \n",
       "\n",
       "                 MOD QUEUE NAME                 QA QUEUE NAME  \\\n",
       "15400     VN LL Anchor Video 02    [QA] VN LL Anchor Video 02   \n",
       "15401     VN LL Anchor Video 02    [QA] VN LL Anchor Video 02   \n",
       "15402     VN LL Anchor Video 02    [QA] VN LL Anchor Video 02   \n",
       "15403     VN LL Anchor Video 02    [QA] VN LL Anchor Video 02   \n",
       "15404     VN LL Anchor Video 02    [QA] VN LL Anchor Video 02   \n",
       "...                         ...                           ...   \n",
       "16223  VN LL Seller On Boarding  [QA]VN LL Seller On Boarding   \n",
       "16224  VN LL Seller On Boarding  [QA]VN LL Seller On Boarding   \n",
       "16225       VN VAT Number Check        QA VN VAT Number Check   \n",
       "16226       VN VAT Number Check        QA VN VAT Number Check   \n",
       "16227       VN VAT Number Check        QA VN VAT Number Check   \n",
       "\n",
       "                           Moderator Final Decision     Error Category 1  \\\n",
       "15400    anh.pht@trans-cosmos.com.vn  Failed appeal            1. People   \n",
       "15401    anh.tnm@trans-cosmos.com.vn  Failed appeal            1. People   \n",
       "15402     hao.th@trans-cosmos.com.vn  Failed appeal            1. People   \n",
       "15403    huy.ltk@trans-cosmos.com.vn  Failed appeal            1. People   \n",
       "15404   kieu.nlp@trans-cosmos.com.vn  Failed appeal            1. People   \n",
       "...                              ...            ...                  ...   \n",
       "16223    sang.ta@trans-cosmos.com.vn  Failed appeal   1. Mod_Enforcement   \n",
       "16224  thanh.lvp@trans-cosmos.com.vn  Failed appeal   1. Mod_Enforcement   \n",
       "16225    dao.lnt@trans-cosmos.com.vn      Edge case  4. Platform/Tooling   \n",
       "16226    dara.kd@trans-cosmos.com.vn      Edge case  4. Platform/Tooling   \n",
       "16227   hieu.nm3@trans-cosmos.com.vn  Failed appeal   1. Mod_Enforcement   \n",
       "\n",
       "                       Error Category 2  \\\n",
       "15400      1.5 Policy Misinterpretation   \n",
       "15401     1.4 Content Misinterpretation   \n",
       "15402                    1.3 Negligence   \n",
       "15403      1.5 Policy Misinterpretation   \n",
       "15404                    1.3 Negligence   \n",
       "...                                 ...   \n",
       "16223  1.4 Mod_Policy Misinterpretation   \n",
       "16224                1.1 Mod_Negligence   \n",
       "16225                4.2 Platform Issue   \n",
       "16226                4.2 Platform Issue   \n",
       "16227     1.5 Mod_Process Knowledge Gap   \n",
       "\n",
       "                                        Error Category 3  \\\n",
       "15400  1.5.1 Misinterpretation of the existing guideline   \n",
       "15401             1.4.1 Misinterpretation of the content   \n",
       "15402                                 1.3.4 Pursuing AHT   \n",
       "15403  1.5.1 Misinterpretation of the existing guideline   \n",
       "15404                        1.3.1 Mis-click/Mis-tagging   \n",
       "...                                                  ...   \n",
       "16223  1.4.1 Mod misinterpretation of the existing gu...   \n",
       "16224                                1.1.4 Mod oversight   \n",
       "16225                                 4.2.3 Access Issue   \n",
       "16226                                 4.2.3 Access Issue   \n",
       "16227  1.5.5 Mod did not follow proper moderation pro...   \n",
       "\n",
       "       quanity_failed_appeal  quanity_edge_case  \n",
       "15400                      1                  0  \n",
       "15401                      1                  0  \n",
       "15402                      1                  0  \n",
       "15403                      1                  0  \n",
       "15404                      1                  0  \n",
       "...                      ...                ...  \n",
       "16223                      1                  0  \n",
       "16224                      1                  0  \n",
       "16225                      0                  1  \n",
       "16226                      0                  2  \n",
       "16227                      1                  0  \n",
       "\n",
       "[805 rows x 13 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RCA - Accr Report\n",
    "RCA_diff_dive_regular_appeal = regular_appeal_Rawdata.loc[(regular_appeal_Rawdata['Final Decision'] == 'Failed appeal') | (regular_appeal_Rawdata['Final Decision'] == 'Edge case'),['mod_date','Queue Name','mod','Final Decision','Error Category 1', 'Error Category 2','Error Category 3']].rename(columns={'mod_date':'Date','Queue Name':'QA QUEUE NAME','mod':'Moderator'})\n",
    "RCA_diff_dive_regular_sideproject = side_project_rawdata.loc[(side_project_rawdata['Final Decision'] == 'Failed appeal') | (side_project_rawdata['Final Decision'] == 'Edge case'),['mod_date','Queue Name','mod','Final Decision','Error Category 1', 'Error Category 2','Error Category 3']].rename(columns={'mod_date':'Date','Queue Name':'QA QUEUE NAME','mod':'Moderator'})\n",
    "RCA_diff_dive_e_upl = E_UPL_rawdata.loc[(E_UPL_rawdata['Final Decision']=='Failed appeal') | (E_UPL_rawdata['Final Decision']=='Edge case'),['Moderation Date','Queue Name','Moderators Name','Final Decision','Error Category 1','Error Category 2', 'Error Category 3']].rename(columns={'Moderation Date':'Date','Queue Name':'QA QUEUE NAME','Moderators Name':'Moderator'})\n",
    "RCA_diff_dive_g_upl = G_UPL_rawdata.loc[(G_UPL_rawdata['Final Decision']=='Failed appeal') | (G_UPL_rawdata['Final Decision']=='Edge case'),['Moderation Date','Queue Name','Moderators Name','Final Decision','Error Category 1','Error Category 2', 'Error Category 3']].rename(columns={'1st Date':'Date','Queue Name':'QA QUEUE NAME','1st Name':'Moderator'})\n",
    "RCA_diff_dive_1 = pd.concat([RCA_diff_dive_regular_appeal.reset_index(drop=True),RCA_diff_dive_regular_sideproject.reset_index(drop=True)],axis=0)\n",
    "RCA_diff_dive_2 = pd.concat([RCA_diff_dive_e_upl.reset_index(drop=True),RCA_diff_dive_g_upl.reset_index(drop=True)],axis=0)\n",
    "RCA_diff_dive_1 = pd.merge(RCA_diff_dive_1,week_list,left_on='Date',right_on='Date',how='left').rename(columns={'Mod_Week':'Week'})\n",
    "RCA_diff_dive_2 = pd.merge(RCA_diff_dive_2,week_list,left_on='Date',right_on='Date',how='left').rename(columns={'UPL_Week':'Week'})\n",
    "RCA_diff_dive_1 = RCA_diff_dive_1[['Quarter','Month','Week','QA QUEUE NAME','Moderator','Final Decision','Error Category 1', 'Error Category 2','Error Category 3']]\n",
    "RCA_diff_dive_2 = RCA_diff_dive_2[['Quarter','Month','Week','QA QUEUE NAME','Moderator','Final Decision','Error Category 1', 'Error Category 2','Error Category 3']]\n",
    "RCA_diff_dive =  pd.concat([RCA_diff_dive_1.reset_index(drop=True)],axis=0)\n",
    "RCA_diff_dive = pd.merge(RCA_diff_dive,queue_list,how='left',left_on='QA QUEUE NAME',right_on='QA QUEUE NAME')\n",
    "RCA_diff_dive_count = RCA_diff_dive.groupby(['Quarter','Month','Week', 'COMPOUND', 'MOD QUEUE NAME', 'QA QUEUE NAME', 'Moderator','Final Decision', 'Error Category 1', 'Error Category 2','Error Category 3']).agg(\n",
    "    quanity_failed_appeal=('Final Decision', lambda x: (x == 'Failed appeal').sum()),\n",
    "    quanity_edge_case=('Final Decision', lambda x: (x == 'Edge case').sum())).reset_index()\n",
    "\n",
    "RCA_diff_dive_count = filter_week(RCA_diff_dive_count,filter_week_func,['Appeal','LL Product', 'CB Product','Livestream','Anchor Video','Seller', 'IPR'])\n",
    "RCA_diff_dive_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>COMPOUND</th>\n",
       "      <th>QA QUEUE NAME</th>\n",
       "      <th>Moderator</th>\n",
       "      <th>Policy Error</th>\n",
       "      <th>quanity_failed_appeal</th>\n",
       "      <th>quanity_edge_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>W5 (01.28 - 02.03)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>anh.tdk@trans-cosmos.com.vn</td>\n",
       "      <td>irrelevant promotion</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>W5 (01.28 - 02.03)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>anh.tdk@trans-cosmos.com.vn</td>\n",
       "      <td>misleading functionality and effect</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>W5 (01.28 - 02.03)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>chien.vm@trans-cosmos.com.vn</td>\n",
       "      <td>irrelevant promotion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>W5 (01.28 - 02.03)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>chien.vm@trans-cosmos.com.vn</td>\n",
       "      <td>redirect traffic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>W5 (01.28 - 02.03)</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>[QA] VN LL Anchor Video 02</td>\n",
       "      <td>dat.nt2@trans-cosmos.com.vn</td>\n",
       "      <td>absolute terms</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Oct</td>\n",
       "      <td>W43 (10.22 - 10.28)</td>\n",
       "      <td>Seller</td>\n",
       "      <td>[QA]VN LL Seller On Boarding</td>\n",
       "      <td>ngan.ptt1@trans-cosmos.com.vn</td>\n",
       "      <td>possible ip infringement</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Oct</td>\n",
       "      <td>W43 (10.22 - 10.28)</td>\n",
       "      <td>Seller</td>\n",
       "      <td>[QA]VN LL Seller On Boarding</td>\n",
       "      <td>thai.tq1@trans-cosmos.com.vn</td>\n",
       "      <td>unclear documentation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Oct</td>\n",
       "      <td>W43 (10.26 - 11.01)</td>\n",
       "      <td>E-UPL</td>\n",
       "      <td>[VN] Mall UP Search CB Sample QA</td>\n",
       "      <td>van.nt@trans-cosmos.com.vn</td>\n",
       "      <td>incomplete information</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Oct</td>\n",
       "      <td>W43 (10.26 - 11.01)</td>\n",
       "      <td>E-UPL</td>\n",
       "      <td>[VN] Mall UP Search L2L Sample QA</td>\n",
       "      <td>an.lht@trans-cosmos.com.vn</td>\n",
       "      <td>unsupported products</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Oct</td>\n",
       "      <td>W43 (10.26 - 11.01)</td>\n",
       "      <td>E-UPL</td>\n",
       "      <td>[VN] Mall UP Search L2L Sample QA</td>\n",
       "      <td>nhu.ttq@trans-cosmos.com.vn</td>\n",
       "      <td>inconsistent information</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Quarter Month                 Week      COMPOUND  \\\n",
       "0          1.0   Feb   W5 (01.28 - 02.03)  Anchor Video   \n",
       "1          1.0   Feb   W5 (01.28 - 02.03)  Anchor Video   \n",
       "2          1.0   Feb   W5 (01.28 - 02.03)  Anchor Video   \n",
       "3          1.0   Feb   W5 (01.28 - 02.03)  Anchor Video   \n",
       "4          1.0   Feb   W5 (01.28 - 02.03)  Anchor Video   \n",
       "...        ...   ...                  ...           ...   \n",
       "13300      4.0   Oct  W43 (10.22 - 10.28)        Seller   \n",
       "13301      4.0   Oct  W43 (10.22 - 10.28)        Seller   \n",
       "13302      4.0   Oct  W43 (10.26 - 11.01)         E-UPL   \n",
       "13303      4.0   Oct  W43 (10.26 - 11.01)         E-UPL   \n",
       "13304      4.0   Oct  W43 (10.26 - 11.01)         E-UPL   \n",
       "\n",
       "                           QA QUEUE NAME                      Moderator  \\\n",
       "0             [QA] VN LL Anchor Video 02    anh.tdk@trans-cosmos.com.vn   \n",
       "1             [QA] VN LL Anchor Video 02    anh.tdk@trans-cosmos.com.vn   \n",
       "2             [QA] VN LL Anchor Video 02   chien.vm@trans-cosmos.com.vn   \n",
       "3             [QA] VN LL Anchor Video 02   chien.vm@trans-cosmos.com.vn   \n",
       "4             [QA] VN LL Anchor Video 02    dat.nt2@trans-cosmos.com.vn   \n",
       "...                                  ...                            ...   \n",
       "13300       [QA]VN LL Seller On Boarding  ngan.ptt1@trans-cosmos.com.vn   \n",
       "13301       [QA]VN LL Seller On Boarding   thai.tq1@trans-cosmos.com.vn   \n",
       "13302   [VN] Mall UP Search CB Sample QA     van.nt@trans-cosmos.com.vn   \n",
       "13303  [VN] Mall UP Search L2L Sample QA     an.lht@trans-cosmos.com.vn   \n",
       "13304  [VN] Mall UP Search L2L Sample QA    nhu.ttq@trans-cosmos.com.vn   \n",
       "\n",
       "                              Policy Error  quanity_failed_appeal  \\\n",
       "0                     irrelevant promotion                      2   \n",
       "1      misleading functionality and effect                      1   \n",
       "2                     irrelevant promotion                      1   \n",
       "3                         redirect traffic                      1   \n",
       "4                           absolute terms                      1   \n",
       "...                                    ...                    ...   \n",
       "13300             possible ip infringement                      0   \n",
       "13301                unclear documentation                      1   \n",
       "13302               incomplete information                      1   \n",
       "13303                 unsupported products                      1   \n",
       "13304             inconsistent information                      0   \n",
       "\n",
       "       quanity_edge_case  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "13300                  1  \n",
       "13301                  0  \n",
       "13302                  0  \n",
       "13303                  0  \n",
       "13304                  1  \n",
       "\n",
       "[13305 rows x 9 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Policy Errors - Accr Report\n",
    "Policy_diff_dive_regular_appeal = regular_appeal_Rawdata.loc[(regular_appeal_Rawdata['Final Decision'] == 'Failed appeal') | (regular_appeal_Rawdata['Final Decision'] == 'Edge case'), ['mod_date', 'Queue Name', 'mod','Final Decision','Policy Error']].rename(columns={'mod_date': 'Date', 'Queue Name': 'QA QUEUE NAME','mod':'Moderator'})\n",
    "Policy_diff_dive_sideproject = side_project_rawdata.loc[(side_project_rawdata['Final Decision'] == 'Failed appeal') | (side_project_rawdata['Final Decision'] == 'Edge case'), ['mod_date', 'Queue Name','mod', 'Final Decision','Policy Error']].rename(columns={'mod_date': 'Date', 'Queue Name': 'QA QUEUE NAME','mod':'Moderator'})\n",
    "Policy_diff_dive_e_upl = E_UPL_rawdata.loc[(E_UPL_rawdata['Final Decision']=='Failed appeal') | (E_UPL_rawdata['Final Decision']=='Edge case'),['Moderation Date','Queue Name','Moderators Name','Final Decision','Policy Error']].rename(columns={'Moderation Date':'Date','Queue Name':'QA QUEUE NAME','Moderators Name':'Moderator'})\n",
    "Policy_diff_dive_g_upl = G_UPL_rawdata.loc[(G_UPL_rawdata['Final Decision']=='Failed appeal') | (G_UPL_rawdata['Final Decision']=='Edge case'),['Moderation Date','Queue Name','Moderators Name','Final Decision','Policy Error']].rename(columns={'Moderation Date':'Date','Queue Name':'QA QUEUE NAME','Moderators Name':'Moderator'})\n",
    "Policy_diff_dive_1 = pd.concat([Policy_diff_dive_regular_appeal.reset_index(drop=True),Policy_diff_dive_sideproject.reset_index(drop=True)],axis=0)\n",
    "Policy_diff_dive_2 = pd.concat([Policy_diff_dive_e_upl.reset_index(drop=True),Policy_diff_dive_g_upl.reset_index(drop=True)],axis=0)\n",
    "Policy_diff_dive_1 = pd.merge(Policy_diff_dive_1,week_list,left_on='Date',right_on='Date',how='left').rename(columns={'Mod_Week':'Week'})\n",
    "Policy_diff_dive_1 = Policy_diff_dive_1[['Quarter','Month','Week','QA QUEUE NAME','Moderator','Final Decision','Policy Error']]\n",
    "Policy_diff_dive_2 = pd.merge(Policy_diff_dive_2,week_list,left_on='Date',right_on='Date',how='left').rename(columns={'UPL_Week':'Week'})\n",
    "Policy_diff_dive_2 = Policy_diff_dive_2[['Quarter','Month','Week','QA QUEUE NAME','Moderator', 'Final Decision','Policy Error']]\n",
    "Policy_diff_dive = pd.concat([Policy_diff_dive_1.reset_index(drop=True), Policy_diff_dive_2.reset_index(drop=True)], axis = 0)\n",
    "Policy_errors = policy_errors_list.copy()\n",
    "Policy_diff_dive['Policy Error'] = Policy_diff_dive['Policy Error'].str.lower()\n",
    "Policy_errors_pattern = \"|\".join(Policy_errors)\n",
    "def pattern_searcher(search_str:str, search_list:str):\n",
    "    search_obj = re.search(search_list, search_str)\n",
    "    if search_obj :\n",
    "        return_str = search_str[search_obj.start(): search_obj.end()]\n",
    "    else:\n",
    "        return_str = np.nan\n",
    "    return return_str\n",
    "Policy_diff_dive['Policy Error'] = Policy_diff_dive['Policy Error'].astype(str).apply(lambda x: pattern_searcher(search_str=x, search_list=Policy_errors_pattern))\n",
    "Policy_diff_dive = pd.merge(Policy_diff_dive,queue_list,how='left',left_on='QA QUEUE NAME',right_on='QA QUEUE NAME')\n",
    "Policy_errors_count = Policy_diff_dive.groupby(['Quarter','Month','Week', 'COMPOUND', 'QA QUEUE NAME','Moderator', 'Policy Error']).agg(quanity_failed_appeal=('Final Decision', lambda x: (x == 'Failed appeal').sum()), quanity_edge_case=('Final Decision', lambda x: (x == 'Edge case').sum())).reset_index()\n",
    "Policy_errors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>COMPOUND</th>\n",
       "      <th>MOD QUEUE NAME</th>\n",
       "      <th>QA QUEUE NAME</th>\n",
       "      <th>Moderator</th>\n",
       "      <th>Overkill_Overall</th>\n",
       "      <th>Overkill</th>\n",
       "      <th>Leakage_Overall</th>\n",
       "      <th>Leakage</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>%Overkill</th>\n",
       "      <th>%Leakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>W1 (12.31 - 01.06)</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>LL Product</td>\n",
       "      <td>VN LL Product Initial Review</td>\n",
       "      <td>QA VN LL Product Initial Review</td>\n",
       "      <td>sang.tt1@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9645</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>W1 (12.31 - 01.06)</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Livestream</td>\n",
       "      <td>VN LL Live Report 02</td>\n",
       "      <td>[QA] VN LL Live Report 02</td>\n",
       "      <td>nhu.nvq@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9646</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>W1 (12.31 - 01.06)</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Livestream</td>\n",
       "      <td>VN LL Live Report 02</td>\n",
       "      <td>[QA] VN LL Live Report 02</td>\n",
       "      <td>quyen.tt4@trans-cosmos.com.vn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8855</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>W1 (12.31 - 01.06)</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Livestream</td>\n",
       "      <td>VN LL Live 02</td>\n",
       "      <td>[QA] VN LL Live 02</td>\n",
       "      <td>an.hb2@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>W1 (12.31 - 01.06)</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Livestream</td>\n",
       "      <td>VN LL Live 02</td>\n",
       "      <td>[QA] VN LL Live 02</td>\n",
       "      <td>gia.pn@trans-cosmos.com.vn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>W47 (11.23 - 11.29)</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>E-UPL</td>\n",
       "      <td>[VN] Mall UP Search L2L Sample</td>\n",
       "      <td>[VN] Mall UP Search L2L Sample QA</td>\n",
       "      <td>anh.tnm@trans-cosmos.com.vn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>W48 (11.26 - 12.02)</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>LL Product</td>\n",
       "      <td>VN LL Product Initial Review</td>\n",
       "      <td>QA VN LL Product Initial Review</td>\n",
       "      <td>huyen.nt5@trans-cosmos.com.vn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>W48 (11.26 - 12.02)</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN Product IPR initial review</td>\n",
       "      <td>QA VN Product IPR initial review</td>\n",
       "      <td>thien.ld@trans-cosmos.com.vn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13065</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>W48 (11.26 - 12.02)</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>CB Product</td>\n",
       "      <td>VN CB Product Buffer</td>\n",
       "      <td>[QA]VN CB Product Buffer</td>\n",
       "      <td>duong.pt@trans-cosmos.com.vn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>W48 (11.26 - 12.02)</td>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>LL Product</td>\n",
       "      <td>VN LL Product Initial Review</td>\n",
       "      <td>QA VN LL Product Initial Review</td>\n",
       "      <td>truc.htt@trans-cosmos.com.vn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16039 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Quarter Month                 Week       Date    COMPOUND  \\\n",
       "2912       1.0   Jan   W1 (12.31 - 01.06) 2022-12-31  LL Product   \n",
       "9645       1.0   Jan   W1 (12.31 - 01.06) 2022-12-31  Livestream   \n",
       "9646       1.0   Jan   W1 (12.31 - 01.06) 2022-12-31  Livestream   \n",
       "8855       1.0   Jan   W1 (12.31 - 01.06) 2022-12-31  Livestream   \n",
       "8856       1.0   Jan   W1 (12.31 - 01.06) 2022-12-31  Livestream   \n",
       "...        ...   ...                  ...        ...         ...   \n",
       "15889      4.0   Dec  W47 (11.23 - 11.29) 2023-11-28       E-UPL   \n",
       "4849       4.0   Dec  W48 (11.26 - 12.02) 2023-11-28  LL Product   \n",
       "15980      4.0   Dec  W48 (11.26 - 12.02) 2023-11-28         IPR   \n",
       "13065      4.0   Dec  W48 (11.26 - 12.02) 2023-11-28  CB Product   \n",
       "4852       4.0   Dec  W48 (11.26 - 12.02) 2023-11-28  LL Product   \n",
       "\n",
       "                       MOD QUEUE NAME                      QA QUEUE NAME  \\\n",
       "2912     VN LL Product Initial Review    QA VN LL Product Initial Review   \n",
       "9645             VN LL Live Report 02          [QA] VN LL Live Report 02   \n",
       "9646             VN LL Live Report 02          [QA] VN LL Live Report 02   \n",
       "8855                    VN LL Live 02                 [QA] VN LL Live 02   \n",
       "8856                    VN LL Live 02                 [QA] VN LL Live 02   \n",
       "...                               ...                                ...   \n",
       "15889  [VN] Mall UP Search L2L Sample  [VN] Mall UP Search L2L Sample QA   \n",
       "4849     VN LL Product Initial Review    QA VN LL Product Initial Review   \n",
       "15980   VN Product IPR initial review   QA VN Product IPR initial review   \n",
       "13065            VN CB Product Buffer           [QA]VN CB Product Buffer   \n",
       "4852     VN LL Product Initial Review    QA VN LL Product Initial Review   \n",
       "\n",
       "                           Moderator  Overkill_Overall  Overkill  \\\n",
       "2912    sang.tt1@trans-cosmos.com.vn               1.0       0.0   \n",
       "9645     nhu.nvq@trans-cosmos.com.vn               1.0       1.0   \n",
       "9646   quyen.tt4@trans-cosmos.com.vn               0.0       0.0   \n",
       "8855      an.hb2@trans-cosmos.com.vn               1.0       1.0   \n",
       "8856      gia.pn@trans-cosmos.com.vn               0.0       0.0   \n",
       "...                              ...               ...       ...   \n",
       "15889    anh.tnm@trans-cosmos.com.vn               0.0       0.0   \n",
       "4849   huyen.nt5@trans-cosmos.com.vn               0.0       0.0   \n",
       "15980   thien.ld@trans-cosmos.com.vn               0.0       0.0   \n",
       "13065   duong.pt@trans-cosmos.com.vn               0.0       0.0   \n",
       "4852    truc.htt@trans-cosmos.com.vn               0.0       0.0   \n",
       "\n",
       "       Leakage_Overall  Leakage  Sample Size  %Overkill  %Leakage  \n",
       "2912               0.0      0.0          4.0   0.000000  0.000000  \n",
       "9645               0.0      0.0          6.0   0.166667  0.000000  \n",
       "9646               1.0      1.0          2.0   0.000000  0.500000  \n",
       "8855               0.0      0.0          2.0   0.500000  0.000000  \n",
       "8856               1.0      1.0          3.0   0.000000  0.333333  \n",
       "...                ...      ...          ...        ...       ...  \n",
       "15889              1.0      1.0          9.0   0.000000  0.111111  \n",
       "4849               1.0      1.0          2.0   0.000000  0.500000  \n",
       "15980              1.0      1.0          6.0   0.000000  0.166667  \n",
       "13065              1.0      1.0          3.0   0.000000  0.333333  \n",
       "4852               1.0      1.0          1.0   0.000000  1.000000  \n",
       "\n",
       "[16039 rows x 15 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FN/ FP Rate - Accr Report - Regular/Appeal\n",
    "False_errors_regular_appeal = regular_appeal_Rawdata.loc[~regular_appeal_Rawdata['Final Decision'].isnull(),['mod_date','Queue Name','mod','Final Decision','Final False Error']].rename(columns={'mod_date':'Date','Queue Name':'QA QUEUE NAME','mod':'Moderator'})\n",
    "False_errors_sideproject = side_project_rawdata.loc[~side_project_rawdata['Final Decision'].isnull(),['mod_date','Queue Name','mod','Final Decision','Final False Error']].rename(columns={'mod_date':'Date','Queue Name':'QA QUEUE NAME','mod':'Moderator'})\n",
    "False_errors_e_upl = E_UPL_rawdata.loc[~E_UPL_rawdata['Final Decision'].isnull(),['Moderation Date','Queue Name','Moderators Name','Final Decision','moderators_false_error']].rename(columns={'Moderation Date':'Date','Queue Name':'QA QUEUE NAME','moderators_false_error':'Final False Error','Moderators Name':'Moderator'})\n",
    "False_errors_g_upl = G_UPL_rawdata.loc[~G_UPL_rawdata['Final Decision'].isnull(),['Moderation Date','Queue Name','Moderators Name','Final Decision','moderators_false_error']].rename(columns={'Moderation Date':'Date','Queue Name':'QA QUEUE NAME','moderators_false_error':'Final False Error','Moderators Name':'Moderator'})\n",
    "False_errors_concat_1 = pd.concat([False_errors_regular_appeal.reset_index(drop=True), False_errors_sideproject.reset_index(drop=True)], axis = 0)\n",
    "False_errors_concat_2 = pd.concat([False_errors_e_upl.reset_index(drop=True),False_errors_g_upl.reset_index(drop=True)], axis = 0)\n",
    "False_errors_concat_1['Final False Error'] = False_errors_concat_1['Final False Error'].str.title()\n",
    "False_errors_concat_2['Final False Error'] = False_errors_concat_2['Final False Error'].str.title()\n",
    "False_errors_1 = pd.merge(False_errors_concat_1,week_list,left_on='Date',right_on='Date',how='left').rename(columns={'Mod_Week':'Week','Date_x':'Date'})\n",
    "False_errors_2 = pd.merge(False_errors_concat_2,week_list,left_on='Date',right_on='Date',how='left').rename(columns={'UPL_Week':'Week'})\n",
    "False_errors_1 = False_errors_1[['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator','Final Decision','Final False Error']]\n",
    "False_errors_2 = False_errors_2[['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator','Final Decision','Final False Error']]\n",
    "False_errors =  pd.concat([False_errors_1.reset_index(drop=True), False_errors_2.reset_index(drop=True)], axis = 0)\n",
    "Overkill =  False_errors[(False_errors['Final Decision'].isin(['Failed appeal'])) & (False_errors['Final False Error'] == 'False Positive')]\n",
    "Overkill_count = Overkill.groupby(['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator']).size().reset_index(name='Overkill')\n",
    "Overkill_Overall =  False_errors[(False_errors['Final Decision'].isin(['Failed appeal','Edge case'])) & (False_errors['Final False Error'] == 'False Positive')]\n",
    "Overkill_Overall_count = Overkill_Overall.groupby(['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator']).size().reset_index(name='Overkill_Overall')\n",
    "Leakage =  False_errors[(False_errors['Final Decision'].isin(['Failed appeal'])) & (False_errors['Final False Error'] == 'False Negative')]\n",
    "Leakage_count = Leakage.groupby(['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator']).size().reset_index(name='Leakage')\n",
    "Leakage_Overall =  False_errors[(False_errors['Final Decision'].isin(['Failed appeal','Edge case'])) & (False_errors['Final False Error'] == 'False Negative')]\n",
    "Leakage_Overall_count = Leakage_Overall.groupby(['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator']).size().reset_index(name='Leakage_Overall')\n",
    "FP_false_errors = pd.merge(Overkill_Overall_count,Overkill_count,how='left',left_on=['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator'],right_on=['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator'])\n",
    "FN_false_errors = pd.merge(Leakage_Overall_count,Leakage_count,how='left',left_on=['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator'],right_on=['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator'])\n",
    "All_fn_fp = pd.merge(FP_false_errors,FN_false_errors,how='outer',on=['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator'])\n",
    "All_fn_fp = pd.merge(all_sample_sizes,All_fn_fp,how='left',left_on=['Week','Moderation Date','Queue Name','Moderators Name'],right_on=['Week','Date','QA QUEUE NAME','Moderator'])\n",
    "All_fn_fp_final = pd.merge(All_fn_fp,queue_list,on=['QA QUEUE NAME'],how='inner')\n",
    "All_fn_fp_final = All_fn_fp_final[['Quarter','Month','Week','Date','MOD QUEUE NAME','QA QUEUE NAME','Moderator','Overkill_Overall','Overkill','Leakage_Overall','Leakage','Sample Size']]\n",
    "All_fn_fp_final = All_fn_fp_final.sort_values(by=['Week'], ascending = True)\n",
    "All_fn_fp_final['%Overkill'] = All_fn_fp_final['Overkill'] / All_fn_fp_final['Sample Size']\n",
    "All_fn_fp_final['%Leakage'] = All_fn_fp_final['Leakage'] / All_fn_fp_final['Sample Size']\n",
    "All_fn_fp_final = All_fn_fp_final.groupby(by=['Quarter','Month','Week','Date','QA QUEUE NAME','Moderator'], as_index = False).agg({\n",
    "   'Overkill_Overall':'sum',\n",
    "   'Overkill_Overall':'sum',\n",
    "   'Overkill':'sum',\n",
    "   'Leakage_Overall':'sum',\n",
    "   'Leakage':'sum',\n",
    "   'Sample Size':'sum'})\n",
    "All_fn_fp_final['%Overkill'] = All_fn_fp_final['Overkill'] / All_fn_fp_final['Sample Size']\n",
    "All_fn_fp_final['%Leakage'] = All_fn_fp_final['Leakage'] / All_fn_fp_final['Sample Size']\n",
    "All_fn_fp_final = pd.merge(All_fn_fp_final, queue_list,how='outer',on='QA QUEUE NAME')\n",
    "All_fn_fp_final = All_fn_fp_final[['Quarter','Month','Week','Date','COMPOUND','MOD QUEUE NAME','QA QUEUE NAME','Moderator','Overkill_Overall','Overkill','Leakage_Overall','Leakage','Sample Size','%Overkill','%Leakage']]\n",
    "All_fn_fp_final = All_fn_fp_final.dropna(subset='Week')\n",
    "All_fn_fp_final = All_fn_fp_final.sort_values(by='Date', ascending=True)\n",
    "All_fn_fp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Moderation Date</th>\n",
       "      <th>COMPOUND</th>\n",
       "      <th>MOD QUEUE NAME</th>\n",
       "      <th>QA QUEUE NAME</th>\n",
       "      <th>Moderators Name</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Mods Wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244888</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>CB Product</td>\n",
       "      <td>VN CB Shop Decoration Risk Review</td>\n",
       "      <td>QA VN CB Shop Decoration Risk Review</td>\n",
       "      <td>phung.nhk@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244889</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>an.hb2@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244890</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>bang.pt@trans-cosmos.com.vn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244891</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>bich.ntn2@trans-cosmos.com.vn</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244892</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W44 (10.29 - 11.04)</td>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>chau.plb@trans-cosmos.com.vn</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338895</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>dong.ltk@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338896</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>giang.lt3@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338897</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>hau.nq@trans-cosmos.com.vn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338898</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Livestream</td>\n",
       "      <td>VN LL Live No-Anchor Commercial Content</td>\n",
       "      <td>QA VN LL Live No-Anchor Commercial Content</td>\n",
       "      <td>tu.lq@trans-cosmos.com.vn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338899</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>xuan.ht2@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33401 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Quarter Month                 Week Moderation Date      COMPOUND  \\\n",
       "244888      4.0   Nov  W44 (10.29 - 11.04)      2023-10-29    CB Product   \n",
       "244889      4.0   Nov  W44 (10.29 - 11.04)      2023-10-29           IPR   \n",
       "244890      4.0   Nov  W44 (10.29 - 11.04)      2023-10-29           IPR   \n",
       "244891      4.0   Nov  W44 (10.29 - 11.04)      2023-10-29           IPR   \n",
       "244892      4.0   Nov  W44 (10.29 - 11.04)      2023-10-29           IPR   \n",
       "...         ...   ...                  ...             ...           ...   \n",
       "338895      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "338896      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "338897      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "338898      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25    Livestream   \n",
       "338899      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "\n",
       "                                  MOD QUEUE NAME  \\\n",
       "244888         VN CB Shop Decoration Risk Review   \n",
       "244889  VN LL Anchor Video Counterfeit Key Frame   \n",
       "244890  VN LL Anchor Video Counterfeit Key Frame   \n",
       "244891  VN LL Anchor Video Counterfeit Key Frame   \n",
       "244892  VN LL Anchor Video Counterfeit Key Frame   \n",
       "...                                          ...   \n",
       "338895                     VN LL No-Anchor Video   \n",
       "338896                     VN LL No-Anchor Video   \n",
       "338897                     VN LL No-Anchor Video   \n",
       "338898   VN LL Live No-Anchor Commercial Content   \n",
       "338899                     VN LL No-Anchor Video   \n",
       "\n",
       "                                      QA QUEUE NAME  \\\n",
       "244888         QA VN CB Shop Decoration Risk Review   \n",
       "244889  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "244890  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "244891  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "244892  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "...                                             ...   \n",
       "338895                     QA VN LL No-Anchor Video   \n",
       "338896                     QA VN LL No-Anchor Video   \n",
       "338897                     QA VN LL No-Anchor Video   \n",
       "338898   QA VN LL Live No-Anchor Commercial Content   \n",
       "338899                     QA VN LL No-Anchor Video   \n",
       "\n",
       "                      Moderators Name  Sample Size  Mods Wrong  \n",
       "244888  phung.nhk@trans-cosmos.com.vn          1.0         0.0  \n",
       "244889     an.hb2@trans-cosmos.com.vn          1.0         0.0  \n",
       "244890    bang.pt@trans-cosmos.com.vn          2.0         0.0  \n",
       "244891  bich.ntn2@trans-cosmos.com.vn          5.0         0.0  \n",
       "244892   chau.plb@trans-cosmos.com.vn          5.0         0.0  \n",
       "...                               ...          ...         ...  \n",
       "338895   dong.ltk@trans-cosmos.com.vn          1.0         0.0  \n",
       "338896  giang.lt3@trans-cosmos.com.vn          1.0         0.0  \n",
       "338897     hau.nq@trans-cosmos.com.vn          2.0         0.0  \n",
       "338898      tu.lq@trans-cosmos.com.vn          2.0         0.0  \n",
       "338899   xuan.ht2@trans-cosmos.com.vn          1.0         0.0  \n",
       "\n",
       "[33401 rows x 10 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_filter = ['LL Product','CB Product','Seller','IPR','Appeal','Livestream','Anchor Video']\n",
    "mod_accr_overall = pd.merge(all_sample_sizes,all_mod_wrong,how='left',\n",
    "                            left_on=['Week', 'Moderation Date', 'Queue Name', 'Moderators Name'],\n",
    "                            right_on=['Week', 'Moderation Date', 'Queue Name', 'Moderators Name'])\n",
    "mod_accr_overall['Mods Wrong'] = mod_accr_overall['Mods Wrong'].fillna(0)       \n",
    "mod_accr_overall_copy = pd.merge(mod_accr_overall,week_list,how='left',left_on=['Week','Moderation Date'],right_on=['Mod_Week','Date'])\n",
    "mod_accr_overall_copy = pd.merge(mod_accr_overall_copy,queue_list,how='left',left_on='Queue Name',right_on='QA QUEUE NAME')\n",
    "mod_accr_overall_copy = mod_accr_overall_copy[['Quarter','Month','Week', 'Moderation Date','COMPOUND','MOD QUEUE NAME','QA QUEUE NAME','Moderators Name','Sample Size','Mods Wrong']]\n",
    "mod_accr_overall_copy = mod_accr_overall_copy[~mod_accr_overall_copy['Month'].isnull()]\n",
    "mod_accr_overall_copy = mod_accr_overall_copy.drop_duplicates()\n",
    "mod_accr_overall_final_filter = filter_week(mod_accr_overall_copy,filter_week_func,['Appeal','LL Product', 'CB Product','Livestream','Anchor Video','Seller', 'IPR'])\n",
    "mod_accr_overall_final_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EffectDate', 'Email', 'LineManager', 'Batch', 'Task',\n",
       "       'ProductionTenure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_alternation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_sample = pd.read_excel('mod no moderation.xlsx')\n",
    "# mod_sample['Date'] = pd.to_datetime(mod_sample['Date'].apply(convert_datetime))\n",
    "# print(mod_sample.columns)\n",
    "# mod_sample_ratio = pd.merge(mod_sample,mod_accr_overall_final_filter,how='left',right_on=['Moderation Date','MOD QUEUE NAME','Moderators Name'],left_on=['Date','Queue Title','Moderator'])\n",
    "# mod_sample_ratio = mod_sample_ratio[['Week','Date','COMPOUND','Queue Title','Moderator','No. of Moderation Tasks','Sample Size','Mods Wrong']]\n",
    "# mod_sample_ratio.to_excel('mod samples ratio.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Moderation Date</th>\n",
       "      <th>COMPOUND</th>\n",
       "      <th>MOD QUEUE NAME</th>\n",
       "      <th>QA QUEUE NAME</th>\n",
       "      <th>Moderators Name</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Mods Wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253105</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W45 (11.05 - 11.11)</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN CB Trademark New</td>\n",
       "      <td>QA VN CB Trademark New</td>\n",
       "      <td>bao.dtq@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253106</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W45 (11.05 - 11.11)</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>anh.tdk@trans-cosmos.com.vn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253107</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W45 (11.05 - 11.11)</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>bich.ntn2@trans-cosmos.com.vn</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253108</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W45 (11.05 - 11.11)</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>danh.vt1@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253109</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W45 (11.05 - 11.11)</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>IPR</td>\n",
       "      <td>VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>QA VN LL Anchor Video Counterfeit Key Frame</td>\n",
       "      <td>dung.ltm@trans-cosmos.com.vn</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338895</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>dong.ltk@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338896</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>giang.lt3@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338897</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>hau.nq@trans-cosmos.com.vn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338898</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Livestream</td>\n",
       "      <td>VN LL Live No-Anchor Commercial Content</td>\n",
       "      <td>QA VN LL Live No-Anchor Commercial Content</td>\n",
       "      <td>tu.lq@trans-cosmos.com.vn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338899</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>W47 (11.19 - 11.25)</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>Anchor Video</td>\n",
       "      <td>VN LL No-Anchor Video</td>\n",
       "      <td>QA VN LL No-Anchor Video</td>\n",
       "      <td>xuan.ht2@trans-cosmos.com.vn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26082 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Quarter Month                 Week Moderation Date      COMPOUND  \\\n",
       "253105      4.0   Nov  W45 (11.05 - 11.11)      2023-11-05           IPR   \n",
       "253106      4.0   Nov  W45 (11.05 - 11.11)      2023-11-05           IPR   \n",
       "253107      4.0   Nov  W45 (11.05 - 11.11)      2023-11-05           IPR   \n",
       "253108      4.0   Nov  W45 (11.05 - 11.11)      2023-11-05           IPR   \n",
       "253109      4.0   Nov  W45 (11.05 - 11.11)      2023-11-05           IPR   \n",
       "...         ...   ...                  ...             ...           ...   \n",
       "338895      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "338896      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "338897      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "338898      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25    Livestream   \n",
       "338899      4.0   Nov  W47 (11.19 - 11.25)      2023-11-25  Anchor Video   \n",
       "\n",
       "                                  MOD QUEUE NAME  \\\n",
       "253105                       VN CB Trademark New   \n",
       "253106  VN LL Anchor Video Counterfeit Key Frame   \n",
       "253107  VN LL Anchor Video Counterfeit Key Frame   \n",
       "253108  VN LL Anchor Video Counterfeit Key Frame   \n",
       "253109  VN LL Anchor Video Counterfeit Key Frame   \n",
       "...                                          ...   \n",
       "338895                     VN LL No-Anchor Video   \n",
       "338896                     VN LL No-Anchor Video   \n",
       "338897                     VN LL No-Anchor Video   \n",
       "338898   VN LL Live No-Anchor Commercial Content   \n",
       "338899                     VN LL No-Anchor Video   \n",
       "\n",
       "                                      QA QUEUE NAME  \\\n",
       "253105                       QA VN CB Trademark New   \n",
       "253106  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "253107  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "253108  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "253109  QA VN LL Anchor Video Counterfeit Key Frame   \n",
       "...                                             ...   \n",
       "338895                     QA VN LL No-Anchor Video   \n",
       "338896                     QA VN LL No-Anchor Video   \n",
       "338897                     QA VN LL No-Anchor Video   \n",
       "338898   QA VN LL Live No-Anchor Commercial Content   \n",
       "338899                     QA VN LL No-Anchor Video   \n",
       "\n",
       "                      Moderators Name  Sample Size  Mods Wrong  \n",
       "253105    bao.dtq@trans-cosmos.com.vn          1.0         0.0  \n",
       "253106    anh.tdk@trans-cosmos.com.vn          2.0         0.0  \n",
       "253107  bich.ntn2@trans-cosmos.com.vn          5.0         0.0  \n",
       "253108   danh.vt1@trans-cosmos.com.vn          1.0         0.0  \n",
       "253109   dung.ltm@trans-cosmos.com.vn          3.0         0.0  \n",
       "...                               ...          ...         ...  \n",
       "338895   dong.ltk@trans-cosmos.com.vn          1.0         0.0  \n",
       "338896  giang.lt3@trans-cosmos.com.vn          1.0         0.0  \n",
       "338897     hau.nq@trans-cosmos.com.vn          2.0         0.0  \n",
       "338898      tu.lq@trans-cosmos.com.vn          2.0         0.0  \n",
       "338899   xuan.ht2@trans-cosmos.com.vn          1.0         0.0  \n",
       "\n",
       "[26082 rows x 10 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_columns = mod_accr_overall.columns\n",
    "unoficial_filter_time = filter_time(unoficial,'Moderation Date',from_DATE,to_DATE,unoficial.columns)\n",
    "mod_accr_overall_filter_time = filter_time(mod_accr_overall,'Moderation Date',from_DATE,to_DATE,mod_accr_overall.columns)\n",
    "try:\n",
    "   mod_accr_overall_filter_time.to_excel(f'Mod KPI {from_DATE}_{to_DATE}.xlsx',index=False)\n",
    "   unoficial.to_excel(f'Unofficial false cases {from_DATE}_{to_DATE}.xlsx',index=False)\n",
    "except:\n",
    "   pass\n",
    "mod_accr_overall_filter_time_copy = filter_time(mod_accr_overall_copy,'Moderation Date',from_DATE,to_DATE,mod_accr_overall_copy.columns)\n",
    "mod_accr_overall_filter_time_copy.columns\n",
    "mod_accr_overall_filter_time_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EffectDate</th>\n",
       "      <th>Email</th>\n",
       "      <th>LineManager</th>\n",
       "      <th>Task</th>\n",
       "      <th>IPR_transfer</th>\n",
       "      <th>IPR_Seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>ai.btm@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN NGỌC TRÍ</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209833</th>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209834</th>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209835</th>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209836</th>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209837</th>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>yen.tp@trans-cosmos.com.vn</td>\n",
       "      <td>NGUYỄN ĐỖ PHÚ YÊN</td>\n",
       "      <td>Live_ds</td>\n",
       "      <td>No</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186747 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EffectDate                       Email        LineManager     Task  \\\n",
       "3797   2022-09-05  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3798   2022-09-06  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3799   2022-09-07  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3800   2022-09-08  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "3801   2022-09-09  ai.btm@trans-cosmos.com.vn    NGUYỄN NGỌC TRÍ        0   \n",
       "...           ...                         ...                ...      ...   \n",
       "209833 2023-05-18  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209834 2023-05-19  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209835 2023-05-20  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209836 2023-05-21  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "209837 2023-05-22  yen.tp@trans-cosmos.com.vn  NGUYỄN ĐỖ PHÚ YÊN  Live_ds   \n",
       "\n",
       "       IPR_transfer IPR_Seniority  \n",
       "3797             No           NaT  \n",
       "3798             No           NaT  \n",
       "3799             No           NaT  \n",
       "3800             No           NaT  \n",
       "3801             No           NaT  \n",
       "...             ...           ...  \n",
       "209833           No           NaT  \n",
       "209834           No           NaT  \n",
       "209835           No           NaT  \n",
       "209836           No           NaT  \n",
       "209837           No           NaT  \n",
       "\n",
       "[186747 rows x 6 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipr_transfer_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7908\\3142622352.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newbie_oldbie_tracker_ipr_initially_temp.drop(columns=['EffectDate', 'Email', 'LineManager', 'Task', 'IPR_transfer', 'IPR_Seniority'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#NEWBIE/OLDBIE\n",
    "samples_ppe = input_data_csv(\"Sample Size All Queues/All\")\n",
    "false_ppe = input_data_csv(\"False case All Queues/All\")\n",
    "\n",
    "samples_ppe['Moderation Date'] = pd.to_datetime(samples_ppe['Moderation Date'].apply(convert_datetime))\n",
    "false_ppe['Moderation Date'] = pd.to_datetime(false_ppe['Moderation Date'].apply(convert_datetime))\n",
    "\n",
    "compound_filter = ['Anchor Video','Livestream','CB Product','LL Product','Seller','IPR','Appeal']\n",
    "mod_accr_overall = pd.merge(samples_ppe,false_ppe,how='left',\n",
    "                            left_on=['Week', 'Moderation Date', 'Queue Name', 'Moderators Name'],\n",
    "                            right_on=['Week', 'Moderation Date', 'Queue Name', 'Moderators Name'])\n",
    "mod_accr_overall['Mods Wrong'] = mod_accr_overall['Mods Wrong'].fillna(0)              \n",
    "mod_accr_overall = pd.merge(mod_accr_overall,queue_list,how='left',left_on='Queue Name',right_on='QA QUEUE NAME')\n",
    "mod_accr_overall = mod_accr_overall[['Week', 'Moderation Date','CATEGORY','COMPOUND', 'QA QUEUE NAME', 'Moderators Name','Sample Size','Mods Wrong']]\n",
    "mod_accr_overall = mod_accr_overall[mod_accr_overall['COMPOUND'].isin(compound_filter)]\n",
    "mod_accr_overall = mod_accr_overall.sort_values(by='Moderation Date',ascending=True)\n",
    "newbie_oldbie_tracker_non_ipr_temp = mod_accr_overall[mod_accr_overall['COMPOUND']!='IPR']\n",
    "newbie_oldbie_tracker_ipr_temp = mod_accr_overall[mod_accr_overall['COMPOUND']=='IPR']\n",
    "\n",
    "ipr_transfer_tracker = ipr_transfer_tracker[ipr_transfer_tracker['IPR_transfer']=='Yes']\n",
    "\n",
    "newbie_oldbie_tracker_non_ipr = pd.merge(newbie_oldbie_tracker_non_ipr_temp,data_full_alternation,how='left',left_on=['Moderation Date','Moderators Name'],right_on=['EffectDate','Email'])\n",
    "newbie_oldbie_tracker_non_ipr.loc[newbie_oldbie_tracker_non_ipr['ProductionTenure'] >= 90, 'Seniority'] = 'oldbie'\n",
    "newbie_oldbie_tracker_non_ipr.loc[newbie_oldbie_tracker_non_ipr['ProductionTenure'] < 90, 'Seniority'] = 'newbie'\n",
    "newbie_oldbie_tracker_non_ipr.drop(columns=['EffectDate', 'Email', 'LineManager', 'Task','Batch','ProductionTenure'], inplace=True)\n",
    "\n",
    "newbie_oldbie_tracker_ipr = pd.merge(newbie_oldbie_tracker_ipr_temp,ipr_transfer_tracker,how='left',left_on=['Moderators Name'],right_on=['Email'])\n",
    "newbie_oldbie_tracker_ipr_initially_temp = newbie_oldbie_tracker_ipr[newbie_oldbie_tracker_ipr['IPR_transfer'].isnull()]\n",
    "newbie_oldbie_tracker_ipr_initially_temp.drop(columns=['EffectDate', 'Email', 'LineManager', 'Task', 'IPR_transfer', 'IPR_Seniority'], inplace=True)\n",
    "newbie_oldbie_tracker_ipr_initially = pd.merge(newbie_oldbie_tracker_ipr_initially_temp,data_full_alternation,how='left',left_on=['Moderation Date','Moderators Name'],right_on=['EffectDate','Email'])\n",
    "newbie_oldbie_tracker_ipr_initially.loc[newbie_oldbie_tracker_ipr_initially['ProductionTenure'] >= 90, 'Seniority'] = 'oldbie'\n",
    "newbie_oldbie_tracker_ipr_initially.loc[newbie_oldbie_tracker_ipr_initially['ProductionTenure'] < 90, 'Seniority'] = 'newbie'\n",
    "newbie_oldbie_tracker_ipr_initially.drop(columns=['EffectDate', 'Email', 'LineManager', 'Task','Batch','ProductionTenure'], inplace=True)\n",
    "\n",
    "newbie_oldbie_tracker_ipr_transfer = newbie_oldbie_tracker_ipr[~newbie_oldbie_tracker_ipr['IPR_transfer'].isnull()]\n",
    "newbie_oldbie_tracker_ipr_transfer = newbie_oldbie_tracker_ipr_transfer[newbie_oldbie_tracker_ipr_transfer['Moderation Date'] >= newbie_oldbie_tracker_ipr_transfer['EffectDate']]\n",
    "newbie_oldbie_tracker_ipr_transfer = newbie_oldbie_tracker_ipr_transfer.drop_duplicates()\n",
    "conditions = [\n",
    "    (newbie_oldbie_tracker_ipr_transfer['Moderation Date'] >= newbie_oldbie_tracker_ipr_transfer['EffectDate']) &\n",
    "    (newbie_oldbie_tracker_ipr_transfer['Moderation Date'] <= newbie_oldbie_tracker_ipr_transfer['IPR_Seniority']),\n",
    "    (newbie_oldbie_tracker_ipr_transfer['Moderation Date'] > newbie_oldbie_tracker_ipr_transfer['IPR_Seniority'])]\n",
    "values = ['newbie', 'oldbie']\n",
    "newbie_oldbie_tracker_ipr_transfer['Seniority'] = np.select(conditions, values, default='other')\n",
    "newbie_oldbie_tracker_ipr_transfer.drop(columns=['EffectDate', 'Email', 'LineManager', 'Task','IPR_transfer','IPR_Seniority'], inplace=True)\n",
    "\n",
    "newbie_oldbie_tracker = pd.concat([newbie_oldbie_tracker_non_ipr,newbie_oldbie_tracker_ipr_initially,newbie_oldbie_tracker_ipr_transfer],axis=0)\n",
    "newbie_oldbie_tracker_download = filter_week(newbie_oldbie_tracker,filter_week_func,['Appeal','LL Product', 'CB Product','Livestream','Anchor Video','Seller', 'IPR'])\n",
    "newbie_oldbie_tracker_download.to_excel('newbie_oldbie_tracker_download.xlsx', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_acc = pd.read_csv('nov_ag_list_without_manager.csv')\n",
    "exclude_acc = exclude_acc[exclude_acc['filter_col'] == 1]\n",
    "exclude_acc['max_date'] = pd.to_datetime(exclude_acc['max_date'].apply(convert_datetime))\n",
    "exclude_acc['min_date'] = pd.to_datetime(exclude_acc['min_date'].apply(convert_datetime))\n",
    "exclude_acc = exclude_acc[['Email', 'min_date', 'max_date']]\n",
    "\n",
    "kpi_result = pd.DataFrame()\n",
    "\n",
    "for index, row in exclude_acc.iterrows():\n",
    "    temp_df = mod_accr_overall_filter_time[\n",
    "        (mod_accr_overall_filter_time['Moderation Date'] >= row['min_date']) &\n",
    "        (mod_accr_overall_filter_time['Moderation Date'] <= row['max_date']) &\n",
    "        (mod_accr_overall_filter_time['Moderators Name'] == row['Email'])\n",
    "    ]\n",
    "    if not temp_df.empty:\n",
    "        kpi_result = pd.concat([kpi_result, temp_df])\n",
    "\n",
    "kpi_result = kpi_result.drop_duplicates()\n",
    "kpi_result.to_excel(f'Mod KPI {from_DATE}_{to_DATE}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_sample_analyst = pd.merge(live_prod,mod_accr_overall_filter_time_copy,how='left',left_on=['Date','QA QUEUE NAME', 'Moderator'],right_on=['Moderation Date', 'QA QUEUE NAME','Moderators Name'])\n",
    "# mod_sample_analyst = mod_sample_analyst[['Mod_Week', 'Date', 'QA QUEUE NAME','Moderator','No. of Moderation Tasks', 'Sample Size', 'Mods Wrong']]\n",
    "# mod_sample_analyst.to_excel('mod_live_sample_analyst.xlsx',index=False)\n",
    "# mod_sample_analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_accr_overall_final_filter = filter_week(mod_accr_overall_copy,filter_week_func,compound_filter)\n",
    "# All_fn_fp_final_filter = filter_week(All_fn_fp_final,filter_week_func,compound_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sheets_mod = {'Acc': mod_accr_overall_final_filter,'RCA':RCA_diff_dive_count}\n",
    "\n",
    "mod_writer = pd.ExcelWriter('mod.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for sheet_name in all_sheets_mod.keys():\n",
    "    all_sheets_mod[sheet_name].to_excel(mod_writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "mod_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_KPI_Internal = mod_accr_overall_copy.groupby(by=['CATEGORY'],as_index=False).agg({'Sample Size':'sum','Mods Wrong':'sum'})\n",
    "# overall_KPI_Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EffectDate', 'Email', 'LineManager', 'Batch', 'Task',\n",
       "       'ProductionTenure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_alternation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Role'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Role'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\qa_data\\Mod Accr.ipynb Cell 43\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/qa_data/Mod%20Accr.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mod_accr_overall_linemanager \u001b[39m=\u001b[39m mod_accr_overall_linemanager[[\u001b[39m'\u001b[39m\u001b[39mModeration Date\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mQA QUEUE NAME\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mModerators Name\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSample Size\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mMods Wrong\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/qa_data/Mod%20Accr.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mod_accr_overall_linemanager \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(mod_accr_overall_linemanager,data_full_alternation,how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m,left_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mModeration Date\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mModerators Name\u001b[39m\u001b[39m'\u001b[39m],right_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mEffectDate\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mEmail\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/qa_data/Mod%20Accr.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m mod_accr_overall_linemanager \u001b[39m=\u001b[39m mod_accr_overall_linemanager[\u001b[39m~\u001b[39mmod_accr_overall_linemanager[\u001b[39m'\u001b[39;49m\u001b[39mRole\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39misnull()]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/qa_data/Mod%20Accr.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m mod_accr_overall_linemanager \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(mod_accr_overall_linemanager,week_list,how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m,left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModeration Date\u001b[39m\u001b[39m'\u001b[39m,right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Role'"
     ]
    }
   ],
   "source": [
    "mod_accr_overall_linemanager = mod_accr_overall_copy.groupby(by=['Moderation Date','QA QUEUE NAME','Moderators Name'], as_index=False).agg({'Sample Size':'sum','Mods Wrong':'sum'})\n",
    "mod_accr_overall_linemanager = filter_time(mod_accr_overall_linemanager,'Moderation Date',from_DATE,to_DATE,['Moderation Date','QA QUEUE NAME','Moderators Name','Sample Size','Mods Wrong'])\n",
    "mod_accr_overall_linemanager = mod_accr_overall_linemanager[['Moderation Date','QA QUEUE NAME','Moderators Name','Sample Size','Mods Wrong']]\n",
    "mod_accr_overall_linemanager = pd.merge(mod_accr_overall_linemanager,data_full_alternation,how='left',left_on=['Moderation Date','Moderators Name'],right_on=['EffectDate','Email'])\n",
    "mod_accr_overall_linemanager = mod_accr_overall_linemanager[~mod_accr_overall_linemanager['Role'].isnull()]\n",
    "mod_accr_overall_linemanager = pd.merge(mod_accr_overall_linemanager,week_list,how='left',left_on='Moderation Date',right_on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_accr_overall_linemanager = mod_accr_overall_linemanager.dropna(subset=['LineManager', 'Report_Week'])\n",
    "mod_accr_overall_linemanager = mod_accr_overall_linemanager[['LineManager','Role','Batch','ProductionTenure','Report_Week','Moderation Date','QA QUEUE NAME','Moderators Name','Sample Size','Mods Wrong']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_week_func = {'W44'}\n",
    "def filter_week(df,W):\n",
    "    df = df[df['Report_Week'].str.contains('|'.join(W))]\n",
    "    return df\n",
    "mod_accr_overall_linemanager_2 = filter_week(mod_accr_overall_linemanager,filter_week_func)\n",
    "mod_accr_overall_linemanager_2 = mod_accr_overall_linemanager_2.groupby(by=['LineManager','Report_Week','Moderation Date','Moderators Name'],as_index=False).agg({'Sample Size':'sum','Mods Wrong':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_accr_overall_linemanager_2.to_excel(f'mod accr line manager {filter_week_func}.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
