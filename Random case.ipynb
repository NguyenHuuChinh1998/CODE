{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import win32com.client\n",
    "import webbrowser\n",
    "import time\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_csv_files(folder_path, title_column, resolve_time_column, sheet_name=None):\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    for file in files:\n",
    "         if file.endswith(\".csv\") and \"tcs_export\" in file:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            if sheet_name is None:\n",
    "                df = pd.read_csv(file_path)\n",
    "            else:\n",
    "                df = pd.read_csv(file_path, sheet_name=sheet_name)\n",
    "                \n",
    "            first_title = df[title_column][0]\n",
    "            \n",
    "            df[resolve_time_column] = pd.to_datetime(df[resolve_time_column])\n",
    "            \n",
    "            start_date = df[resolve_time_column].min()\n",
    "            end_date = df[resolve_time_column].max()\n",
    "            \n",
    "            first_title = re.sub(r'[\\\\/:\"*?<>|]+', '', first_title)\n",
    "            \n",
    "            start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "            end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "            \n",
    "            new_file_name = f\"{first_title}_{start_date_str}_{end_date_str}.csv\"\n",
    "            new_file_path = os.path.join(folder_path, new_file_name)\n",
    "            \n",
    "            if os.path.exists(new_file_path):\n",
    "                os.remove(new_file_path)\n",
    "            \n",
    "            os.rename(file_path, new_file_path)\n",
    "\n",
    "dir_randomraw = 'Random rawdata'\n",
    "\n",
    "rename_csv_files(dir_randomraw, 'title', '1_resolve_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queue\n",
    "queue_list = pd.read_excel('Support_dashboard.xlsx',sheet_name='Queue List').values\n",
    "queue_list = pd.DataFrame(queue_list)\n",
    "headers = ['BUSINESS','COMPOUND','CATEGORY','MOD QUEUE ID','MOD QUEUE NAME',\n",
    "           'QA QUEUE ID','QA QUEUE NAME','QUEUE GROUP','STATUS','Priority','Latency','AHT (secs)','Policy_type','Classify']\n",
    "queue_list.columns = headers\n",
    "\n",
    "#Policy Errors\n",
    "policy_errors_list = pd.read_excel('Support_dashboard.xlsx',sheet_name='Policy Errors').values\n",
    "policy_errors_list = [item for sublist in policy_errors_list for item in sublist]\n",
    "\n",
    "#Data Alternation\n",
    "data_full_alternation = pd.read_excel('linemanager_full.xlsx')\n",
    "data_full_alternation = data_full_alternation[data_full_alternation['Role'].str.contains('Operator')]\n",
    "data_full_alternation = data_full_alternation[['EffectDate','Email','FullName','LineManager','ProductionDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_datetime(a):\n",
    "    my_format=\"%Y-%m-%d %H:%M:%S\"\n",
    "    try:\n",
    "        return datetime.strptime(str(a), \"%Y-%m-%d %H:%M:%S\").strftime(my_format)\n",
    "    except:\n",
    "        return datetime.strptime(str(a), \"%m/%d/%Y %H:%M\").strftime(my_format)\n",
    "def convert_date(a):\n",
    "    my_format=\"%Y-%m-%d\"\n",
    "    try:\n",
    "        return datetime.strptime(str(a), \"%Y-%m-%d %H:%M:%S\").strftime(my_format)\n",
    "    except:\n",
    "        return datetime.strptime(str(a), \"%m/%d/%Y %H:%M\").strftime(my_format)    \n",
    "    \n",
    "def input_data(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, dtype={'task_id': object,'project_id':object,'object_id':object})\n",
    "            df[['project_id','task_id','object_id']] = df[['project_id','task_id','object_id']].replace(to_replace=r'id=',value= '',regex=True).astype(str)\n",
    "            df['1_resolve_time'] = df['1_resolve_time'].apply(convert_datetime)\n",
    "            \n",
    "            df['source_file'] = os.path.basename(file_path)\n",
    "\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "  \n",
    "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_rawdata = input_data('Random rawdata')\n",
    "Rand_rawdata = Rand_rawdata.drop_duplicates(subset='task_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_rawdata = Rand_rawdata[['task_id', 'project_id', 'title', 'object_id','1_verifier','1_resolve_time','1_duration','1_verify_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_time( df,  from_date, to_date):\n",
    "    Rand_rawdata['1_resolve_time'] = pd.to_datetime(Rand_rawdata['1_resolve_time'])\n",
    "    Rand_rawdata_fiter = df[(df['1_resolve_time'].dt.strftime('%Y-%m-%d') >= from_date) & (df['1_resolve_time'].dt.strftime('%Y-%m-%d') <= to_date)]\n",
    "\n",
    "    return Rand_rawdata_fiter,from_date,to_date\n",
    "\n",
    "Rand_export,from_date,to_date = filter_time(Rand_rawdata, '2023-11-12', '2023-11-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>title</th>\n",
       "      <th>object_id</th>\n",
       "      <th>1_verifier</th>\n",
       "      <th>1_resolve_time</th>\n",
       "      <th>1_duration</th>\n",
       "      <th>1_verify_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270712</th>\n",
       "      <td>7298434342366364162</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7298201659228834561_1699259133</td>\n",
       "      <td>nguyen.npk@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-12 01:16:02</td>\n",
       "      <td>23</td>\n",
       "      <td>{\"real_assign_time\":1699726528.685,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271237</th>\n",
       "      <td>7298441047066132994</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7298343097758255873_1699282189</td>\n",
       "      <td>nguyen.npk@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-12 01:16:36</td>\n",
       "      <td>28</td>\n",
       "      <td>{\"real_assign_time\":1699726557.952,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271456</th>\n",
       "      <td>7298443606312927746</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7298367667625282306_1699284532</td>\n",
       "      <td>linh.pc@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-12 04:22:22</td>\n",
       "      <td>10</td>\n",
       "      <td>{\"real_assign_time\":1699737721.701,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271519</th>\n",
       "      <td>7298444370380882434</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7298102367072406274_1699225338</td>\n",
       "      <td>nguyen.npk@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-12 06:01:54</td>\n",
       "      <td>24</td>\n",
       "      <td>{\"real_assign_time\":1699743679.615,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271600</th>\n",
       "      <td>7298445356193333762</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7298245188672047880_1699256216</td>\n",
       "      <td>trang.nlx1@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-12 06:03:21</td>\n",
       "      <td>66</td>\n",
       "      <td>{\"real_assign_time\":1699743723.414,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282650</th>\n",
       "      <td>7299537404195570178</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7299115286928657158_1699495305</td>\n",
       "      <td>anh.nm@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-14 16:31:41</td>\n",
       "      <td>34</td>\n",
       "      <td>{\"real_assign_time\":1699954255.429,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282651</th>\n",
       "      <td>7299537425427071489</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7299415768637852434_1699529363</td>\n",
       "      <td>thai.ng@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-14 16:31:43</td>\n",
       "      <td>14</td>\n",
       "      <td>{\"real_assign_time\":1699954278.164,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282652</th>\n",
       "      <td>7299537456712499714</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7299347033675074311_1699514436</td>\n",
       "      <td>hao.hm@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-14 16:32:27</td>\n",
       "      <td>28</td>\n",
       "      <td>{\"real_assign_time\":1699954308.134,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282653</th>\n",
       "      <td>7299537468720693761</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7299152476635253510_1699499404</td>\n",
       "      <td>van.vtn@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-14 16:32:36</td>\n",
       "      <td>30</td>\n",
       "      <td>{\"real_assign_time\":1699954314.784,\"real_resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282654</th>\n",
       "      <td>7299537517110395394</td>\n",
       "      <td>7171514518084895234</td>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>7299447363469429505_1699538587</td>\n",
       "      <td>thai.ng@trans-cosmos.com.vn</td>\n",
       "      <td>2023-11-14 16:32:19</td>\n",
       "      <td>37</td>\n",
       "      <td>{\"real_assign_time\":1699954291.47,\"real_resolv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9827 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    task_id           project_id              title  \\\n",
       "270712  7298434342366364162  7171514518084895234  VN LL Live Backup   \n",
       "271237  7298441047066132994  7171514518084895234  VN LL Live Backup   \n",
       "271456  7298443606312927746  7171514518084895234  VN LL Live Backup   \n",
       "271519  7298444370380882434  7171514518084895234  VN LL Live Backup   \n",
       "271600  7298445356193333762  7171514518084895234  VN LL Live Backup   \n",
       "...                     ...                  ...                ...   \n",
       "282650  7299537404195570178  7171514518084895234  VN LL Live Backup   \n",
       "282651  7299537425427071489  7171514518084895234  VN LL Live Backup   \n",
       "282652  7299537456712499714  7171514518084895234  VN LL Live Backup   \n",
       "282653  7299537468720693761  7171514518084895234  VN LL Live Backup   \n",
       "282654  7299537517110395394  7171514518084895234  VN LL Live Backup   \n",
       "\n",
       "                             object_id                      1_verifier  \\\n",
       "270712  7298201659228834561_1699259133  nguyen.npk@trans-cosmos.com.vn   \n",
       "271237  7298343097758255873_1699282189  nguyen.npk@trans-cosmos.com.vn   \n",
       "271456  7298367667625282306_1699284532     linh.pc@trans-cosmos.com.vn   \n",
       "271519  7298102367072406274_1699225338  nguyen.npk@trans-cosmos.com.vn   \n",
       "271600  7298245188672047880_1699256216  trang.nlx1@trans-cosmos.com.vn   \n",
       "...                                ...                             ...   \n",
       "282650  7299115286928657158_1699495305      anh.nm@trans-cosmos.com.vn   \n",
       "282651  7299415768637852434_1699529363     thai.ng@trans-cosmos.com.vn   \n",
       "282652  7299347033675074311_1699514436      hao.hm@trans-cosmos.com.vn   \n",
       "282653  7299152476635253510_1699499404     van.vtn@trans-cosmos.com.vn   \n",
       "282654  7299447363469429505_1699538587     thai.ng@trans-cosmos.com.vn   \n",
       "\n",
       "            1_resolve_time  1_duration  \\\n",
       "270712 2023-11-12 01:16:02          23   \n",
       "271237 2023-11-12 01:16:36          28   \n",
       "271456 2023-11-12 04:22:22          10   \n",
       "271519 2023-11-12 06:01:54          24   \n",
       "271600 2023-11-12 06:03:21          66   \n",
       "...                    ...         ...   \n",
       "282650 2023-11-14 16:31:41          34   \n",
       "282651 2023-11-14 16:31:43          14   \n",
       "282652 2023-11-14 16:32:27          28   \n",
       "282653 2023-11-14 16:32:36          30   \n",
       "282654 2023-11-14 16:32:19          37   \n",
       "\n",
       "                                            1_verify_data  \n",
       "270712  {\"real_assign_time\":1699726528.685,\"real_resol...  \n",
       "271237  {\"real_assign_time\":1699726557.952,\"real_resol...  \n",
       "271456  {\"real_assign_time\":1699737721.701,\"real_resol...  \n",
       "271519  {\"real_assign_time\":1699743679.615,\"real_resol...  \n",
       "271600  {\"real_assign_time\":1699743723.414,\"real_resol...  \n",
       "...                                                   ...  \n",
       "282650  {\"real_assign_time\":1699954255.429,\"real_resol...  \n",
       "282651  {\"real_assign_time\":1699954278.164,\"real_resol...  \n",
       "282652  {\"real_assign_time\":1699954308.134,\"real_resol...  \n",
       "282653  {\"real_assign_time\":1699954314.784,\"real_resol...  \n",
       "282654  {\"real_assign_time\":1699954291.47,\"real_resolv...  \n",
       "\n",
       "[9827 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v6210227\\AppData\\Local\\Temp\\ipykernel_19292\\3927253285.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rand_export['1st_result'] = Rand_export['1_verify_data'].apply(check_string)\n"
     ]
    }
   ],
   "source": [
    "keymap = {\"Not Approve\":['\"status\":400','\"audit_result\":400','disapproval', 'disapproved','not approval','not approval','not approve' ,'not approval','disapprove','disapproved','(truncated)'] ,\n",
    "    \"Approve\":[ '\"status\":200' ,'\"audit_result\":200', 'approval', 'approved','200' ,'200.0' ,'approve']}\n",
    "\n",
    "def check_string(s):\n",
    "    if isinstance(s, str):\n",
    "        s_lower = s.lower()\n",
    "\n",
    "        for approval_status, substrings in keymap.items():\n",
    "            if any(substring in s_lower for substring in substrings):\n",
    "                return approval_status\n",
    "\n",
    "    return s\n",
    "\n",
    "Rand_export['1st_result'] = Rand_export['1_verify_data'].apply(check_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_export_test = Rand_export[['title', 'task_id', '1_verify_data', '1st_result']]\n",
    "Rand_export_test = Rand_export_test.loc[Rand_export_test['1st_result'] == 'Not approve']\n",
    "Rand_export_test = Rand_export_test.drop_duplicates(subset=['title'])\n",
    "\n",
    "def get_first_not_approve(df):\n",
    "    return df.iloc[0]\n",
    "\n",
    "Rand_export_test = Rand_export_test.groupby('title').apply(get_first_not_approve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v6210227\\AppData\\Local\\Temp\\ipykernel_19292\\3688987074.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rand_export['1_verify_data'] = Rand_export['1_verify_data'].replace(['0013', '0012', '0005', '_'], ' ', regex=True)\n",
      "C:\\Users\\v6210227\\AppData\\Local\\Temp\\ipykernel_19292\\3688987074.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rand_export['1_verify_data'] = Rand_export['1_verify_data'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "Rand_export['1_verify_data'] = Rand_export['1_verify_data'].replace(['0013', '0012', '0005', '_'], ' ', regex=True)\n",
    "Rand_export['1_verify_data'] = Rand_export['1_verify_data'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Policy_errors = policy_errors_list.copy()\n",
    "cols_to_check = ['1_verify_data']\n",
    "cols_to_return = ['Mod Reason']\n",
    "queue_policy_type = queue_list[['MOD QUEUE NAME','Policy_type']]\n",
    "Rand_export = pd.merge(Rand_export,queue_policy_type, how='inner', left_on='title', right_on='MOD QUEUE NAME')\n",
    "for col_idx, col in enumerate(cols_to_check):\n",
    "    Rand_export[cols_to_return[col_idx]] = ''\n",
    "    for i, row in Rand_export.iterrows():\n",
    "        cell_value = row[col]\n",
    "        policy_type = row['Policy_type']\n",
    "        if isinstance(cell_value, str):\n",
    "            if 'form info' in cell_value:\n",
    "                form_info_index = cell_value.index('form info')\n",
    "                cell_value = cell_value[form_info_index:]\n",
    "                match_list_1 = [match for match in Policy_errors if match in cell_value]\n",
    "                if match_list_1:\n",
    "                    match_list = list(OrderedDict.fromkeys(match_list_1))\n",
    "                    final_reason = \", \".join(match_list).strip()\n",
    "                    Rand_export.at[i, cols_to_return[col_idx]] = final_reason\n",
    "            elif 'reject reasons' in cell_value:\n",
    "                form_info_index = cell_value.index('reject reasons')\n",
    "                cell_value_new = cell_value[:form_info_index]\n",
    "                match_list_1 = [match for match in Policy_errors if match in cell_value_new]\n",
    "                if match_list_1:\n",
    "                    match_list = list(OrderedDict.fromkeys(match_list_1))\n",
    "                    final_reason = \", \".join(match_list).strip()\n",
    "                    Rand_export.at[i, cols_to_return[col_idx]] = final_reason\n",
    "            elif 'reject label' in cell_value:\n",
    "                form_info_index = cell_value.index('reject label')\n",
    "                cell_value = cell_value[form_info_index:]\n",
    "                match_list_1 = [match for match in Policy_errors if match in cell_value]\n",
    "                if match_list_1:\n",
    "                    match_list = list(OrderedDict.fromkeys(match_list_1))\n",
    "                    final_reason = \", \".join(match_list).strip()\n",
    "                    Rand_export.at[i, cols_to_return[col_idx]] = final_reason\n",
    "            else:\n",
    "                if policy_type == 'Multi-choice':\n",
    "                    match_list_1 = [match for match in Policy_errors if match in cell_value]\n",
    "                    if match_list_1:\n",
    "                        match_list = list(OrderedDict.fromkeys(match_list_1))\n",
    "                        final_reason = \", \".join(match_list).strip()\n",
    "                        Rand_export.at[i, cols_to_return[col_idx]] = final_reason\n",
    "                elif policy_type == 'Single-choice':\n",
    "                    match_list_1 = []\n",
    "                    for match in Policy_errors:\n",
    "                        if match in cell_value:\n",
    "                            match_list_1.append(match)\n",
    "                            break\n",
    "                    if match_list_1:\n",
    "                        final_reason = match_list_1[0]\n",
    "                        Rand_export.at[i, cols_to_return[col_idx]] = final_reason\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "Rand_export['policy errors'] = Rand_export[['Mod Reason']].apply(lambda x: x[x != ''].loc[x[x != ''].last_valid_index()] if x[x != ''].last_valid_index() else '', axis=1)\n",
    "Rand_export['policy errors'] = Rand_export['policy errors'].replace(\"_\",\" \",regex=True).replace(\"counterfeit abnorma price product\",\"abnormal price\")\n",
    "Rand_export['policy errors'] = Rand_export['policy errors'].apply(lambda x: \", \".join(set(x.split(\", \"))))\n",
    "Rand_export = Rand_export[['title','task_id','object_id','1_resolve_time','1_verifier','1_duration','1st_result','policy errors']]\n",
    "Rand_export['Date'] = pd.to_datetime(Rand_export['1_resolve_time'].apply(convert_date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_export_rawdata = pd.merge(Rand_export,data_full_alternation,how='left',left_on=['Date','1_verifier'],right_on=['EffectDate','Email'])\n",
    "Rand_export_rawdata.to_excel(f'all cases backup queue {from_date}{to_date}.xlsx')\n",
    "Rand_export_rawdata = Rand_export_rawdata[Rand_export_rawdata['1_resolve_time'] >= Rand_export_rawdata['ProductionDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_export_rawdata = Rand_export_rawdata[['title', 'task_id', 'object_id', '1_resolve_time', '1_verifier', 'FullName', 'LineManager','1_duration', '1st_result', 'policy errors']]\n",
    "def sample_or_return_all(x):\n",
    "    if len(x) <= 10:\n",
    "        return x\n",
    "    else:\n",
    "        return x.sample(n=10, replace=False, random_state=1)\n",
    "Rand_export_for_QA = Rand_export_rawdata.groupby('1_verifier',as_index=False).apply(sample_or_return_all)\n",
    "Rand_export_for_QA = Rand_export_for_QA[['title','task_id','object_id','1_resolve_time','1_verifier','FullName', 'LineManager','1_duration','1st_result','policy errors']]\n",
    "Rand_export_for_QA = Rand_export_for_QA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v6210227\\AppData\\Local\\Temp\\ipykernel_19292\\143026491.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Rand_export_for_TLs = pd.concat([Rand_export_for_TLs, sampled_group])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LineManager\n",
       "BÙI THỊ THANH THẢO        150\n",
       "HÀ MINH ĐẠT               150\n",
       "LẠI TRẦN ĐOÀN THUẬN       150\n",
       "NGUYỄN THỊ TUYẾT NHUNG    150\n",
       "NGUYỄN ĐỖ PHÚ YÊN         150\n",
       "VÕ TẤN LỰC                150\n",
       "NGUYỄN THỊ THU HẰNG        60\n",
       "NGUYỄN HUY DANH            40\n",
       "NGUYỄN QUANG ANH            2\n",
       "NGUYỄN TRẦN ĐỨC THÀNH       2\n",
       "LÊ TẤN THỊNH                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_by_manager = Rand_export_for_QA.groupby('LineManager')\n",
    "desired_rows_per_manager = 150\n",
    "Rand_export_for_TLs = pd.DataFrame(columns=['title', 'task_id', 'object_id', '1_resolve_time', '1_verifier','FullName', 'LineManager', '1_duration', '1st_result', 'policy errors'])\n",
    "for _, group in grouped_by_manager:\n",
    "    sampled_group = group.sample(n=min(desired_rows_per_manager, len(group)), random_state=1)\n",
    "    Rand_export_for_TLs = pd.concat([Rand_export_for_TLs, sampled_group])\n",
    "Rand_export_for_TLs = Rand_export_for_TLs.reset_index(drop=True)\n",
    "Rand_export_for_TLs['LineManager'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_by_manager = Rand_export_for_QA.groupby('LineManager')\n",
    "# Rand_export_for_TLs = pd.DataFrame(columns=['title', 'task_id', 'object_id', '1_resolve_time', '1_verifier', '1_duration', '1st_result', 'policy errors'])\n",
    "# total_rows_to_select = 150\n",
    "# for _, group in grouped_by_manager:\n",
    "#     if len(group) > total_rows_to_select:\n",
    "#         sampled_group = group.sample(n=total_rows_to_select, random_state=1)\n",
    "#     else:\n",
    "#         sampled_group = group\n",
    "#     avg_rows_per_verifier = total_rows_to_select / len(sampled_group['1_verifier'].unique())    \n",
    "#     temp_df = pd.DataFrame(columns=Rand_export_for_QA.columns)\n",
    "#     for verifier, verifier_group in sampled_group.groupby('1_verifier'):\n",
    "#         rows_for_verifier = min(int(avg_rows_per_verifier), len(verifier_group))\n",
    "#         if len(verifier_group) > rows_for_verifier:\n",
    "#             sampled_verifier_group = verifier_group.sample(n=rows_for_verifier, random_state=1)\n",
    "#         else:\n",
    "#             sampled_verifier_group = verifier_group\n",
    "#         temp_df = pd.concat([temp_df, sampled_verifier_group])\n",
    "#     Rand_export_for_TLs = pd.concat([Rand_export_for_TLs, temp_df])\n",
    "# Rand_export_for_TLs = Rand_export_for_TLs.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>1_verifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VN LL Live Backup</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  1_verifier\n",
       "0  VN LL Live Backup        1261"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Rand_export_for_QA.groupby(by=['title'],as_index=False).agg({'1_verifier':'count'})\n",
    "print(sum(test['1_verifier']))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_export_for_QA.to_excel(f'Random case exported/QA Random case exported exported {from_date}{to_date}.xlsx', index=False)\n",
    "Rand_export_for_TLs.to_excel(f'Random case exported/TL Random case exported exported {from_date}{to_date}.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
